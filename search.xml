<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[linux每日命令(34)：ps命令和pstree命令]]></title>
    <url>%2F2018%2F12%2F04%2Flinux%E6%AF%8F%E6%97%A5%E5%91%BD%E4%BB%A4(34)%EF%BC%9Aps%E5%91%BD%E4%BB%A4%E5%92%8Cpstree%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[Linux中的ps命令是Process Status的缩写。ps命令用来列出系统中当前运行的那些进程。ps命令列出的是当前那些进程的快照，就是执行ps命令的那个时刻的那些进程，如果想要动态的显示进程信息，就可以使用top命令。 要对进程进行监测和控制，首先必须要了解当前进程的情况，也就是需要查看当前进程，而 ps 命令就是最基本同时也是非常强大的进程查看命令。使用该命令可以确定有哪些进程正在运行和运行的状态、进程是否结束、进程有没有僵死、哪些进程占用了过多的资源等等。总之大部分信息都是可以通过执行该命令得到的。 ps 为我们提供了进程的一次性的查看，它所提供的查看结果并不动态连续的；如果想对进程时间监控，应该用 top 工具。 kill 命令用于杀死进程。 一．命令格式：ps [参数] 二．命令功能：用于显示当前进程 (process) 的状态。 三．命令参数：ps 的参数非常多, 在此仅列出几个常用的参数并大略介绍含义 参数 描述 -A 列出所有的行程 -e 等于“-A” -a 显示现行终端机下的所有进程，包括其他用户的进程； -u 以用户为主的进程状态 ； x 通常与 a 这个参数一起使用，可列出较完整信息。 -w 显示加宽可以显示较多的资讯 -au 显示较详细的资讯 -aux 显示所有包含其他使用者的行程 -f 做一个更为完整的输出。 四. 使用实例1. 显示所有进程信息命令： ps -A 输出：12345678910111213141516[root@localhost autoAweme]# ps -A PID TTY TIME CMD 1 ? 00:00:15 systemd 2 ? 00:00:00 kthreadd 3 ? 00:00:56 ksoftirqd/0 5 ? 00:00:00 kworker/0:0H 7 ? 00:01:01 migration/0 8 ? 00:00:00 rcu_bh 9 ? 00:18:57 rcu_sched 10 ? 00:00:00 lru-add-drain 11 ? 00:00:03 watchdog/0 12 ? 00:00:02 watchdog/1 13 ? 00:01:01 migration/1 14 ? 00:00:56 ksoftirqd/1 16 ? 00:00:00 kworker/1:0H……省略部分结果 2. 显示指定用户信息命令： ps -u root 输出： 12345678910111213141516171819[root@localhost autoAweme]# ps -u root PID TTY TIME CMD 1 ? 00:00:15 systemd 2 ? 00:00:00 kthreadd 3 ? 00:00:56 ksoftirqd/0 5 ? 00:00:00 kworker/0:0H 7 ? 00:01:01 migration/0 8 ? 00:00:00 rcu_bh 9 ? 00:18:57 rcu_sched 10 ? 00:00:00 lru-add-drain 11 ? 00:00:03 watchdog/0 12 ? 00:00:02 watchdog/1 13 ? 00:01:01 migration/1 14 ? 00:00:56 ksoftirqd/1 16 ? 00:00:00 kworker/1:0H 18 ? 00:00:00 kdevtmpfs 19 ? 00:00:00 netns 20 ? 00:00:00 khungtaskd……省略部分结果 说明：显示root进程用户信息 3. 显示所有进程信息，连带命令行命令： ps -ef 输出：12345678[root@localhost autoAweme]# ps -efUID PID PPID C STIME TTY TIME CMDroot 1 0 0 11月30 ? 00:00:15 /usr/lib/systemd/systemd --swiroot 2 0 0 11月30 ? 00:00:00 [kthreadd]root 3 2 0 11月30 ? 00:00:56 [ksoftirqd/0]root 5 2 0 11月30 ? 00:00:00 [kworker/0:0H]root 7 2 0 11月30 ? 00:01:01 [migration/0]……省略部分结果 4. ps 与grep 常用组合用法，查找特定进程命令： ps -ef|grep uwsgi 输出：123456[root@localhost autoAweme]# ps -ef|grep uwsgiroot 30568 795 0 12月01 ? 00:00:19 /home/hc/project/envs/pgc/bin/uwsgi --ini /home/hc/project/pgc.iniroot 30578 30568 0 12月01 ? 00:00:00 /home/hc/project/envs/pgc/bin/uwsgi --ini /home/hc/project/pgc.iniroot 66069 795 1 12:07 ? 00:04:29 /home/hc/project/envs/autoAweme/bin/uwsgi --ini /home/hc/project/autoAweme.iniroot 66096 66069 0 12:07 ? 00:00:01 /home/hc/project/envs/autoAweme/bin/uwsgi --ini /home/hc/project/autoAweme.iniroot 80022 86053 0 16:06 pts/1 00:00:00 grep --color=auto uwsgi 5：将目前属于您自己这次登入的 PID 与相关信息列示出来命令： ps -l 输出： 12345[root@localhost autoAweme]# ps -lF S UID PID PPID C PRI NI ADDR SZ WCHAN TTY TIME CMD4 S 0 85984 80319 0 80 0 - 58596 do_wai pts/1 00:00:00 su4 S 0 86053 85984 0 80 0 - 29208 do_wai pts/1 00:00:01 bash0 R 0 107795 86053 0 80 0 - 38300 - pts/1 00:00:00 ps 说明： 各相关信息的意义： 标志 意义 F 代表这个程序的旗标 (flag)， 4 代表使用者为 super user S 代表这个程序的状态 (STAT)，关于各 STAT 的意义将在内文介绍 UID 程序被该 UID 所拥有 PID 就是这个程序的 ID ！ PPID 则是其上级父程序的ID C CPU 使用的资源百分比 PRI 指进程的执行优先权(Priority的简写)，其值越小越早被执行； NI 这个进程的nice值，其表示进程可被执行的优先级的修正数值。 ADDR 这个是内核函数，指出该程序在内存的那个部分。如果是个 running的程序，一般就是 “-“ SZ 使用掉的内存大小 WCHAN 目前这个程序是否正在运作当中，若为 - 表示正在运作 TTY 登入者的终端机位置 TIME 使用掉的 CPU 时间。 CMD 所下达的指令为何 在预设的情况下， ps 仅会列出与目前所在的 bash shell 有关的 PID 而已，所以， 当我使用 ps -l 的时候，只有三个 PID。 6.列出目前所有的正在内存当中的程序命令： ps aux 输出： 12345678910[root@localhost autoAweme]# ps auxUSER PID %CPU %MEM VSZ RSS TTY STAT START TIME COMMANDroot 1 0.0 0.1 125804 4260 ? Ss 11月30 0:15 /usr/lib/systemd/systemd --switched-root --system --deserialize 22root 2 0.0 0.0 0 0 ? S 11月30 0:00 [kthreadd]root 3 0.0 0.0 0 0 ? S 11月30 0:56 [ksoftirqd/0]root 5 0.0 0.0 0 0 ? S&lt; 11月30 0:00 [kworker/0:0H]root 7 0.0 0.0 0 0 ? S 11月30 1:01 [migration/0]root 8 0.0 0.0 0 0 ? S 11月30 0:00 [rcu_bh]root 9 0.3 0.0 0 0 ? S 11月30 19:02 [rcu_sched]……省略部分结果 说明： 标志 意义 USER 该 process 属于那个使用者账号的 PID 该 process 的号码 %CPU 该 process 使用掉的 CPU 资源百分比 %MEM 该 process 所占用的物理内存百分比 VSZ 该 process 使用掉的虚拟内存量 (Kbytes) RSS 该 process 占用的固定的内存量 (Kbytes) TTY 该 process 是在那个终端机上面运作，若与终端机无关，则显示 ?，另外， tty1-tty6 是本机上面的登入者程序，若为 pts/0 等等的，则表示为由网络连接进主机的程序。 STAT 该程序目前的状态 START 该 process 被触发启动的时间 TIME 该 process 实际使用 CPU 运作的时间 COMMAND 该程序的实际指令 STAT：该程序目前的状态，主要的状态有 ps工具标识进程的5种状态码 D ：不可中断 uninterruptible sleep (usually IO) R ：该程序目前正在运作，或者是可被运作 S ：该程序目前正在睡眠当中 (可说是 idle 状态)，但可被某些讯号 (signal) 唤醒。 T ：该程序目前正在侦测或者是停止了 Z ：该程序应该已经终止，但是其父程序却无法正常的终止他，造成 zombie (疆尸) 程序的状态 7.以类似进程树的结构显示命令： ps -axjf 输出： 12345678910111213[root@localhost autoAweme]# ps -axjf PPID PID PGID SID TTY TPGID STAT UID TIME COMMAND 0 2 0 0 ? -1 S 0 0:00 [kthreadd] 2 3 0 0 ? -1 S 0 0:57 \_ [ksoftirqd/0] 2 5 0 0 ? -1 S&lt; 0 0:00 \_ [kworker/0:0H] 2 7 0 0 ? -1 S 0 1:02 \_ [migration/0]……省略部分结果 1 80310 2416 2416 ? -1 Sl 1000 0:25 /usr/libexec/gnome-terminal-server 80310 80318 2416 2416 ? -1 S 1000 0:00 \_ gnome-pty-helper 80310 80319 80319 80319 pts/1 28727 Ss 1000 0:00 \_ bash 80319 85984 85984 80319 pts/1 28727 S 0 0:00 \_ su 85984 86053 86053 80319 pts/1 28727 S 0 0:01 \_ bash 86053 28727 28727 80319 pts/1 28727 R+ 0 0:00 \_ ps -axjf 8. pstree命令更优雅的树状显示pstree命令以树状图显示进程间的关系（display a tree of processes）。ps命令可以显示当前正在运行的那些进程的信息，但是对于它们之间的关系却显示得不够清晰。在Linux系统中，系统调用fork可以创建子进程，通过子shell也可以创建子进程，Linux系统中进程之间的关系天生就是一棵树，树的根就是进程PID为1的init进程。 以树状图只显示进程的名字，且相同进程合并显示：命令： pstree 输出：1234567891011121314151617[root@localhost autoAweme]# pstreesystemd─┬─ModemManager───2*[&#123;ModemManager&#125;] ├─NetworkManager───2*[&#123;NetworkManager&#125;] ├─VGAuthService ├─2*[abrt-watch-log] ├─abrtd ├─accounts-daemon───2*[&#123;accounts-daemon&#125;] ├─alsactl ├─at-spi-bus-laun─┬─dbus-daemon │ └─3*[&#123;at-spi-bus-laun&#125;] ├─at-spi2-registr───2*[&#123;at-spi2-registr&#125;] ├─atd ├─auditd─┬─audispd─┬─sedispatch │ │ └─&#123;audispd&#125; │ └─&#123;auditd&#125; ├─avahi-daemon───avahi-daemon……省略部分结果 以树状图显示进程同时还显示PID：命令： pstree -p 输出：1234567891011121314151617181920[root@localhost autoAweme]# pstree -psystemd(1)─┬─ModemManager(686)─┬─&#123;ModemManager&#125;(722) │ └─&#123;ModemManager&#125;(744) ├─NetworkManager(796)─┬─&#123;NetworkManager&#125;(807) │ └─&#123;NetworkManager&#125;(811) ├─VGAuthService(677) ├─abrt-watch-log(698) ├─abrt-watch-log(703) ├─abrtd(684) ├─accounts-daemon(680)─┬─&#123;accounts-daemon&#125;(699) │ └─&#123;accounts-daemon&#125;(742) ├─alsactl(679) ├─at-spi-bus-laun(2636)─┬─dbus-daemon(2641) │ ├─&#123;at-spi-bus-laun&#125;(2637) │ ├─&#123;at-spi-bus-laun&#125;(2638) │ └─&#123;at-spi-bus-laun&#125;(2640) ├─at-spi2-registr(2643)─┬─&#123;at-spi2-registr&#125;(2648) │ └─&#123;at-spi2-registr&#125;(2649) ├─atd(1171)……省略部分结果 以树状图显示进程PID为的进程以及子孙进程，如果有-p参数则同时显示每个进程的PID：命令： pstree [-p] &lt;pid&gt; 输出：12345678910111213141516171819202122[root@localhost autoAweme]# pstree 1244mysqld_safe───mysqld───19*[&#123;mysqld&#125;][root@localhost autoAweme]# pstree -p 1244mysqld_safe(1244)───mysqld(1869)─┬─&#123;mysqld&#125;(1906) ├─&#123;mysqld&#125;(1911) ├─&#123;mysqld&#125;(1912) ├─&#123;mysqld&#125;(1913) ├─&#123;mysqld&#125;(1914) ├─&#123;mysqld&#125;(1915) ├─&#123;mysqld&#125;(1916) ├─&#123;mysqld&#125;(1917) ├─&#123;mysqld&#125;(1918) ├─&#123;mysqld&#125;(1919) ├─&#123;mysqld&#125;(1920) ├─&#123;mysqld&#125;(1926) ├─&#123;mysqld&#125;(1927) ├─&#123;mysqld&#125;(1928) ├─&#123;mysqld&#125;(1929) ├─&#123;mysqld&#125;(1930) ├─&#123;mysqld&#125;(1931) ├─&#123;mysqld&#125;(2081) └─&#123;mysqld&#125;(77714) 以树状图显示进程，相同名称的进程不合并显示，并且会显示命令行参数，如果有-p参数则同时显示每个进程的PID。 命令： pstree -a 输出： 1234567891011121314151617181920[root@localhost autoAweme]# pstree -asystemd --switched-root --system --deserialize 22 ├─ModemManager │ └─2*[&#123;ModemManager&#125;] ├─NetworkManager --no-daemon │ └─2*[&#123;NetworkManager&#125;] ├─VGAuthService -s ├─supervisord /usr/bin/supervisord -c /etc/supervisord.conf │ ├─celery /home/hc/project//envs/autoAweme/bin/celery worker -A celery_worker.celery -l info │ │ ├─celery /home/hc/project//envs/autoAweme/bin/celery worker -A celery_worker.celery -l info │ │ │ └─&#123;celery&#125; │ │ ├─celery /home/hc/project//envs/autoAweme/bin/celery worker -A celery_worker.celery -l info │ │ │ └─&#123;celery&#125; │ │ └─2*[&#123;celery&#125;] │ ├─uwsgi --ini /home/hc/project/pgc.ini │ │ └─uwsgi --ini /home/hc/project/pgc.ini │ └─uwsgi --ini /home/hc/project/autoAweme.ini │ ├─uwsgi --ini /home/hc/project/autoAweme.ini │ └─2*[&#123;uwsgi&#125;]……省略部分结果 注：因为pstree输出的信息可能比较多，所以最好与more/less配合使用,使用上下箭头查看，按q退出。 pstree -p | less 9. 其他实例 可以用 | 管道和 more 连接起来分页查看 命令： ps -aux |more 把所有进程显示出来，并输出到ps001.txt文件 命令： ps -aux &gt; ps001.txt 输出指定的字段 命令： ps -o pid,ppid,pgrp,session,tpgid,comm linux上进程的几种状态下面内容来源于 https://blog.csdn.net/zy512638348/article/details/78193278 R（TASK_RUNNING），可执行状态&amp;运行状态（在run_queue队列里的状态）只有在该状态的进程才可能在CPU上运行，同一时刻可能有多个进程处于可执行状态，这些进程的task_struct结构（进程控制块）被放入对应的CPU的可执行队列中（一个进程最多只能出现在一个CPU的可执行队列中）。进程调度器的任务就是从各个CPU的可执行队列中分别选择一个进程在该CPU上运行。 一般将正在CPU上执行的进程定义为RUNNING状态，而将可执行但是尚未被调度执行的进程定义为READY状态，这两种状态在linux下同一为TASK_RUNNING状态。只要可执行队列不为空，其对应的CPU就不能偷懒，就要执行其中某个进程。一般称此时的CPU“忙碌”。对应的，CPU“空闲”就是指其对应的可执行队列为空，以致于CPU无事可做。 S（TASK_INTERRUPTIBLE）,可中断的睡眠状态，可处理signal处于这个状态的进程因为等待某个事件的发生（比如等待socket连接、等待信号量），而被挂起。这些进程的task_struct结构被放入对应事件的等待队列中。当这些事件发生时（由外部中断触发、或由其他进程触发），对应的等待队列中的一个或多个进程被唤醒。通过ps命令我们会看到，一般情况下，进程列表中的绝大多数进程都处于TASK_INTERRUPTIBLE状态（除非机器的负载很高）。毕竟CPU就那么几个，而进程动辄几十上百个，如果不是绝大多数进程都在睡眠，CPU又怎么响应的过来。 D（TASK_UNINTERRUPTIBLE），不可中断的睡眠状态，可处理signal，有延迟与TASK_INTERRUPTIBLE状态类似，进程也处于睡眠状态，但是此刻的进程是不可中断的。不可中断，指的并不是CPU不响应外部硬件的中断，而是指进程不响应异步信号。绝大多数情况下，进程处在睡眠状态时，总是应该能够响应异步信号的。否则你将惊奇的发现，kill -9竟然杀不死一个正在睡眠的进程了！于是我们也很好理解，为什么ps命令看到的进程几乎不会出现TASK_UNINTERRUPTIBLE状态，而总是TASK_INTERRUPTIBLE状态。 而TASK_UNINTERRUPTIBLE状态存在的意义就在于，内核的某些处理流程是不能被打断的。如果响应异步信号，程序的执行流程中就会被插入一段用于处理异步信号的流程（这个插入流程可能只存在于内核态，也可能延伸到用户态），于是原有的流程被中断了。（参见《linux内核异步中断浅析》）在进程对某些硬件进行操作时（比如进程调用read系统调用对某个设备文件进行读操作，而read系统调用最终执行到对应设备驱动的代码，并与对应的物理设备进行交互），可能需要使用TASK_UNINTERRUPTIBLE状态对进程进行保护，以避免进程与设备交互的过程被打断，造成设备陷入不可控的状态。这种情况下的TASK_UNINTERRUPTIBLE状态总是非常短暂的，通过ps命令基本上不可能捕捉到。 Z（TASK_DEAD-EXIT_ZOMBIE）退出状态，进程称为僵尸进程，不可被kill，即不相应任务信号，无法用SIGKILL杀死向进程发送一个SIGSTOP信号，它就会因响应信号而进入TASK_STOPPED状态（除非该进程本身处于TASK_UNINTERRUPTIBLE状态而不响应信号）。(SIGSTOP与SIGKILL信号一样，是非强制的。不允许用户进程通过signal系统的系统调用重新设置对应的信号处理函数)向进程发送一个SIGCONT信号，可以让其从TASK_STOPPED状态恢复到TASK_RUNNING状态。 当进程正在被跟踪时，它处于TASK_TRACED这个特殊的状态。“正在被跟踪”指的是进程暂停下来，等待跟踪它的进程对它进行操作。比如在gdb中对被跟踪的进程下一个断点，进程在断点处停下来的时候就处于TASK_TRACED状态。而在其他时候，被跟踪的进程还是处于前面提到的那些状态。对于进程本身来说，TASK_STOPPED和TASK_TRACED状态很类似，都是表示进程暂停下来。而TASK_TRACED状态相当于在TASK_STOPPED之上多了一层保护，处于TASK_TRACED状态的进程不能响应SIGCONT信号而被唤醒。只能等到调试进程通过ptrace系统调用执行PTRACE_CONT、PTRACE_DETACH等操作（通过ptrace系统调用的参数指定操作），或调试进程退出，被调试的进程才能恢复TASK_RUNNING状态。 T（TASK_STOPPED or TASK_TRACED）,暂停状态或跟踪状态，不可处理signal,因为根本没有时间片运行代码向进程发送一个SIGSTOP信号，它就会因响应信号而进入TASK_STOPPED状态（除非该进程本身处于TASK_UNINTERRUPTIBLE状态而不响应信号）。(SIGSTOP与SIGKILL信号一样，是非强制的。不允许用户进程通过signal系统的系统调用重新设置对应的信号处理函数)向进程发送一个SIGCONT信号，可以让其从TASK_STOPPED状态恢复到TASK_RUNNING状态。 当进程正在被跟踪时，它处于TASK_TRACED这个特殊的状态。“正在被跟踪”指的是进程暂停下来，等待跟踪它的进程对它进行操作。比如在gdb中对被跟踪的进程下一个断点，进程在断点处停下来的时候就处于TASK_TRACED状态。而在其他时候，被跟踪的进程还是处于前面提到的那些状态。对于进程本身来说，TASK_STOPPED和TASK_TRACED状态很类似，都是表示进程暂停下来。而TASK_TRACED状态相当于在TASK_STOPPED之上多了一层保护，处于TASK_TRACED状态的进程不能响应SIGCONT信号而被唤醒。只能等到调试进程通过ptrace系统调用执行PTRACE_CONT、PTRACE_DETACH等操作（通过ptrace系统调用的参数指定操作），或调试进程退出，被调试的进程才能恢复TASK_RUNNING状态。 X（TASK_DEAD-EXIT_DEAD），退出状态，进程即将被销毁而进程在退出过程中也可能不会保留它的task_struct。比如这个进程是多线程程序中被detach过的进程（进程？线程？参见《linux线程浅析》）。或者父进程通过设置SIGCHLD信号的handler为SIG_IGN，显式的忽略了SIGCHLD信号。（这是posix的规定，尽管子进程的退出信号可以被设置为SIGCHLD以外的其他信号。）此时，进程将被置于EXIT_DEAD退出状态，这意味着接下来的代码立即就会将该进程彻底释放。所以EXIT_DEAD状态是非常短暂的，几乎不可能通过ps命令捕捉到。 进程的初始状态进程是通过fork系列的系统调用（fork、clone、vfork）来创建的，内核（或内核模块）也可以通过kernel_thread函数创建内核进程。这些创建子进程的函数本质上都完成了相同的功能——将调用进程复制一份，得到子进程。（可以通过选项参数来决定各种资源是共享、还是私有。）那么既然调用进程处于TASK_RUNNING状态（否则，它若不是正在运行，又怎么进行调用？），则子进程默认也处于TASK_RUNNING状态。另外，在系统调用调用clone和内核函数kernel_thread也接受CLONE_STOPPED选项，从而将子进程的初始状态置为 TASK_STOPPED。 进程状态变迁进程自创建以后，状态可能发生一系列的变化，直到进程退出。而尽管进程状态有好几种，但是进程状态的变迁却只有两个方向——从TASK_RUNNING状态变为非TASK_RUNNING状态、或者从非TASK_RUNNING状态变为TASK_RUNNING状态。也就是说，如果给一个TASK_INTERRUPTIBLE状态的进程发送SIGKILL信号，这个进程将先被唤醒（进入TASK_RUNNING状态），然后再响应SIGKILL信号而退出（变为TASK_DEAD状态）。并不会从TASK_INTERRUPTIBLE状态直接退出（至少发送一个SIGCHLD信号需要活着吧）。 进程从非TASK_RUNNING状态变为TASK_RUNNING状态，是由别的进程（也可能是中断处理程序）执行唤醒操作来实现的。执行唤醒的进程设置被唤醒进程的状态为TASK_RUNNING，然后将其task_struct结构加入到某个CPU的可执行队列中。于是被唤醒的进程将有机会被调度执行。 而进程从TASK_RUNNING状态变为非TASK_RUNNING状态，则有两种途径：1、响应信号而进入TASK_STOPED状态、或TASK_DEAD状态；2、执行系统调用主动进入TASK_INTERRUPTIBLE状态（如nanosleep系统调用）、或TASK_DEAD状态（如exit系统调用）；或由于执行系统调用需要的资源得不到满足，而进入TASK_INTERRUPTIBLE状态或TASK_UNINTERRUPTIBLE状态（如select系统调用）。显然，这两种情况都只能发生在进程正在CPU上执行的情况下。]]></content>
      <categories>
        <category>linux每日命令</category>
      </categories>
      <tags>
        <tag>linux命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux每日命令(33)：diff命令]]></title>
    <url>%2F2018%2F12%2F03%2Flinux%E6%AF%8F%E6%97%A5%E5%91%BD%E4%BB%A4(33)%EF%BC%9Adiff%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[diff 命令是 linux上非常重要的工具，用于比较文件的内容，特别是比较两个版本不同的文件以找到改动的地方。diff在命令行中打印每一个行的改动。最新版本的diff还支持二进制文件。diff程序的输出被称为补丁 (patch)，因为Linux系统中还有一个patch程序，可以根据diff的输出将a.c的文件内容更新为b.c。diff是svn、cvs、git等版本控制工具不可或缺的一部分。 一. 命令格式diff [参数] [文件1或目录1] [文件2或目录2] 二．命令功能diff命令能比较单个文件或者目录内容。如果指定比较的是文件，则只有当输入为文本文件时才有效。以逐行的方式，比较文本文件的异同处。如果指定比较的是目录的的时候，diff 命令会比较两个目录下名字相同的文本文件。列出不同的二进制文件、公共子目录和只在一个目录出现的文件。 三. 命令参数 参数 描述 -行数 指定要显示多少行的文本。此参数必须与-c或-u参数一并使用。 -a 或–text ，diff预设只会逐行比较文本文件。 -b 或–ignore-space-change ，不检查空格字符的不同。 -B 或–ignore-blank-lines ，不检查空白行。 -c 显示全部内文，并标出不同之处。 -C行数 或–context行数 与执行”-c-行数”指令相同。 -d 或–minimal ， 使用不同的演算法，以较小的单位来做比较。 -D 或ifdef ， 此参数的输出格式可用于前置处理器巨集。 -e 或–ed ， 此参数的输出格式可用于ed的script文件。 -f 或-forward-ed ，输出的格式类似ed的script文件，但按照原来文件的顺序来显示不同处。 -H 或–speed-large-files ， 比较大文件时，可加快速度。 -l 或–ignore-matching-lines ，若两个文件在某几行有所不同，而这几行同时都包含了选项中指定的字符或字符串，则不显示这两个文件的差异。 -i 或–ignore-case ，不检查大小写的不同。 -l 或–paginate ，将结果交由pr程序来分页。 -n 或–rcs ，将比较结果以RCS的格式来显示。 -N 或–new-file ，在比较目录时，若文件A仅出现在某个目录中，预设会显示：Only in目录：文件A若使用-N参数，则diff会将文件A与一个空白的文件比较。 -p 若比较的文件为C语言的程序码文件时，显示差异所在的函数名称。 -P 或–unidirectional-new-file ，与-N类似，但只有当第二个目录包含了一个第一个目录所没有的文件时，才会将这个文件与空白的文件做比较。 -q 或–brief ， 仅显示有无差异，不显示详细的信息。 -r 或–recursive ，比较子目录中的文件。 -s 或–report-identical-files， 若没有发现任何差异，仍然显示信息。 -S 或–starting-file ， 在比较目录时，从指定的文件开始比较。 -t 或–expand-tabs ，在输出时，将tab字符展开。 -T 或–initial-tab ，在每行前面加上tab字符以便对齐。 -u ,-U或–unified= ， 以合并的方式来显示文件内容的不同。 -v 或–version ， 显示版本信息。 -w 或–ignore-all-space ， 忽略全部的空格字符。 -W 或–width ， 在使用-y参数时，指定栏宽。 -x 或–exclude ， 不比较选项中所指定的文件或目录。 -X 或–exclude-from ， 您可以将文件或目录类型存成文本文件，然后在=中指定此文本文件。 -y 或–side-by-side ，以并列的方式显示文件的异同之处。 –help 显示帮助。 –left-column 在使用-y参数时，若两个文件某一行内容相同，则仅在左侧的栏位显示该行内容。 –suppress-common-lines 在使用-y参数时，仅显示不同之处。 四. 使用实例1. 比较两个文件命令： diff 2.log 1.log 输出：1234567891011121314151617181920[root@localhost test]# cat 1.log 第一行第二行我是log1第3行第四行第五行第六行[root@localhost test]# cat 2.log第一行第二行我是log2第3行第四行[root@localhost test]# diff 2.log 1.log 3c3&lt; 我是log2第3行---&gt; 我是log1第3行4a5,6&gt; 第五行&gt; 第六行 说明： 上面的”3c3”表示1.log和2.log文件在3行内容有所不同；”4a5,6”表示第2个文件比第1个文件多了第5和6行。 diff 的normal 显示格式有三种提示: a - add c - change d - delete 2. 并排格式输出命令: diff 2.log 1.log -y -W 50 输出: 1234567891011121314[root@localhost test]# diff 2.log 1.log -y -W 50第一行 第一行第二行 第二行我是log2第3行 | 我是log1第3行第四行 第四行 &gt; 第五行 &gt; 第六行[root@localhost test]# diff 1.log 2.log -y -W 50第一行 第一行第二行 第二行我是log1第3行 | 我是log2第3行第四行 第四行第五行 &lt;第六行 &lt; 说明： “|”表示前后2个文件内容有不同 “&lt;”表示后面文件比前面文件少了1行内容 “&gt;”表示后面文件比前面文件多了1行内容 3. 上下文格式输出命令: diff 2.log 1.log -c 输出:1234567891011121314151617181920212223242526272829303132[root@localhost test]# diff 2.log 1.log -c*** 2.log 2018-12-03 10:21:24.914596171 +0800--- 1.log 2018-12-03 10:22:30.922589959 +0800****************** 1,4 **** 第一行 第二行! 我是log2第3行 第四行--- 1,6 ---- 第一行 第二行! 我是log1第3行 第四行+ 第五行+ 第六行[root@localhost test]# diff 1.log 2.log -c*** 1.log 2018-12-03 10:22:30.922589959 +0800--- 2.log 2018-12-03 10:21:24.914596171 +0800****************** 1,6 **** 第一行 第二行! 我是log1第3行 第四行- 第五行- 第六行--- 1,4 ---- 第一行 第二行! 我是log2第3行 第四行 说明： 这种方式在开头两行作了比较文件的说明，这里有三中特殊字符： “＋” 比较的文件的后者比前着多一行 “－” 比较的文件的后者比前着少一行 “！” 比较的文件两者有差别的行 4. 统一格式输出命令: diff 2.log 1.log -c 输出: 1234567891011[root@localhost test]# diff 2.log 1.log -u--- 2.log 2018-12-03 10:21:24.914596171 +0800+++ 1.log 2018-12-03 10:22:30.922589959 +0800@@ -1,4 +1,6 @@ 第一行 第二行-我是log2第3行+我是log1第3行 第四行+第五行+第六行 说明： 它的第一部分，也是文件的基本信息： — 2.log 2018-12-03 10:21:24.914596171 +0800+++ 1.log 2018-12-03 10:22:30.922589959 +0800 “—“表示变动前的文件，”+++”表示变动后的文件。 第二部分，变动的位置用两个@作为起首和结束。 @@ -1,4 +1,6 @@ 前面的”-1,4”分成三个部分：减号表示第一个文件（即2.log），”1”表示第1行，”4”表示连续4行。合在一起，就表示下面是第一个文件从第1行开始的连续4行。同样的，”+1,6”表示变动后，成为第二个文件从第1行开始的连续6行。 5. 比较文件夹不同命令: diff test test2 输出:12345678910111213141516[root@localhost hc]# ls test1.log 2.log 2.log.back[root@localhost hc]# ls test21.log 2.log[root@localhost hc]# diff test test2diff test/1.log test2/1.log5,6d4&lt; 第五行&lt; 第六行diff test/2.log test2/2.log4c4,5&lt; 第四行---&gt; 第四行1&gt; 第五行Only in test: 2.log.back 6. 比较两个文件不同，并生产补丁命令： diff -ruN 2.log.back 2.log &gt; patch.log 输出：123456789101112131415161718192021222324[root@localhost test]# cat 2.log第一行第二行我是log2第3行第四行[root@localhost test]# cat 2.log.back 第一行第二行我是log2第3行[root@localhost test]# diff -ruN 2.log.back 2.log &gt; patch.log[root@localhost test]# lltotal 16-rw-r--r-- 1 root root 68 12月 3 10:22 1.log-rw-r--r-- 1 root root 48 12月 3 10:21 2.log-rw-r--r-- 1 root root 38 12月 3 11:06 2.log.back-rw-r--r-- 1 root root 165 12月 3 11:06 patch.log[root@localhost test]# cat patch.log --- 2.log.back 2018-12-03 11:06:25.587342012 +0800+++ 2.log 2018-12-03 10:21:24.914596171 +0800@@ -1,3 +1,4 @@ 第一行 第二行 我是log2第3行+第四行 7. 打补丁命令： patch 2.log.back patch.log 输出：1234567891011[root@localhost test]# cat 2.log.back 第一行第二行我是log2第3行[root@localhost test]# patch 2.log.back patch.log patching file 2.log.back[root@localhost test]# cat 2.log.back 第一行第二行我是log2第3行第四行]]></content>
      <categories>
        <category>linux每日命令</category>
      </categories>
      <tags>
        <tag>linux命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux每日命令(32)：gzip命令]]></title>
    <url>%2F2018%2F12%2F01%2Flinux%E6%AF%8F%E6%97%A5%E5%91%BD%E4%BB%A4(32)%EF%BC%9Agzip%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[减少文件大小有两个明显的好处，一是可以减少存储空间，二是通过网络传输文件时，可以减少传输的时间。gzip是在Linux系统中经常使用的一个对文件进行压缩和解压缩的命令，既方便又好用。gzip不仅可以用来压缩大的、较少使用的文件以节省磁盘空间，还可以和tar命令一起构成Linux操作系统中比较流行的压缩文件格式。据统计，gzip命令对文本文件有60%～70%的压缩率。 一．命令格式gzip [参数] [文件或者目录] 二. 命令功能gzip是个使用广泛的压缩程序，文件经它压缩过后，其名称后面会多出”.gz”的扩展名 三. 命令参数必要参数 参数 描述 -a 或–ascii , 使用ASCII文字模式。 -c 或–stdout或–to-stdout ，把压缩后的文件输出到标准输出设备，不去变动原始文件。 -d 或–decompress或—-uncompress，解开压缩文件 -r 或–recursive ， 递归处理，将指定目录下的所有文件及子目录一并处理。 -f 或–force ， 强行压缩文件。不理会文件名称或硬连接是否存在以及该文件是否为符号连接。 -l 或–list， 列出压缩文件的相关信息。 -n 或–no-name ,压缩文件时，不保存原来的文件名称及时间戳记。 -N 或–name ，压缩文件时，保存原来的文件名称及时间戳记。 -q 或–quiet ， 不显示警告信息。 -S&lt;压缩字尾字符串&gt; 或—-suffix&lt;压缩字尾字符串&gt; ，更改压缩字尾字符串。 -t 或–test ， 测试压缩文件是否正确无误。 -v 或–verbose ，显示指令执行过程 -V 或–version ， 显示版本信息。 -L 或–license 显示版本与版权信息。 -num 用指定的数字num调整压缩的速度，-1或–fast表示最快压缩方法（低压缩比），-9或–best表示最慢压缩方法（高压缩比）。系统缺省值为6。 -h 或–help ， 在线帮助。 四. 使用实例1：将当前目录下的每个文件压缩成.gz文件命令： gzip * 输出： 1234567891011[root@localhost test]# lltotal 12-rw-r--r-- 1 root root 2117 12月 1 09:08 1.log-rw-r--r-- 1 root root 2199 12月 1 09:08 2.log-rw-r--r-- 1 root root 2117 12月 1 09:08 3.log[root@localhost test]# gzip *[root@localhost test]# lltotal 12-rw-r--r-- 1 root root 1189 12月 1 09:08 1.log.gz-rw-r--r-- 1 root root 1245 12月 1 09:08 2.log.gz-rw-r--r-- 1 root root 1189 12月 1 09:08 3.log.gz 说明：将test目录下的每个文件压缩成.gz文件 2. 将当前目录下的每个压缩的文件解压，并列出详细信息命令： gzip -dv * 输出：123456789101112131415161718[root@localhost test]# touch 4.log[root@localhost test]# lltotal 12-rw-r--r-- 1 root root 1189 12月 1 09:08 1.log.gz-rw-r--r-- 1 root root 1245 12月 1 09:08 2.log.gz-rw-r--r-- 1 root root 1189 12月 1 09:08 3.log.gz-rw-r--r-- 1 root root 0 12月 1 09:17 4.log[root@localhost test]# gzip -dv *1.log.gz: 45.0% -- replaced with 1.log2.log.gz: 44.5% -- replaced with 2.log3.log.gz: 45.0% -- replaced with 3.loggzip: 4.log: unknown suffix -- ignored[root@localhost test]# lltotal 12-rw-r--r-- 1 root root 2117 12月 1 09:08 1.log-rw-r--r-- 1 root root 2199 12月 1 09:08 2.log-rw-r--r-- 1 root root 2117 12月 1 09:08 3.log-rw-r--r-- 1 root root 0 12月 1 09:17 4.log 说明：将test目录下的每个已压缩的文件进行解压 3. 详细当前目录下的压缩文件的信息，但不进行解压命令： gzip -l * 输出： 1234567891011[root@localhost test]# lltotal 12-rw-r--r-- 1 root root 1189 12月 1 09:08 1.log.gz-rw-r--r-- 1 root root 1245 12月 1 09:08 2.log.gz-rw-r--r-- 1 root root 1189 12月 1 09:08 3.log.gz[root@localhost test]# gzip -l * compressed uncompressed ratio uncompressed_name 1189 2117 45.0% 1.log 1245 2199 44.5% 2.log 1189 2117 45.0% 3.log 3623 6433 44.1% (totals) 说明：详细显示例1中的每个压缩文件的信息，但不进行解压 4. 递归的压缩目录命令： gzip -rv test 输出：123456789101112131415161718[root@localhost test]# lltotal 12-rw-r--r-- 1 root root 2117 12月 1 09:08 1.log-rw-r--r-- 1 root root 2199 12月 1 09:08 2.log-rw-r--r-- 1 root root 2117 12月 1 09:08 3.log[root@localhost test]# cd ..[root@localhost hc]# gzip -v testgzip: test is a directory -- ignored[root@localhost hc]# gzip -rv testtest/1.log: 45.0% -- replaced with test/1.log.gztest/2.log: 44.5% -- replaced with test/2.log.gztest/3.log: 45.0% -- replaced with test/3.log.gz[root@localhost hc]# cd test[root@localhost test]# lltotal 12-rw-r--r-- 1 root root 1189 12月 1 09:08 1.log.gz-rw-r--r-- 1 root root 1245 12月 1 09:08 2.log.gz-rw-r--r-- 1 root root 1189 12月 1 09:08 3.log.gz 说明：这样所有test下面的文件都变成了*.gz，目录依然存在只是目录里面的文件相应变成了*.gz，这就是压缩，和打包不同。因为是对目录操作，所以需要加上-r选项，这样也可以对子目录进行递归了。如果要压缩成一个gz文件，可以先用tar命令对目录进行打包，然后再对打包文件使用gzip命令 5. 递归的解压目录命令： gzip -drv test 输出： 12345678910111213141516[root@localhost test]# lltotal 12-rw-r--r-- 1 root root 1189 12月 1 09:08 1.log.gz-rw-r--r-- 1 root root 1245 12月 1 09:08 2.log.gz-rw-r--r-- 1 root root 1189 12月 1 09:08 3.log.gz[root@localhost test]# cd ..[root@localhost hc]# gzip -drv testtest/1.log.gz: 45.0% -- replaced with test/1.logtest/2.log.gz: 44.5% -- replaced with test/2.logtest/3.log.gz: 45.0% -- replaced with test/3.log[root@localhost hc]# cd test[root@localhost test]# lltotal 12-rw-r--r-- 1 root root 2117 12月 1 09:08 1.log-rw-r--r-- 1 root root 2199 12月 1 09:08 2.log-rw-r--r-- 1 root root 2117 12月 1 09:08 3.log]]></content>
      <categories>
        <category>linux每日命令</category>
      </categories>
      <tags>
        <tag>linux命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux每日命令(31)：tar命令]]></title>
    <url>%2F2018%2F11%2F30%2Flinux%E6%AF%8F%E6%97%A5%E5%91%BD%E4%BB%A4(31)%EF%BC%9Atar%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[tar命令可以为linux的文件和目录创建档案。利用tar，可以为某一特定文件创建档案（备份文件），也可以在档案中改变文件，或者向档案中加入新的文件。tar最初被用来在磁带上创建档案，现在，用户可以在任何设备上创建档案。利用tar命令，可以把一大堆的文件和目录全部打包成一个文件，这对于备份文件或将几个文件组合成为一个文件以便于网络传输是非常有用的。 首先要弄清两个概念：打包和压缩。打包:是指将一大堆文件或目录变成一个总的文件.压缩:则是将一个大的文件通过一些压缩算法变成一个小文件。 为什么要区分这两个概念呢？这源于Linux中很多压缩程序只能针对一个文件进行压缩，这样当你想要压缩一大堆文件时，你得先将这一大堆文件先打成一个包（tar命令），然后再用压缩程序进行压缩（gzip bzip2命令）。 linux下最常用的打包程序就是tar了，使用tar程序打出来的包我们常称为tar包，tar包文件的命令通常都是以.tar结尾的。生成tar包后，就可以用其它的程序来进行压缩。 一．命令格式tar [必要参数] [选择参数] [文件] 二. 命令功能用来压缩和解压文件。tar本身不具有压缩功能。他是调用压缩功能实现的 三. 命令参数必要参数 参数 描述 -A 或–catenate 新增压缩文件到已存在的压缩文件 -B 或–read-full-records，读取数据时重设区块大小。 -c 或–create，建立新的压缩文件 -d 或-diff，记录文件的差别 -r 或–append 新增文件到已存在的压缩文件的结尾部分 -u 或–update 仅置换较压缩文件内的文件更新的文件 -x 或–extrac，从压缩的文件中提取文件 -t 或–list ，列出压缩文件的内容 -z 或–gzip或–ungzip,通过gzip指令解压文件 -j 通过bzip2指令解压文件 -p 或–same-permissions 用原来的文件权限还原文件 -Z 通过compress指令解压文件 -N&lt;日期格式&gt; 或–newer=&lt;日期时间&gt; ，只将较指定日期更新的文件保存到备份文件里。 -v 显示操作过程 -l 文件系统边界设置 -k 或–keep-old-files， 解压文件时，不覆盖已有的文件 -m 或–modification-time ，解压文件时，不变更文件的更改时间 -W 或–verify，压缩文件时，确认文件正确无误 选择参数 参数 描述 -b 设置区块数目 -C 切换到指定目录 -f 指定压缩文件 –help 显示帮助信息 –version 显示版本信息 四. 常见解压、压缩命令tar打包：tar cvf FileName.tar DirName (将目录Dirname及其下面的目录、文件打包成名为FileName.tar的包)解包：tar xvf FileName.tar （注：tar是打包，不是压缩！） .gz压缩： gzip FileName解压1： gunzip FileName.gz解压2： gzip -d FileName.gz .tar.gz 和 .tgz压缩：tar zcvf FileName.tar.gz DirName解压：tar zxvf FileName.tar.gz .bz2压缩： bzip2 -z FileName解压1：bzip2 -d FileName.bz2解压2：bunzip2 FileName.bz2 .tar.bz2压缩：tar jcvf FileName.tar.bz2 DirName解压：tar jxvf FileName.tar.bz2 .bz解压1：bzip2 -d FileName.bz解压2：bunzip2 FileName.bz .tar.bz解压：tar jxvf FileName.tar.bz .Z压缩：compress FileName解压：uncompress FileName.Z .tar.Z压缩：tar Zcvf FileName.tar.Z DirName解压：tar Zxvf FileName.tar.Z .zip压缩：zip FileName.zip DirName解压：unzip FileName.zip .rar压缩：rar a FileName.rar DirName解压：rar x FileName.rar 五. 使用实例1：将文件全部打包成tar包命令： 123456tar -cvf log.tar 1.log tar -zcvf log.tar.gz 1.logtar -jcvf log.tar.bz2 1.log ``` 输出： [root@localhost test]# ll 1.log-rw-r–r– 1 root root 3743 Nov 30 09:51 1.log[root@localhost test]# tar -cvf log.tar 1.log1.log[root@localhost test]# tar -zcvf log.tar.gz 1.log1.log[root@localhost test]# tar -jcvf log.tar.bz2 1.log1.log[root@localhost test]# ll .tar-rw-r–r– 1 root root 10240 Nov 30 09:53 log.tar-rw-r–r– 1 root root 1798 Nov 30 09:55 log.tar.bz2-rw-r–r– 1 root root 1816 Nov 30 09:54 log.tar.gz123456789101112131415161718说明：tar -cvf log.tar 1.log 仅打包，不压缩！ tar -zcvf log.tar.gz 1.log 打包后，以 gzip 压缩 tar -jcvf log.tar.bz2 1.log 打包后，以 bzip2 压缩 在参数 f 之后的文件档名是自己取的，我们习惯上都用 .tar 来作为辨识。 如果加 z 参数，则以 .tar.gz 或 .tgz 来代表 gzip 压缩过的 tar包； 如果加 j 参数，则以 .tar.bz2 来作为tar包名。## 2：查阅上述 tar包内有哪些文件命令： tar -ztvf log.tar.gz输出： [root@localhost test]# tar -ztvf log.tar.gz-rw-r–r– root/root 3743 2018-11-30 09:51 1.log123456789101112说明：由于我们使用 gzip 压缩的log.tar.gz，所以要查阅log.tar.gz包内的文件时，就得要加上 z 这个参数了。## 3：将tar 包解压缩命令： tar -zxvf /home/hc/test/log.tar.gz 输出： [root@localhost test]# cd test2[root@localhost test2]# ls[root@localhost test2]# tar -zxvf /home/hc/test/log.tar.gz1.log[root@localhost test2]# ls1.log123456789101112说明：在预设的情况下，我们可以将压缩档在任何地方解开的,比如此处就是在test2目录下解压了test目录下的log.tar.gz## 4：只解压tar包里的部分文件命令： tar -zxvf /home/hc/test/log123.tar.gz 2.log输出： [root@localhost test2]# cd ../test[root@localhost test]# ls1.log 2.log 3.log log.tar log.tar.bz2 log.tar.gz[root@localhost test]# tar -zcvf log123.tar.gz 1.log 2.log 3.log1.log2.log3.log[root@localhost test]# lltotal 36-rw-r–r– 1 root root 3743 Nov 30 09:51 1.log-rw-r–r– 1 root root 3743 Nov 30 09:51 2.log-rw-r–r– 1 root root 3743 Nov 30 09:51 3.log-rw-r–r– 1 root root 1943 Nov 30 10:07 log123.tar.gz-rw-r–r– 1 root root 10240 Nov 30 10:01 log.tar-rw-r–r– 1 root root 1810 Nov 30 10:01 log.tar.bz2-rw-r–r– 1 root root 1817 Nov 30 10:01 log.tar.gz[root@localhost test]# cd ../test2[root@localhost test2]# ls1.log[root@localhost test2]# tar -ztvf /home/hc/test/log123.tar.gz-rw-r–r– root/root 3743 2018-11-30 09:51 1.log-rw-r–r– root/root 3743 2018-11-30 09:51 2.log-rw-r–r– root/root 3743 2018-11-30 09:51 3.log[root@localhost test2]# tar -zxvf /home/hc/test/log123.tar.gz 2.log2.log[root@localhost test2]# ls1.log 2.log1234567891011说明： 此处是只解压出了log123.tar.gz包里的2.log文件，我们可以通过 tar -ztvf 来查阅 tar 包内的文件名称## 5：在文件夹当中，比某个日期新的文件才备份命令： tar -N "2018/11/30" -zcvf log11.tar.gz .输出： [root@localhost test]# lltotal 0-rw-r–r– 1 root root 0 Nov 30 10:23 1.log-rw-r–r– 1 root root 0 Nov 30 10:23 2.log-rw-r–r– 1 root root 0 Nov 30 10:23 3.log[root@localhost test]# tar -N “2018/11/30” -zcvf log11.tar.gz ./tar: Option –after-date: Treating date `2018/11/30’ as 2018-11-30 00:00:00./1.log./2.log./3.log[root@localhost test]# tar -N “2018/12/30” -zcvf log12.tar.gz ./tar: Option –after-date: Treating date `2018/12/30’ as 2018-12-30 00:00:00tar: ./1.log: file is unchanged; not dumpedtar: ./2.log: file is unchanged; not dumpedtar: ./3.log: file is unchanged; not dumpedtar: ./log11.tar.gz: file is unchanged; not dumped[root@localhost test]# lltotal 8-rw-r–r– 1 root root 0 Nov 30 10:23 1.log-rw-r–r– 1 root root 0 Nov 30 10:23 2.log-rw-r–r– 1 root root 0 Nov 30 10:23 3.log-rw-r–r– 1 root root 128 Nov 30 10:56 log11.tar.gz-rw-r–r– 1 root root 45 Nov 30 10:57 log12.tar.gz[root@localhost test]# tar -tzvf log11.tar.gz-rw-r–r– root/root 0 2018-11-30 10:23 ./1.log-rw-r–r– root/root 0 2018-11-30 10:23 ./2.log-rw-r–r– root/root 0 2018-11-30 10:23 ./3.log[root@localhost test]# tar -tzvf log12.tar.gz[root@localhost test]#1234567891011说明：将当前目录下的更新时间比2018-11-30 00:00:00新的文件或目录进行压缩备份## 6：备份文件夹内容时排除部分文件命令： tar --exclude ./log12.tar.gz -zcvf test.tar.gz ./*输出： [root@localhost test]# ls1.log 2.log 3.log log11.tar.gz log12.tar.gz[root@localhost test]# tar –exclude ./log12.tar.gz -zcvf test.tar.gz ./*./1.log./2.log./3.log./log11.tar.gz[root@localhost test]# tar -tzvf test.tar.gz-rw-r–r– root/root 0 2018-11-30 10:23 ./1.log-rw-r–r– root/root 0 2018-11-30 10:23 ./2.log-rw-r–r– root/root 0 2018-11-30 10:23 ./3.log-rw-r–r– root/root 128 2018-11-30 10:56 ./log11.tar.gz` 说明： 备份压缩当前目录下除log12.tar.gz文件以外的所有文件或目录]]></content>
      <categories>
        <category>linux每日命令</category>
      </categories>
      <tags>
        <tag>linux命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux每日命令(30)：Linux 用户及用户组相关知识]]></title>
    <url>%2F2018%2F11%2F29%2Flinux%E6%AF%8F%E6%97%A5%E5%91%BD%E4%BB%A4(30)%EF%BC%9ALinux%20%E7%94%A8%E6%88%B7%E5%8F%8A%E7%94%A8%E6%88%B7%E7%BB%84%E7%9B%B8%E5%85%B3%E6%96%87%E4%BB%B6%E3%80%81%E5%91%BD%E4%BB%A4%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[一. 用户、用户组概念及其文件结构详解Linux用户只有两个等级：root及非root。Linux中还有一部分用户，如：apache、mysql、nobody、ftp等，这些也都是非root用户，即普通用户。Linux的权限实际是上不同用户所能访问的文件的不同产生的假象。而这些假象的造成，还要涉及到另外一个概念：用户组 一个用户至少要属于一个用户组 一个用户可以属于多个用户组 用户组存在的原因主要还是方便分配权限。而用户本身和权限的差别不是很大，各个用户之间主要的不同是： 是否拥有密码 home目录（普通用户可以有一个以自己用户名命名的home目录，存放的地址是/home/username，root用户的home目录是：/root） shell 像nobody这样用来执行Nginx的工作进程的用户，一般不分配密码和shell，甚至连home目录都没有。 为什么不分配密码？如果设置了密码，程序无法自动使用。由于不会有人使用这个用户登录系统，所以就没有必要分配shell。（备注：其实严格上说是有分配shell，只是分配的shell是/sbin/nologin这个特殊的shell，没有任何其他功能，主要功能是防止你登陆。） 所有用户都可以通过查看/etc/passwd查看。以下为我的系统中的用户信息：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849[hc@localhost ~]$ cat /etc/passwdroot:x:0:0:root:/root:/bin/bashbin:x:1:1:bin:/bin:/sbin/nologindaemon:x:2:2:daemon:/sbin:/sbin/nologinadm:x:3:4:adm:/var/adm:/sbin/nologinlp:x:4:7:lp:/var/spool/lpd:/sbin/nologinsync:x:5:0:sync:/sbin:/bin/syncshutdown:x:6:0:shutdown:/sbin:/sbin/shutdownhalt:x:7:0:halt:/sbin:/sbin/haltmail:x:8:12:mail:/var/spool/mail:/sbin/nologinoperator:x:11:0:operator:/root:/sbin/nologingames:x:12:100:games:/usr/games:/sbin/nologinftp:x:14:50:FTP User:/var/ftp:/sbin/nologinnobody:x:99:99:Nobody:/:/sbin/nologinsystemd-network:x:192:192:systemd Network Management:/:/sbin/nologindbus:x:81:81:System message bus:/:/sbin/nologinpolkitd:x:999:998:User for polkitd:/:/sbin/nologinlibstoragemgmt:x:998:995:daemon account for libstoragemgmt:/var/run/lsm:/sbin/nologinrpc:x:32:32:Rpcbind Daemon:/var/lib/rpcbind:/sbin/nologincolord:x:997:994:User for colord:/var/lib/colord:/sbin/nologingluster:x:996:993:GlusterFS daemons:/var/run/gluster:/sbin/nologinsaslauth:x:995:76:Saslauthd user:/run/saslauthd:/sbin/nologinabrt:x:173:173::/etc/abrt:/sbin/nologinsetroubleshoot:x:994:991::/var/lib/setroubleshoot:/sbin/nologinrtkit:x:172:172:RealtimeKit:/proc:/sbin/nologinpulse:x:171:171:PulseAudio System Daemon:/var/run/pulse:/sbin/nologinrpcuser:x:29:29:RPC Service User:/var/lib/nfs:/sbin/nologinnfsnobody:x:65534:65534:Anonymous NFS User:/var/lib/nfs:/sbin/nologinunbound:x:993:988:Unbound DNS resolver:/etc/unbound:/sbin/nologinchrony:x:992:987::/var/lib/chrony:/sbin/nologinqemu:x:107:107:qemu user:/:/sbin/nologinradvd:x:75:75:radvd user:/:/sbin/nologintss:x:59:59:Account used by the trousers package to sandbox the tcsd daemon:/dev/null:/sbin/nologinusbmuxd:x:113:113:usbmuxd user:/:/sbin/nologingeoclue:x:991:985:User for geoclue:/var/lib/geoclue:/sbin/nologinntp:x:38:38::/etc/ntp:/sbin/nologinsssd:x:990:984:User for sssd:/:/sbin/nologingdm:x:42:42::/var/lib/gdm:/sbin/nologingnome-initial-setup:x:989:983::/run/gnome-initial-setup/:/sbin/nologinsshd:x:74:74:Privilege-separated SSH:/var/empty/sshd:/sbin/nologinavahi:x:70:70:Avahi mDNS/DNS-SD Stack:/var/run/avahi-daemon:/sbin/nologinpostfix:x:89:89::/var/spool/postfix:/sbin/nologintcpdump:x:72:72::/:/sbin/nologinhc:x:1000:1000:hc:/home/hc:/bin/bashnginx:x:988:982:nginx user:/var/cache/nginx:/sbin/nologinredis:x:987:981:Redis Database Server:/var/lib/redis:/sbin/nologinuwsgi:x:986:980:uWSGI daemon user:/run/uwsgi:/sbin/nologinmysql:x:27:27:MariaDB Server:/var/lib/mysql:/sbin/nologinmongod:x:985:979:mongod:/var/lib/mongo:/bin/false 文件的每一行代表着一个用户，每一行由冒号”：”分割成7个字段，其结构如下： 用户名：密码：UID：GID：用户全名：home目录：shell UID： UID 0 root用户 UID 1~999 是占坑用户，即一些无法登录的用户（以前是系统是1~499，最近刚改） UID 1000 以上是正常的可登录用户 GID：前面说了一个用户可以属于多个用户组，但这里只有一个，表示的是专职用户组，即一个用户只有一个专职用户组，其属于其他用户组的关联关系存储在/etc/group 文件中。 其中比较特殊的是密码字段，统一由x代替了，看/etc/passwd就知道一开始Linux是将密码存在这个文件里的，由于考虑到/etc/passwd可以被所有人查看，所以将统一存储到/etc/shadow文件（只有root权限可以访问）中，具体数据如下：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152[hc@localhost ~]$ cat /etc/shadowcat: /etc/shadow: Permission denied[hc@localhost ~]$ sudo cat /etc/shadow[sudo] password for hc: root:$6$yknGgCVbJAppRylr$SY.X4RUN.6dIG8fT9ofTu03/lcUzcfn4pNNeUWwkakZlH4oNF45h8eDYNxsJhz3Gm6/5ovsdJzdJMCZkKDQzs0::0:99999:7:::bin:*:17632:0:99999:7:::daemon:*:17632:0:99999:7:::adm:*:17632:0:99999:7:::lp:*:17632:0:99999:7:::sync:*:17632:0:99999:7:::shutdown:*:17632:0:99999:7:::halt:*:17632:0:99999:7:::mail:*:17632:0:99999:7:::operator:*:17632:0:99999:7:::games:*:17632:0:99999:7:::ftp:*:17632:0:99999:7:::nobody:*:17632:0:99999:7:::systemd-network:!!:17861::::::dbus:!!:17861::::::polkitd:!!:17861::::::libstoragemgmt:!!:17861::::::rpc:!!:17861:0:99999:7:::colord:!!:17861::::::gluster:!!:17861::::::saslauth:!!:17861::::::abrt:!!:17861::::::setroubleshoot:!!:17861::::::rtkit:!!:17861::::::pulse:!!:17861::::::rpcuser:!!:17861::::::nfsnobody:!!:17861::::::unbound:!!:17861::::::chrony:!!:17861::::::qemu:!!:17861::::::radvd:!!:17861::::::tss:!!:17861::::::usbmuxd:!!:17861::::::geoclue:!!:17861::::::ntp:!!:17861::::::sssd:!!:17861::::::gdm:!!:17861::::::gnome-initial-setup:!!:17861::::::sshd:!!:17861::::::avahi:!!:17861::::::postfix:!!:17861::::::tcpdump:!!:17861::::::hc:$6$h7GHf6NOXJgamNHh$gwsxvkU88Puv5Nt5bn14Wj7UsU0DclLoXMi/99sr36lqn4osb6oKRF/AdCszGAjsYeUl6PX66u/SSJ5MhYsMT0::0:99999:7:::nginx:!!:17861::::::redis:!!:17861::::::uwsgi:!!:17861::::::mysql:!!:17861::::::mongod:!!:17862:::::: 其结构如下： 用：分割，从左往右依次为 账户名：账户名与/etc/passwd里面的账户名是一一对应的关系。 密码：这里可以看到3类，分别是奇奇怪怪的字符串、*和！！其中，奇奇怪怪的字符串就是加密过的密码文件。*代表帐号被锁定(即)，!!表示这个密码已经过期了。奇奇怪怪的字符串是以$6$开头的，表明是用SHA-512加密的，$1$ 表明是用MD5加密的、$2$ 是用Blowfish加密的、$5$是用 SHA-256加密的。 修改日期：这个是表明上一次修改密码的日期与1970-1-1相距的天数密码不可改的天数：假如这个数字是8，则8天内不可改密码，如果是0，则随时可以改。 密码需要修改的期限：如果是99999则永远不用改。如果是其其他数字比如12345，那么必须在距离1970-1-1的12345天内修改密码，否则密码失效。 修改期限前N天发出警告：比如你在第五条规定今年6月20号规定密码必须被修改，系统会从距离6-20号的N天前向对应的用户发出警告。 密码过期的宽限：假设这个数字被设定为M，那么帐号过期的M天内修改密码是可以修改的，改了之后账户可以继续使用。 帐号失效日期：假设这个日期为X，与第三条一样，X表示的日期依然是1970-1-1相距的天数，过了X之后，帐号失效。 保留：被保留项，暂时还没有被用上。 再来看看/etc/group文件： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677[hc@localhost ~]$ cat /etc/grouproot:x:0:bin:x:1:daemon:x:2:sys:x:3:adm:x:4:tty:x:5:disk:x:6:lp:x:7:mem:x:8:kmem:x:9:wheel:x:10:cdrom:x:11:mail:x:12:postfixman:x:15:dialout:x:18:floppy:x:19:games:x:20:tape:x:33:video:x:39:ftp:x:50:lock:x:54:audio:x:63:nobody:x:99:users:x:100:utmp:x:22:utempter:x:35:input:x:999:systemd-journal:x:190:systemd-network:x:192:dbus:x:81:polkitd:x:998:printadmin:x:997:cgred:x:996:libstoragemgmt:x:995:rpc:x:32:colord:x:994:dip:x:40:gluster:x:993:ssh_keys:x:992:saslauth:x:76:abrt:x:173:setroubleshoot:x:991:rtkit:x:172:pulse-access:x:990:pulse-rt:x:989:pulse:x:171:rpcuser:x:29:nfsnobody:x:65534:unbound:x:988:chrony:x:987:kvm:x:36:qemuqemu:x:107:radvd:x:75:tss:x:59:libvirt:x:986:usbmuxd:x:113:geoclue:x:985:ntp:x:38:sssd:x:984:gdm:x:42:gnome-initial-setup:x:983:sshd:x:74:avahi:x:70:slocate:x:21:postdrop:x:90:postfix:x:89:tcpdump:x:72:stapusr:x:156:stapsys:x:157:stapdev:x:158:hc:x:1000:hcnginx:x:982:redis:x:981:uwsgi:x:980:mysql:x:27:mongod:x:979: 其结构如下： 组名：用户组密码：GID：用户组内的用户名 正常的使用中很少会用到用户组密码，其存储在/etc/gshadow中。 用户组文件比较特特殊的是“”用户组内的用户名”，其实就是这个组下的用户列表，每个用户之间用逗号“,”分割；本字段可以为空；如果字段为空表示用户组为GID的用户名 普通用户的权限非常的低，就连在系统里安装软件的权限都没有，很多时候可以临时给普通用户以特权，就是sudo（在命令前添加sudo）。比如： sudo cat /etc/shadow 完成后需要您输入root的密码，这样 就可以假借root身份了，centos默认普通用户是没有sudo权限的，这与主要以桌面版为主的Ubuntu和Fedora不同，如需给予用户root特权，就需要更改/etc/sudoers文件，修改内容。 比如我为了给hc用户增加sudo特权，就用root权限，修改/etc/sudoers文件，在root下面加入了hc用户 修改前 12## Allow root to run any commands anywhere root ALL=(ALL) ALL 修改后效果如下123## Allow root to run any commands anywhere root ALL=(ALL) ALLhc ALL=(ALL) ALL 如果要给某个用户组添加sudo特权则为：（与给用户不同的是多了一个%） 12## Allows people in group wheel to run all commands%wheel ALL=(ALL) ALL 另外一种方式是添加不需要输入root密码即有root权限的用户，添加方法如下：1%wheel ALL=(ALL) NOPASSWD: ALL 另外还可以设定到底有哪些执行权限，具体的规则如下：（具体可看sudoers配置文件详解） 授权用户 主机=[(切换到哪些用户或用户组)] [是否需要密码验证] 命令1,[(切换到哪些用户或用户组)] [是否需要密码验证] [命令2],[(切换到哪些用户或用户组)] [是否需要密码验证] [命令3]...... 另外默认情况下第一次使用sudo时，需要输入root密码，如果5分钟内再次执行sudo则无需再输入密码，超过5分钟则要重新输入。这个时间也是可以进行配置的，在sudoers中添加如下内容即可： Defaults:用户名 timestamp_timeout=20 其中单位是分钟，如果设为0，则表示每次都要输入密码。 讲解了这么多，接下来学习下常用的shell命令 二. 常用的用户、用户组shell命令用户相关命令useradd功能： 用来创建用户 语法 ： useradd 选项 用户名 选项： 选项 描述 -d 目录 指定用户主目录，如果此目录不存在，则同时使用-m选项，可以创建主目录，也是用户登入时的启始目录 -g 用户组 指定用户所属的群组 -G 用户组 指定用户所属的附加群组 -u 用户号 指定用户id -e 指定帐号的有效期限 -f 指定在密码过期后多少天即关闭该帐号 -m 自动建立用户的登入目录 -M 不要自动建立用户的登入目录 -n 取消建立以用户名称为名的群组 -r 建立系统帐号 -s Shell文件 指定用户登入后所使用的shell 示例1： useradd –d /home/sam -m sam 添加了一个用户sam，并且他的主目录为/home/sam，没有主目录的时候自动创建。（/home为默认的用户主目录所在的父目录） 示例2： sudo useradd username -m -s /sbin/nologin -d /home/username -g groupname 其中： -s /sbin/nologin 设置不能登陆-d 设置用户主目录-g 用户组-m 创建用户目录 示例3： useradd -s /bin/sh -g group –G adm,root gem 添加一个用户gem，使用的Shell是/bin/sh，主用户组为group，附加组为adm，root。 userdel功能： 用来删除用户 语法： userdel 选项 用户名 -r 把用户的主目录一起删除。 usermod功能： 用来修改用户 语法： usermod 选项 用户名 示例： usermod -s /bin/ksh -d /home/z –g developer sam 将sam用户的Shell改为/bin/ksh，主目录改为/home/z，用户组为developer。 passwd功能： 用来修改用户口令 语法： passwd 选项 用户名 选项： 选项 描述 -l 锁定口令，即禁用账号。 -u 口令解锁。 -d 使账号无口令。 -f 强迫用户下次登录时修改口令。 示例1： 修改用户密码 12345$ passwdOld password:******New password:*******Re-enter new password:******* 假设当前用户是sam，则上面的命令修改该用户自己的口令。 如果是超级用户，可以用下列形式指定任何用户的口令： 1234# passwd samNew password:*******Re-enter new password:******* 示例2： # passwd -d sam 说明： 将用户sam的口令删除，这样用户sam下一次登录时，系统就不再询问口令。 示例3： # passwd -l sam 说明： 锁定sam用户，使其不能登录。 用户组相关命令groupadd功能： 创建用户组 语法： groupadd 选项 用户组 参数： 选项 描述 -g 指定新用户组的组标识号（GID）。 -o 一般与-g选项同时使用，表示新用户组的GID可以与系统已有用户组的GID相同。 示例1: groupadd group1 说明：此命令向系统中增加了一个新组group1，新组的组标识号是在当前已有的最大组标识号的基础上加1。 示例2： groupadd -g 101 group2 说明：此命令向系统中增加了一个新组group2，同时指定新组的组标识号是101。 groupdel功能： 用于删除群组。需要从系统上删除群组时，可用groupdel(group delete)指令来完成这项工作。倘若该群组中仍包括某些用户，则必须先删除这些用户后，方能删除群组。 语法： groupdel [群组名称] 示例： groupdel group2 groupmod功能： 用于更改一个组在系统上的定义 语法： groupmod [-g &lt;群组识别码&gt; &lt;-o&gt;][-n &lt;新群组名称&gt;][群组名称] 选项： 选项 描述 -g –gid GID 修改组的GID号 -n –new-name NEW_GROUP 更改组的组名 -o 与-g配置使用，可以设定不唯一的组ID值 -h –help 获得groupmod命令的使用帮助信息 例子： 假设已存在组testbed,gid为4000 示例： groupmod -n testbed-new testbed 将testbed组名更改为testnbed-new groupmod -g 5000 testbed-new 将testbed-new组的组ID更改为5 三. 综合示例1.建立两个用户组group1和group2，以及三个用户dennis、daniel、abigale，并且将前2个用户分配在group1用户组下，后一个分配在group2用户组下，并给dennis设置密码输出： 12345678910111213141516171819202122232425[root@localhost ~]# groupadd group1[root@localhost ~]# groupadd group2[root@localhost ~]# useradd -g group1 dennis[root@localhost ~]# useradd -g group1 daniel[root@localhost ~]# useradd -g group2 abigale[root@localhost ~]# passwd dennisChanging password for user dennis.New password: BAD PASSWORD: The password fails the dictionary check - it is too simplistic/systematicRetype new password: passwd: all authentication tokens updated successfully.[root@localhost ~]# tail -3 /etc/passwddennis:x:1000:1000::/home/dennis:/bin/bashdaniel:x:1001:1000::/home/daniel:/bin/bashabigale:x:1002:1001::/home/abigale:/bin/bash[root@localhost ~]# tail -3 /etc/groupdocker:x:995:rootgroup1:x:1000:group2:x:1001:[root@localhost ~]# cd /home/[root@localhost home]# lltotal 0drwx------. 2 abigale group2 62 Nov 29 00:36 abigaledrwx------. 2 daniel group1 62 Nov 29 00:36 danieldrwx------. 2 dennis group1 62 Nov 29 00:36 dennis 2.改变abigale的用户组由group2变为group1输出： 12345678910[root@localhost home]# usermod -g group1 abigale[root@localhost home]# lltotal 0drwx------. 2 abigale group1 62 Nov 29 00:36 abigaledrwx------. 2 daniel group1 62 Nov 29 00:36 danieldrwx------. 2 dennis group1 62 Nov 29 00:36 dennis[root@localhost home]# tail -3 /etc/passwddennis:x:1000:1000::/home/dennis:/bin/bashdaniel:x:1001:1000::/home/daniel:/bin/bashabigale:x:1002:1000::/home/abigale:/bin/bash 参考文章：https://www.cnblogs.com/duhuo/p/5892513.htmlhttps://blog.csdn.net/chanrayli/article/details/78998941]]></content>
      <categories>
        <category>linux每日命令</category>
      </categories>
      <tags>
        <tag>linux命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux每日命令(29)：chown命令]]></title>
    <url>%2F2018%2F11%2F28%2Flinux%E6%AF%8F%E6%97%A5%E5%91%BD%E4%BB%A4(29)%EF%BC%9Achown%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[chown将指定文件的拥有者改为指定的用户或组，用户可以是用户名或者用户ID；组可以是组名或者组ID；文件是以空格分开的要改变权限的文件列表，支持通配符。系统管理员经常使用chown命令，在将文件拷贝到另一个用户的名录下之后，让用户拥有使用该文件的权限。 一．命令格式：chown [选项]... [所有者][:[组]] 文件... 二．命令功能：通过chown改变文件的拥有者和群组。在更改文件的所有者或所属群组时，可以使用用户名称和用户识别码设置。普通用户不能将自己的文件改变成其他的拥有者。其操作权限一般为管理员。 三．命令参数： 参数 描述 -c 当发生改变时输出调试信息 -f 忽略错误信息 -h 修复符号链接 -R 处理指定目录以及其子目录下的所有文件 -v 运行时显示详细的处理信息 –dereference 作用于符号链接的指向，而不是符号链接本身 –no-dereference 作用于符号链接本身 –reference=&lt;文件或者目录&gt; 把指定的目录/文件作为参考，把操作的文件/目录设置成参考文件/目录相同拥有者和群组 –help 显示帮助信息 –version 显示版本信息 四．使用实例：1：改变文件的拥有者和群组命令： chown root:mail log1 输出： 12345[root@localhost dir1]# ll log1-rwxrwxr-x. 1 root root 0 Nov 20 18:53 log1[root@localhost dir1]# chown root:mail log1[root@localhost dir1]# ll log1-rwxrwxr-x. 1 root mail 0 Nov 20 18:53 log1 说明： 将log1文件的拥有者设为root，群组设为mail 2：改变文件拥有者和群组命令： chown root: log1 输出： 12345[root@localhost dir1]# ll log1-rwxrwxr-x. 1 root mail 0 Nov 20 18:53 log1[root@localhost dir1]# chown root: log1[root@localhost dir1]# ll log1-rwxrwxr-x. 1 root root 0 Nov 20 18:53 log1 说明： 将log1文件的拥有者和群组均设为root 3：改变文件群组命令： chown :mail log1 输出： 12345[root@localhost dir1]# ll log1-rwxrwxr-x. 1 root root 0 Nov 20 18:53 log1[root@localhost dir1]# chown :mail log1[root@localhost dir1]# ll log1-rwxrwxr-x. 1 root mail 0 Nov 20 18:53 log1 说明： 将log1文件的群组由root改为mail 4：改变指定目录以及其子目录下的所有文件的拥有者和群组命令： chown -R -v root:mail dir2 输出： 123456789101112[root@localhost test]# ll dir2total 0-rwxr--r--. 1 root root 0 Nov 26 19:34 log2-rwxr--r--. 1 root root 0 Nov 26 19:33 log3[root@localhost test]# chown -R -v root:mail dir2changed ownership of ‘dir2/log3’ from root:root to root:mailchanged ownership of ‘dir2/log2’ from root:root to root:mailchanged ownership of ‘dir2’ from root:bin to root:mail[root@localhost test]# ll dir2total 0-rwxr--r--. 1 root mail 0 Nov 26 19:34 log2-rwxr--r--. 1 root mail 0 Nov 26 19:33 log3 说明： 将dir2目录以及其目录下的所有文件的拥有者设置为root，群组设置为mail]]></content>
      <categories>
        <category>linux每日命令</category>
      </categories>
      <tags>
        <tag>linux命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux每日命令(28)：chgrp命令]]></title>
    <url>%2F2018%2F11%2F27%2Flinux%E6%AF%8F%E6%97%A5%E5%91%BD%E4%BB%A4(28)%EF%BC%9Achgrp%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[在linux系统里，文件或目录的权限的掌控以拥有者及所属群组来管理。可以使用chgrp指令取变更文件与目录所属群组，这种方式采用群组名称或群组识别码都可以。Chgrp命令就是change group的缩写！要被改变的组名必须要在/etc/group文件内存在才行。 一．命令格式：chgrp [选项] [组] [文件] 二．命令功能：chgrp命令可采用群组名称或群组识别码的方式改变文件或目录的所属群组。使用权限是超级用户。 三．命令参数： 参数 描述 -c 当发生改变时输出调试信息 -f 不显示错误信息 -R 处理指定目录以及其子目录下的所有文件 -v 运行时显示详细的处理信息 –dereference 作用于符号链接的指向，而不是符号链接本身 –no-dereference 作用于符号链接本身 –reference=&lt;文件或者目录&gt; 根据指定文件改变文件的群组属性 –help 显示帮助信息 –version 显示版本信息 四．使用实例：1：改变文件的群组属性命令： chgrp -v bin log1 输出： 1234567[root@localhost test]# ll log1---xrw-r--. 2 root root 0 Nov 22 03:54 log1[root@localhost test]# chgrp -v bin log1changed group of ‘log1’ from root to bin[root@localhost test]# ll log1---xrw-r--. 2 root bin 0 Nov 22 03:54 log1 说明： 将log1文件由root群组改为bin群组 2：根据指定文件改变文件的群组属性命令： chgrp --reference=log1 dir2 输出： 12345678910111213141516[root@localhost test]# lltotal 0drwxr-xr-x. 4 root root 159 Nov 20 19:24 dir1drwxr-xr-x. 2 root root 30 Nov 26 19:34 dir2---xrw-r--. 2 root bin 0 Nov 22 03:54 log1---xrw-r--. 2 root bin 0 Nov 22 03:54 log1.hard_linklrwxrwxrwx. 1 root root 4 Nov 22 03:54 log1.link -&gt; log1[root@localhost test]# chgrp --reference=log1 dir2[root@localhost test]# lltotal 0drwxr-xr-x. 4 root root 159 Nov 20 19:24 dir1drwxr-xr-x. 2 root bin 30 Nov 26 19:34 dir2---xrw-r--. 2 root bin 0 Nov 22 03:54 log1---xrw-r--. 2 root bin 0 Nov 22 03:54 log1.hard_linklrwxrwxrwx. 1 root root 4 Nov 22 03:54 log1.link -&gt; log1 说明： 改变目录文件dir2 的群组属性，使得目录文件dir2 的群组属性和参考文件log1的群组属性相同 3：改变指定目录以及其子目录下的所有文件的群组属性命令： chgrp -R bin dir1 输出： 123456789101112131415161718192021222324252627282930313233[root@localhost test]# lltotal 0drwxr-xr-x. 4 root root 159 Nov 20 19:24 dir1drwxr-xr-x. 2 root bin 30 Nov 26 19:34 dir2---xrw-r--. 2 root bin 0 Nov 22 03:54 log1---xrw-r--. 2 root bin 0 Nov 22 03:54 log1.hard_linklrwxrwxrwx. 1 root root 4 Nov 22 03:54 log1.link -&gt; log1[root@localhost test]# ll dir1total 44-rwxrwxr-x. 1 root root 0 Nov 20 18:53 log1-rw-r--r--. 1 root root 50 Nov 20 18:56 log2drwxr-xr-x. 2 root root 44 Nov 20 19:35 log3-rw-r--r--. 1 root root 2683 Nov 17 00:23 logging.py-rw-r--r--. 1 root root 3877 Nov 17 00:23 logging.pyc-rw-r--r--. 1 root root 2410 Nov 17 00:23 log.py-rw-r--r--. 1 root root 3640 Nov 17 00:23 log.pycdrwxr-xr-x. 3 root root 30 Nov 17 00:15 logs-rw-r--r--. 1 root root 9679 Nov 17 00:23 log_test.py-rw-r--r--. 1 root root 10246 Nov 17 00:23 log_test.pyc[root@localhost test]# chgrp -R bin dir1[root@localhost test]# ll dir1total 44-rwxrwxr-x. 1 root bin 0 Nov 20 18:53 log1-rw-r--r--. 1 root bin 50 Nov 20 18:56 log2drwxr-xr-x. 2 root bin 44 Nov 20 19:35 log3-rw-r--r--. 1 root bin 2683 Nov 17 00:23 logging.py-rw-r--r--. 1 root bin 3877 Nov 17 00:23 logging.pyc-rw-r--r--. 1 root bin 2410 Nov 17 00:23 log.py-rw-r--r--. 1 root bin 3640 Nov 17 00:23 log.pycdrwxr-xr-x. 3 root bin 30 Nov 17 00:15 logs-rw-r--r--. 1 root bin 9679 Nov 17 00:23 log_test.py-rw-r--r--. 1 root bin 10246 Nov 17 00:23 log_test.pyc 说明： 将dir1目录以及其子目录下的所有文件的群组属性由root改变为bin 4：通过群组识别码改变文件群组属性命令： chgrp -R 0 dir1 输出： 1234567891011121314151617181920212223242526272829[root@localhost test]# cat /etc/grouproot:x:0:bin:x:1:daemon:x:2:sys:x:3:...[root@localhost test]# chgrp -R 0 dir1[root@localhost test]# lltotal 0drwxr-xr-x. 4 root root 159 Nov 20 19:24 dir1drwxr-xr-x. 2 root bin 30 Nov 26 19:34 dir2---xrw-r--. 2 root bin 0 Nov 22 03:54 log1---xrw-r--. 2 root bin 0 Nov 22 03:54 log1.hard_linklrwxrwxrwx. 1 root root 4 Nov 22 03:54 log1.link -&gt; log1[root@localhost test]# ll dir1total 44-rwxrwxr-x. 1 root root 0 Nov 20 18:53 log1-rw-r--r--. 1 root root 50 Nov 20 18:56 log2drwxr-xr-x. 2 root root 44 Nov 20 19:35 log3-rw-r--r--. 1 root root 2683 Nov 17 00:23 logging.py-rw-r--r--. 1 root root 3877 Nov 17 00:23 logging.pyc-rw-r--r--. 1 root root 2410 Nov 17 00:23 log.py-rw-r--r--. 1 root root 3640 Nov 17 00:23 log.pycdrwxr-xr-x. 3 root root 30 Nov 17 00:15 logs-rw-r--r--. 1 root root 9679 Nov 17 00:23 log_test.py-rw-r--r--. 1 root root 10246 Nov 17 00:23 log_test.pyc 说明： 通过群组识别码改变文件群组属性，0为root群组的识别码，具体群组和群组识别码可以去/etc/group文件中查看]]></content>
      <categories>
        <category>linux每日命令</category>
      </categories>
      <tags>
        <tag>linux命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux每日命令(27)：chmod命令]]></title>
    <url>%2F2018%2F11%2F26%2Flinux%E6%AF%8F%E6%97%A5%E5%91%BD%E4%BB%A4(27)%EF%BC%9Achmod%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[chmod命令用于改变linux系统文件或目录的访问权限。用它控制文件或目录的访问权限。该命令有两种用法。一种是包含字母和操作符表达式的文字设定法；另一种是包含数字的数字设定法。 Linux系统中的每个文件和目录都有访问许可权限，用它来确定谁可以通过何种方式对文件和目录进行访问和操作。文件或目录的访问权限分为只读，只写和可执行三种。以文件为例，只读权限表示只允许读其内容，而禁止对其做任何的更改操作。可执行权限表示允许将该文件作为一个程序执行。文件被创建时，文件所有者自动拥有对该文件的读、写和可执行权限，以便于对文件的阅读和修改。用户也可根据需要把访问权限设置为需要的任何组合。有三种不同类型的用户可对文件或目录进行访问：文件所有者，同组用户、其他用户。所有者一般是文件的创建者。所有者可以允许同组用户有权访问文件，还可以将文件的访问权限赋予系统中的其他用户。在这种情况下，系统中每一位用户都能访问该用户拥有的文件或目录。每一文件或目录的访问权限都有三组，每组用三位表示，分别为文件属主的读、写和执行权限；与属主同组的用户的读、写和执行权限；系统中其他用户的读、写和执行权限。当用ls -l命令显示文件或目录的详细信息时，最左边的一列为文件的访问权限。 例如： 命令： ls -al 输出： 12345678[root@localhost test]# ls -altotal 0drwxr-xr-x. 3 root root 69 Nov 23 17:32 .drwxr-xr-x. 5 root root 44 Nov 20 19:24 ..drwxr-xr-x. 4 root root 159 Nov 20 19:24 dir1-rw-r--r--. 2 root root 0 Nov 22 03:54 log1-rw-r--r--. 2 root root 0 Nov 22 03:54 log1.hard_linklrwxrwxrwx. 1 root root 4 Nov 22 03:54 log1.link -&gt; log1 我们以log1为例： -rw-r--r--. 2 root root 0 Nov 22 03:54 log1 第一列共有10个位置，第一个字符指定了文件类型。在通常意义上，一个目录也是一个文件。如果第一个字符是横线，表示是一个非目录的文件。如果是d，表示是一个目录。从第二个字符开始到第十个共9个字符，3个字符一组，分别表示了3组用户对文件或者目录的权限。权限字符用横线代表空许可，r代表只读，w代表写，x代表可执行。 例如： - rw- r-- r-- 表示log1是一个普通文件；log1的属主有读写权限；与log1属主同组的用户只有读权限；其他用户也只有读权限。 确定了一个文件的访问权限后，用户可以利用Linux系统提供的chmod命令来重新设定不同的访问权限。也可以利用chown命令来更改某个文件或目录的所有者。利用chgrp命令来更改某个文件或目录的用户组。 chmod命令是非常重要的，用于改变文件或目录的访问权限。用户用它控制文件或目录的访问权限。chmod命令详细情况如下。 一. 命令格式:chmod [-cfvR] [--help] [--version] mode file #二. 命令功能： 用于改变文件或目录的访问权限，用它控制文件或目录的访问权限。 三. 命令参数：mode : 权限设定字串，格式如下 : [ugoa...][[+-=][rwxX]...][,...] 参数 说明 -c 若该文件权限确实已经更改，才显示其更改动作 -f 若该文件权限无法被更改也不要显示错误讯息 -R 对目前目录下的所有文件与子目录进行相同的权限变更(即以递回的方式逐个变更) -v 运行时显示详细处理信息 选择参数：–reference=&lt;目录或者文件&gt; 设置成具有指定目录或者文件具有相同的权限–version 显示版本信息 权限代号： 参数 说明 r 读权限，用数字4表示 w 写权限，用数字2表示 x 执行权限，用数字1表示 - 删除权限，用数字0表示 s 特殊权限 权限范围： 参数 说明 u 表示该文件的拥有者 g 表示与该文件的拥有者属于同一个群体(group)者 o 表示除了该文件的当前用户或群组之外的用户或者群组 a 所有的用户及群组 该命令有两种用法。一种是包含字母和操作符表达式的文字设定法；另一种是包含数字的数字设定法。 1. 文字设定法:chmod ［who］ ［+ | - | =］ ［mode］ 文件名 2. 数字设定法 我们必须首先了解用数字表示的属性的含义：0表示没有权限，1表示可执行权限，2表示可写权限，4表示可读权限，然后将其相加。所以数字属性的格式应为3个从0到7的八进制数，其顺序是（u）（g）（o）。 例如，如果想让某个文件的属主有“读/写”二种权限，需要把4（可读）+2（可写）＝6（读/写）。 数字设定法的一般形式为： chmod abc 文件名 其中a,b,c各为一个数字，分别表示User、Group、及Other的权限。 r=4，w=2，x=1若要rwx属性则4+2+1=7；若要rw-属性则4+2=6；若要r-x属性则4+1=5。 &lt;权限范围&gt;+&lt;权限设置&gt; 使权限范围内的目录或者文件具有指定的权限&lt;权限范围&gt;-&lt;权限设置&gt; 删除权限范围的目录或者文件的指定权限&lt;权限范围&gt;=&lt;权限设置&gt; 设置权限范围内的目录或者文件的权限为指定的值 四. 使用实例：##1：增加文件所有用户组可执行权限 命令： chmod a+x log1 或 chmod ugo+x log1 输出： 12345[root@localhost test]# ls -l log1-rw-r--r--. 2 root root 0 Nov 22 03:54 log1[root@localhost test]# chmod a+x log1[root@localhost test]# ll log1-rwxr-xr-x. 2 root root 0 Nov 22 03:54 log1 说明： 即设定文件log1的属性为：文件属主（u） 增加执行权限；与文件属主同组用户（g） 增加执行权限；其他用户（o） 增加执行权限。 2：同时修改不同用户权限命令： chmod ug+w,o-x log1 输出： 12345[root@localhost test]# ls -l log1-rwxr-xr-x. 2 root root 0 Nov 22 03:54 log1[root@localhost test]# chmod ug+w,o-x log1[root@localhost test]# ll log1-rwxrwxr--. 2 root root 0 Nov 22 03:54 log1 说明： 设定文件log1的属性为：文件属主（u） 增加写权限;与文件属主同组用户（g） 增加写权限;其他用户（o） 删除执行权限 3：删除文件权限命令： chmod a-x log1 输出： 12345[root@localhost test]# ll log1-rwxrwxr--. 2 root root 0 Nov 22 03:54 log1[root@localhost test]# chmod a-x log1[root@localhost test]# ll log1-rw-rw-r--. 2 root root 0 Nov 22 03:54 log1 说明： 删除所有用户的可执行权限 4：使用“=”设置权限命令： chmod u=x log1 输出：12345[root@localhost test]# ll log1-rw-rw-r--. 2 root root 0 Nov 22 03:54 log1[root@localhost test]# chmod u=x log1[root@localhost test]# ll log1---xrw-r--. 2 root root 0 Nov 22 03:54 log1 说明：将文件log1的所属用户的权限全部取消，并重设为只拥有可执行权限 5：对一个目录及其子目录所有文件添加权限命令： 将目前目录下的所有文件与子目录皆设为任何人可读取 : chmod -R a+r * 指定将目录dir2下的所有文件与子目录皆设为所属用户拥有可执行权限 chmod -R u+x dir2 输出： 123456789[root@localhost test]# ll dir2total 0-rw-r--r--. 1 root root 0 Nov 26 19:34 log2-rw-r--r--. 1 root root 0 Nov 26 19:33 log3[root@localhost test]# chmod -R u+x dir2[root@localhost test]# ll dir2total 0-rwxr--r--. 1 root root 0 Nov 26 19:34 log2-rwxr--r--. 1 root root 0 Nov 26 19:33 log3 说明： 递归地给dir2目录下所有文件和子目录的属主分配可执行权限 6.其他一些实例：命令： chmod 751 file 说明： 给file的属主分配读、写、执行(7)的权限，给file的所在组分配读、执行(5)的权限，给其他用户分配执行(1)的权限 命令： chmod u=rwx,g=rx,o=x file 说明： 上例的另一种形式 命令 chmod =r file 说明： 为所有用户分配读权限 命令： chmod 444 file 说明： 同上例 命令： chmod a-wx,a+r file 说明： 同上例]]></content>
      <categories>
        <category>linux每日命令</category>
      </categories>
      <tags>
        <tag>linux命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux每日命令(26)：Linux文件属性详解]]></title>
    <url>%2F2018%2F11%2F23%2Flinux%E6%AF%8F%E6%97%A5%E5%91%BD%E4%BB%A4(26)%EF%BC%9ALinux%E6%96%87%E4%BB%B6%E5%B1%9E%E6%80%A7%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[Linux 文件或目录的属性主要包括：文件或目录的节点、种类、权限模式、链接数量、所归属的用户和用户组、最近访问或修改的时间等内容。具体情况如下： 命令：ls -lih 输出：12345678910111213[root@localhost test]# ls -lihtotal 051621141 drwxr-xr-x. 4 root root 159 Nov 20 19:24 dir133980025 -rw-r--r--. 1 root root 0 Nov 22 03:54 log133980028 lrwxrwxrwx. 1 root root 4 Nov 22 03:54 log1.link -&gt; log1[root@localhost test]# ln log1 log1.hard_link[root@localhost test]# ls -lihtotal 051621141 drwxr-xr-x. 4 root root 159 Nov 20 19:24 dir133980025 -rw-r--r--. 2 root root 0 Nov 22 03:54 log133980025 -rw-r--r--. 2 root root 0 Nov 22 03:54 log1.hard_link33980028 lrwxrwxrwx. 1 root root 4 Nov 22 03:54 log1.link -&gt; log1[root@localhost test]# 忘记ls 命令参数的，可以参考：linux每日命令(1)：ls命令 说明：第一列：inode 第二列：文件种类和权限； 第三列： 硬链接个数； 第四列： 属主； 第五列：所归属的组； 第六列：文件或目录的大小； 第七列和第八列：最后访问或修改时间； 第九列：文件名或目录名 我们以log1为例： 33980025 -rw-r--r--. 1 root root 0 Nov 22 03:54 log1 inode 的值是：33980025 文件类型：文件类型是-，表示这是一个普通文件； 关于文件的类型，请参考：linux每日命令(25)：Linux文件类型与扩展名 文件权限：文件权限是rw-r–r– ，表示文件属主可读、可写、不可执行，文件所归属的用户组不可写，可读，不可执行，其它用户不可写，可读，不可执行； 硬链接个数： log1这个文件没有硬链接；因为数值是1，就是他本身；(后面我们给他创建了一个硬链接log1.hard_link后，变为了2) 文件属主：也就是这个文件归哪于哪个用户 ，它归于root，也就是第一个root； 文件属组：也就是说，对于这个文件，它归属于哪个用户组，在这里是root用户组； 文件大小：文件大小是0个字节； 访问可修改时间 ：这里的时间是最后访问的时间，最后访问和文件被修改或创建的时间，有时并不是一致的； 当然文档的属性不仅仅包括这些，这些是我们最常用的一些属性。 关于inode：inode 译成中文就是索引节点。每个存储设备或存储设备的分区（存储设备是硬盘、软盘、U盘等等）被格式化为文件系统后，应该有两部份，一部份是inode，另一部份是Block，Block是用来存储数据用的。而inode呢，就是用来存储这些数 据的信息，这些信息包括文件大小、属主、归属的用户组、读写权限等。inode为每个文件进行信息索引，所以就有了inode的数值。操作系统根据指令， 能通过inode值最快的找到相对应的文件。 做个比喻，比如一本书，存储设备或分区就相当于这本书，Block相当于书中的每一页，inode 就相当于这本书前面的目录，一本书有很多的内容，如果想查找某部份的内容，我们可以先查目录，通过目录能最快的找到我们想要看的内容。虽然不太恰当，但还是比较形象。 当我们用ls 查看某个目录或文件时，如果加上-i 参数，就可以看到inode节点了；比如我们前面所说的例子： 12[root@localhost test]# ls -li log133980025 -rw-r--r--. 2 root root 0 Nov 22 03:54 log1 log1 的inode值是 log1 ； 查看一个文件或目录的inode，要通过ls 命令的的 -i参数。]]></content>
      <categories>
        <category>linux每日命令</category>
      </categories>
      <tags>
        <tag>linux命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux每日命令(25)：Linux文件类型与扩展名]]></title>
    <url>%2F2018%2F11%2F22%2Flinux%E6%AF%8F%E6%97%A5%E5%91%BD%E4%BB%A4(25)%EF%BC%9ALinux%E6%96%87%E4%BB%B6%E7%B1%BB%E5%9E%8B%E4%B8%8E%E6%89%A9%E5%B1%95%E5%90%8D%2F</url>
    <content type="text"><![CDATA[Linux文件类型和Linux文件的文件名所代表的意义是两个不同的概念。我们通过一般应用程序而创建的比如file.txt、file.tar.gz ，这些文件虽然要用不同的程序来打开，但放在Linux文件类型中衡量的话，大多是常规文件（也被称为普通文件）。 一. 文件类型Linux文件类型常见的有：普通文件、目录文件、字符设备文件和块设备文件、符号链接文件等，现在我们进行一个简要的说明。 1.普通文件我们用 ls -l 来查看某个文件的属性，可以看到有类似-rwxrwxrwx，值得注意的是第一个符号是 - ，这样的文件在Linux中就是普通文件。这些文件一般是用一些相关的应用程序创建，比如图像工具、文档工具、归档工具… …. 或 cp工具等。这类文件的删除方式是用rm 命令。 另外，依照文件的内容，又大略可以分为： 1.1 纯文本档(ASCII)这是Linux系统中最多的一种文件类型，称为纯文本档是因为内容为我们人类可以直接读到的数据，例如数字、字母等等。 几乎只要我们可以用来做为设定的文件都属于这一种文件类型。 举例来说，你可以用命令： cat ~/.bashrc 来看到该文件的内容。 (cat 是将一个文件内容读出来的指令). 1.2 二进制文件(binary)Linux系统其实仅认识且可以执行二进制文件(binary file)。Linux当中的可执行文件(scripts, 文字型批处理文件不算)就是这种格式的文件。 刚刚使用的命令cat就是一个binary file。 1.3 数据格式文件(data)有些程序在运作的过程当中会读取某些特定格式的文件，那些特定格式的文件可以被称为数据文件 (data file)。举例来说，我们的Linux在使用者登录时，都会将登录的数据记录在 /var/log/wtmp那个文件内，该文件是一个data file，他能够透过last这个指令读出来！ 但是使用cat时，会读出乱码,因为他是属于一种特殊格式的文件 last命令用来显示用户登录信息 2.目录文件当我们在某个目录下执行，看到有类似 drwxr-xr-x ，这样的文件就是目录，目录在Linux是一个比较特殊的文件。注意它的第一个字符是d。创建目录的命令可以用 mkdir 命令，或cp命令，cp可以把一个目录复制为另一个目录。删除用rm 或rmdir命令。 3.字符设备或块设备文件如果你进入/dev目录，列一下文件，会看到类似如下的: 1234[root@localhost log]# ls -al /dev/ttycrw-rw-rw-. 1 root tty 5, 0 Nov 20 18:25 /dev/tty[root@localhost log]# ls -al /dev/sda1 brw-rw----. 1 root disk 8, 1 Nov 20 18:25 /dev/sda1 我们看到/dev/tty的属性是 crw-rw-rw- ，注意前面第一个字符是 c ，这表示字符设备文件。比如猫等串口设备。我们看到 /dev/sda1 的属性是 brw-rw—- ，注意前面的第一个字符是 b，这表示块设备，比如硬盘，光驱等设备。 这个种类的文件，是用mknode来创建，用rm来删除。目前在最新的Linux发行版本中，我们一般不用自己来创建设备文件。因为这些文件是和内核相关联的。 与系统周边及储存等相关的一些文件， 通常都集中在/dev这个目录之下！通常又分为两种： 区块(block)设备档 ：就是一些储存数据， 以提供系统随机存取的接口设备，举例来说，硬盘与软盘等就是啦！ 你可以随机的在硬盘的不同区块读写，这种装置就是成组设备！你可以自行查一下/dev/sda看看， 会发现第一个属性为 b 字符(character)设备文件：亦即是一些串行端口的接口设备， 例如键盘、鼠标等等！这些设备的特色就是一次性读取的，不能够截断输出。 举例来说，你不可能让鼠标跳到另一个画面，而是滑动到另一个地方！第一个属性为 c 4.数据接口文件(sockets)：数据接口文件（或者：套接口文件），这种类型的文件通常被用在网络上的数据承接了。我们可以启动一个程序来监听客户端的要求， 而客户端就可以透过这个socket来进行数据的沟通了。第一个属性为 s ， 最常在/var/run这个目录中看到这种文件类型了。 例如：当我们启动MySQL服务器时，会产生一个mysql.sock的文件。 123[root@localhost ~]# ls -l /var/lib/mysql/mysql.sock srwxrwxrwx 1 mysql mysql 0 Nov 20 18:25 /var/lib/mysql/mysql.sock 注意这个文件的属性的第一个字符是 s。 5.符号链接文件：当我们查看文件属性时，会看到有类似 lrwxrwxrwx,注意第一个字符是l，这类文件是链接文件。是通过ln -s 源文件名 新文件名 。下面是一个例子，表示log1.link是log1的软链接文件。怎么理解呢？这和Windows操作系统中的快捷方式有点相似。 符号链接文件的创建方法举例:123456789[root@localhost test]# touch log1[root@localhost test]# lsdir1 log1[root@localhost test]# ln -s log1 log1.link[root@localhost test]# lltotal 0drwxr-xr-x. 4 root root 159 Nov 20 19:24 dir1-rw-r--r--. 1 root root 0 Nov 22 03:54 log1lrwxrwxrwx. 1 root root 4 Nov 22 03:54 log1.link -&gt; log1 6.数据输送文件（FIFO,pipe）:FIFO也是一种特殊的文件类型，他主要的目的在解决多个程序同时存取一个文件所造成的错误问题。 FIFO是first-in-first-out的缩写。第一个属性为 p 。 二. Linux文件扩展名1.扩展名类型基本上，Linux的文件是没有所谓的扩展名的，一个Linux文件能不能被执行，与他的第一栏的十个属性有关， 与档名根本一点关系也没有。这个观念跟Windows的情况不相同喔！在Windows底下， 能被执行的文件扩展名通常是 .com .exe .bat等等，而在Linux底下，只要你的权限当中具有x的话，例如[ -rwx-r-xr-x ] 即代表这个文件可以被执行。 不过，可以被执行跟可以执行成功是不一样的～举例来说，在root家目录下的install.log 是一个纯文本档，如果经由修改权限成为 -rwxrwxrwx 后，这个文件能够真的执行成功吗？ 当然不行～因为他的内容根本就没有可以执行的数据。所以说，这个x代表这个文件具有可执行的能力， 但是能不能执行成功，当然就得要看该文件的内容. 虽然如此，不过我们仍然希望可以藉由扩展名来了解该文件是什么东西，所以，通常我们还是会以适当的扩展名来表示该文件是什么种类的。底下有数种常用的扩展名： 扩展名 含义 *.sh 脚本或批处理文件 (scripts)，因为批处理文件为使用shell写成的，所以扩展名就编成 .sh *Z, *.tar, *.tar.gz, *.zip, *.tgz 经过打包的压缩文件。这是因为压缩软件分别为 gunzip, tar 等等的，由于不同的压缩软件，而取其相关的扩展名 *.html, *.php 网页相关文件，分别代表 HTML 语法与 PHP 语法的网页文件。 .html 的文件可使用网页浏览器来直接开启，至于 .php 的文件， 则可以透过 client 端的浏览器来 server 端浏览，以得到运算后的网页结果。 基本上，Linux系统上的文件名真的只是让你了解该文件可能的用途而已，真正的执行与否仍然需要权限的规范才行。例如虽然有一个文件为可执行文件，如常见的/bin/ls这个显示文件属性的指令，不过，如果这个文件的权限被修改成无法执行时，那么ls就变成不能执行。 上述的这种问题最常发生在文件传送的过程中。例如你在网络上下载一个可执行文件，但是偏偏在你的 Linux系统中就是无法执行！呵呵！那么就是可能文件的属性被改变了。不要怀疑，从网络上传送到你的 Linux系统中，文件的属性与权限确实是会被改变的。 2.Linux文件名长度限制在Linux底下，使用预设的Ext2/Ext3文件系统时，针对文件名长度限制为： 单一文件或目录的最大容许文件名为 255 个字符 包含完整路径名称及目录 (/) 之完整档名为 4096 个字符 是相当长的档名！我们希望Linux的文件名可以一看就知道该文件在干嘛的， 所以档名通常是很长很长。 3.Linux文件名的字符的限制由于Linux在文字接口下的一些指令操作关系，一般来说，你在设定Linux底下的文件名时， 最好可以避免一些特殊字符比较好！例如底下这些： * ? &gt; &lt; ; &amp; ! [ ] | \ ‘ “ ` ( ) { } 因为这些符号在文字接口下，是有特殊意义的。另外，文件名的开头为小数点“.”时， 代表这个文件为隐藏文件！同时，由于指令下达当中，常常会使用到 -option 之类的选项， 所以你最好也避免将文件档名的开头以 - 或 + 来命名。]]></content>
      <categories>
        <category>linux每日命令</category>
      </categories>
      <tags>
        <tag>linux命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux每日命令(24)：Linux 目录结构]]></title>
    <url>%2F2018%2F11%2F21%2Flinux%E6%AF%8F%E6%97%A5%E5%91%BD%E4%BB%A4(24)%EF%BC%9ALinux%20%E7%9B%AE%E5%BD%95%E7%BB%93%E6%9E%84%2F</url>
    <content type="text"><![CDATA[一. 简介对于每一个Linux学习者来说，了解Linux文件系统的目录结构，是学好Linux的至关重要的一步.，深入了解linux文件目录结构的标准和每个目录的详细功能，对于我们用好linux系统只管重要，下面我们就开始了解一下linux目录结构的相关知识。 当在使用Linux的时候，如果你通过ls –l / 就会发现，在/下包涵很多的目录，比如etc、usr、var、bin … … 等目录，而在这些目录中，我们进去看看，发现也有很多的目录或文件。文件系统在Linux下看上去就象树形结构，所以我们可以把文件系统的结构形象的称为 树形结构。 文件系统的是用来组织和排列文件存取的，所以她是可见的，在Linux中，我们可以通过ls等工具来查看其结构，在Linux系统中，我们见到的都是树形结构；比如操作系统安装在一个文件系统中，他表现为由/ 起始的树形结构。linux文件系统的最顶端是/，我们称/为Linux的root，也就是 Linux操作系统的文件系统。Linux的文件系统的入口就是/，所有的目录、文件、设备都在/之下，/就是Linux文件系统的组织者，也是最上级的领导者。 由于linux是开放源代码，各大公司和团体根据linux的核心代码做各自的操作，编程。这样就造成在根下的目录的不同。这样就造成个人不能使用他人的linux系统的PC。因为你根本不知道一些基本的配置，文件在哪里。。。这就造成了混乱。这就是FHS（Filesystem Hierarchy Standard ）机构诞生的原因。该机构是linux爱好者自发的组成的一个团体，主要是是对linux做一些基本的要求，不至于是操作者换一台主机就成了linux的‘文盲’。 根据FHS(http://www.pathname.com/fhs/)的官方文件指出， 他们的主要目的是希望让使用者可以了解到已安装软件通常放置于那个目录下， 所以他们希望独立的软件开发商、操作系统制作者、以及想要维护系统的用户，都能够遵循FHS的标准。 也就是说，FHS的重点在于规范每个特定的目录下应该要放置什么样子的数据而已。 这样做好处非常多，因为Linux操作系统就能够在既有的面貌下(目录架构不变)发展出开发者想要的独特风格。 事实上，FHS是根据过去的经验一直再持续的改版的，FHS依据文件系统使用的频繁与否与是否允许使用者随意更动， 而将目录定义成为四种交互作用的形态如： 目录类型 示例 可分享的，不变的 /usr (软件放置处)，/opt (第三方软件) 可分享的，可变动的 /var/mail (使用者邮件信箱) ，/var/run (程序相关) 不可分享的，不变的 /etc (配置文件)，/boot (开机与核心档) 不可分享的，可变动的 /var/spool/news (新闻组)，/var/lock (程序相关) 四种类型1. 可分享的(shareable)：可以分享给其他系统挂载使用的目录，所以包括执行文件与用户的邮件等数据， 是能够分享给网络上其他主机挂载用的目录； 2. 不可分享的(unshareable)：自己机器上面运作的装置文件或者是与程序有关的socket文件等， 由于仅与自身机器有关，所以当然就不适合分享给其他主机了。 3. 不变的(static)：有些数据是不会经常变动的，跟随着distribution而不变动。 例如函式库、文件说明文件、系统管理员所管理的主机服务配置文件等等； 4. 可变动的(variable)：经常改变的数据，例如登录文件、一般用户可自行收受的新闻组等。 事实上，FHS针对目录树架构仅定义出三层目录底下应该放置什么数据而已，分别是底下这三个目录的定义： 目录 放置的内容 / (root, 根目录)：与开机系统有关 /usr (unix software resource)：与软件安装/执行有关 /var (variable)：与系统运作过程有关 二. 根目录（/）的意义与内容根目录是整个系统最重要的一个目录，因为不但所有的目录都是由根目录衍生出来的， 同时根目录也与开机/还原/系统修复等动作有关。 由于系统开机时需要特定的开机软件、核心文件、开机所需程序、 函式库等等文件数据，若系统出现错误时，根目录也必须要包含有能够修复文件系统的程序才行。 因为根目录是这么的重要，所以在FHS的要求方面，他希望根目录不要放在非常大的分区， 因为越大的分区内你会放入越多的数据，如此一来根目录所在分区就可能会有较多发生错误的机会。 因此FHS标准建议：根目录(/)所在分区应该越小越好， 且应用程序所安装的软件最好不要与根目录放在同一个分区内，保持根目录越小越好。 如此不但效能较佳，根目录所在的文件系统也较不容易发生问题。说白了，就是根目录和Windows的C盘一个样。 根据以上原因，FHS认为根目录(/)下应该包含如下子目录： 目录 应放置的文件内容 /bin 系统有很多放置执行档的目录，但/bin比较特殊。因为/bin放置的是在单人维护模式下还能够被操作的指令。在/bin底下的指令可以被root与一般帐号所使用，主要有：cat,chmod(修改权限), chown, date, mv, mkdir, cp, bash等等常用的指令。 /boot 主要放置开机会使用到的档案，包括Linux核心档案以及开机选单与开机所需设定档等等。Linux kernel常用的档名为：vmlinuz ，如果使用的是grub这个开机管理程式，则还会存在/boot/grub/这个目录。 /dev 在Linux系统上，任何装置与周边设备都是以档案的型态存在于这个目录当中。 只要通过存取这个目录下的某个档案，就等于存取某个装置。比要重要的档案有/dev/null, /dev/zero, /dev/tty , /dev/lp, / dev/hd, /dev/sd*等等 /etc 系统主要的设定档几乎都放置在这个目录内，例如人员的帐号密码档、各种服务的启始档等等。 一般来说，这个目录下的各档案属性是可以让一般使用者查阅的，但是只有root有权力修改。 FHS建议不要放置可执行档(binary)在这个目录中。 比较重要的档案有：/etc/inittab，/etc/init.d/，/etc/modprobe.conf， /etc/X11/， /etc/fstab， /etc/sysconfig/等等。 另外，其下重要的目录有：/etc/init.d/ ：所有服务的预设启动script都是放在这里的，例如要启动或者关闭iptables的话： /etc/init.d/iptables start、/etc/init.d/ iptables stop /etc/xinetd.d/ ：这就是所谓的super daemon管理的各项服务的设定档目录。/etc/X11/ ：与X Window有关的各种设定档都在这里，尤其是xorg.conf或XF86Config这两个X Server的设定档。 /home 这是系统预设的使用者家目录(home directory)。 在你新增一个一般使用者帐号时，预设的使用者家目录都会规范到这里来。比较重要的是，家目录有两种代号：~ ：代表当前使用者的家目录，而 ~guest：则代表用户名为guest的家目录。 /lib 系统的函式库非常的多，而/lib放置的则是在开机时会用到的函式库，以及在/bin或/sbin底下的指令会呼叫的函式库而已 。 什么是函式库呢？你可以将他想成是外挂，某些指令必须要有这些外挂才能够顺利完成程式的执行之意。 尤其重要的是/lib/modules/这个目录，因为该目录会放置核心相关的模组(驱动程式)。 /media media是媒体的英文，顾名思义，这个/media底下放置的就是可移除的装置。 包括软碟、光碟、DVD等等装置都暂时挂载于此。 常见的档名有：/media/floppy, /media/cdrom等等。 /mnt 如果你想要暂时挂载某些额外的装置，一般建议你可以放置到这个目录中。在古早时候，这个目录的用途与/media相同啦。 只是有了/media之后，这个目录就用来暂时挂载用了。 /opt 这个是给第三方软件放置的目录 。 举例来说，KDE这个桌面管理系统是一个独立的计划，不过他可以安装到Linux系统中，因此KDE的软件就建议放置到此目录下了。 另外，如果你想要自行安装额外的软件(非原本的distribution提供的)，那么也能够将你的软件安装到这里来。 不过，以前的Linux系统中，我们还是习惯放置在/usr/local目录下。 /root 系统管理员(root)的家目录。 之所以放在这里，是因为如果进入单人维护模式而仅挂载根目录时，该目录就能够拥有root的家目录，所以我们会希望root的家目录与根目录放置在同一个分区中。 /sbin Linux有非常多指令是用来设定系统环境的，这些指令只有root才能够利用来设定系统，其他使用者最多只能用来查询而已。放在/sbin底下的为开机过程中所需要的，里面包括了开机、修复、还原系统所需要的指令。至于某些服务器软件，一般则放置到/usr/sbin/当中。至于本机自行安装的软件所产生的系统执行档(system binary)，则放置到/usr/local/sbin/当中了。常见的指令包括：fdisk, fsck, ifconfig, init, mkfs等等。 /srv srv可以视为service的缩写，是一些网路服务启动之后，这些服务所需要取用的资料目录。 常见的服务例如WWW, FTP等等。 举例来说，WWW伺服器需要的网页资料就可以放置在/srv/www/里面。 /tmp 这是让一般使用者或者是正在执行的程序暂时放置档案的地方。这个目录是任何人都能够存取的，所以你需要定期的清理一下。当然，重要资料不可放置在此目录啊。 因为FHS甚至建议在开机时，应该要将/tmp下的资料都删除。 事实上FHS针对根目录所定义的标准就仅限于上表，不过仍旧有些目录也需要我们了解一下，具体如下： 目录 应放置的文件内容 /lost+found 这个目录是使用标准的ext2/ext3档案系统格式才会产生的一个目录，目的在于当档案系统发生错误时，将一些遗失的片段放置到这个目录下。 这个目录通常会在分割槽的最顶层存在，例如你加装一个硬盘于/disk中，那在这个系统下就会自动产生一个这样的目录/disk/lost+found /proc 这个目录本身是一个虚拟文件系统(virtual filesystem)。 他放置的资料都是在内存当中，例如系统核心、行程资讯(process)、周边装置的状态及网络状态等等。因为这个目录下的资料都是在内存当中，所以本身不占任何硬盘空间。比较重要的档案（目录）例如： /proc/cpuinfo, /proc/dma, /proc/interrupts, /proc/ioports, /proc/net/*等等。 /sys 这个目录其实跟/proc非常类似，也是一个虚拟的档案系统，主要也是记录与核心相关的资讯。 包括目前已载入的核心模组与核心侦测到的硬体装置资讯等等。 这个目录同样不占硬盘容量。 除了这些目录的内容之外，另外要注意的是，因为根目录与开机有关，开机过程中仅有根目录会被挂载， 其他分区则是在开机完成之后才会持续的进行挂载的行为。就是因为如此，因此根目录下与开机过程有关的目录， 就不能够与根目录放到不同的分区去。那哪些目录不可与根目录分开呢？有底下这些： 目录 放置的文件 /etc 配置文件 /bin 重要执行档 /dev 所需要的装置文件 /lib 执行档所需的函式库与核心所需的模块 /sbin 重要的系统执行文件 这五个目录千万不可与根目录分开在不同的分区。 二. /usr 目录 的意义与内容依据FHS的基本定义，/usr里面放置的数据属于可分享的与不可变动的(shareable, static)， 如果你知道如何透过网络进行分区的挂载，那么/usr确实可以分享给局域网络内的其他主机来使用。 /usr不是user的缩写，其实usr是Unix Software Resource的缩写， 也就是Unix操作系统软件资源所放置的目录，而不是用户的数据。这点要注意。 FHS建议所有软件开发者，应该将他们的数据合理的分别放置到这个目录下的次目录，而不要自行建立该软件自己独立的目录。 因为是所有系统默认的软件(distribution发布者提供的软件)都会放置到/usr底下，因此这个目录有点类似Windows 系统的C:\Windows\ + C:\Program files\这两个目录的综合体，系统刚安装完毕时，这个目录会占用最多的硬盘容量。 一般来说，/usr的次目录建议有底下这些： 目录 应放置的文件内容 /usr/X11R6/ 为X Window System重要数据所放置的目录，之所以取名为X11R6是因为最后的X版本为第11版，且该版的第6次释出之意。 /usr/bin/ 绝大部分的用户可使用指令都放在这里。请注意到他与/bin的不同之处。(是否与开机过程有关) /usr/include/ c/c++等程序语言的档头(header)与包含档(include)放置处，当我们以tarball方式 (*.tar.gz 的方式安装软件)安装某些数据时，会使用到里头的许多包含档。 /usr/lib/ 包含各应用软件的函式库、目标文件(object file)，以及不被一般使用者惯用的执行档或脚本(script)。 某些软件会提供一些特殊的指令来进行服务器的设定，这些指令也不会经常被系统管理员操作， 那就会被摆放到这个目录下啦。要注意的是，如果你使用的是X86_64的Linux系统， 那可能会有/usr/lib64/目录产生 /usr/local/ 管理员在本机自行安装自己下载的软件(非distribution默认提供者)，建议安装到此目录， 这样会比较便于管理。举例来说，你的distribution提供的软件较旧，你想安装较新的软件但又不想移除旧版， 此时你可以将新版软件安装于/usr/local/目录下，可与原先的旧版软件有分别啦。 你可以自行到/usr/local去看看，该目录下也是具有bin, etc, include, lib…的次目录 /usr/sbin/ 非系统正常运作所需要的系统指令。最常见的就是某些网络服务器软件的服务指令(daemon) /usr/share/ 放置共享文件的地方，在这个目录下放置的数据几乎是不分硬件架构均可读取的数据， 因为几乎都是文本文件嘛。在此目录下常见的还有这些次目录：/usr/share/man：联机帮助文件 /usr/share/doc 软件杂项的文件说明 /usr/share/zoneinfo 与时区有关的时区文件 /usr/src/ 一般源码建议放置到这里，src有source的意思。至于核心原始码则建议放置到/usr/src/linux/目录下。 三. /var 目录的意义与内容：如果/usr是安装时会占用较大硬盘容量的目录，那么/var就是在系统运作后才会渐渐占用硬盘容量的目录。 因为/var目录主要针对常态性变动的文件，包括缓存(cache)、登录档(log file)以及某些软件运作所产生的文件， 包括程序文件(lock file, run file)，或者例如MySQL数据库的文件等等。常见的次目录有： 目录 应放置文件内容 /var/log/message 日志信息，按周自动轮询 /var/log/secure 记录登陆系统存取信息的文件，不管认证成功还是认证失败都会记录 /var/log/wtmp 记录登陆者信息的文件，last,who,w命令信息来源于此 /var/spool/ 这个目录通常放置一些队列数据，所谓的“队列”就是排队等待其他程序使用的数据。 这些数据被使用后通常都会被删除 /var/spool/cron/root 定时器配置文件目录，默认按用户命名 /var/spool/clientmqueue/ 当邮件服务未开启时，所有应发给系统管理员的邮件都将堆放在此 /var/spool/mail/ 系统收到新信会放置到/var/spool/mail/中 /var/tmp 比/tmp 允许的大或需要存在较长时间的临时文件. (虽然系统管理员可能不允许/var/tmp 有很旧的文件.) /var/lib 程序本身执行的过程中，需要使用到的数据文件放置的目录。在此目录下各自的软件应该要有各自的目录。 举例来说，MySQL的数据库放置到/var/lib/mysql/而rpm的数据库则放到/var/lib/rpm去 /var/local /usr/local 中安装的程序的可变数据(即系统管理员安装的程序).注意，如果必要，即使本地安装的程序也会使用其他/var 目录，例如/var/lock . /var/lock 锁定文件.许多程序遵循在/var/lock 中产生一个锁定文件的约定，以支持他们正在使用某个特定的设备或文件.其他程序注意到这个锁定文件，将不试图使用这个设备或文件. /var/log/ 各种程序的Log文件，特别是login (/var/log/wtmp log所有到系统的登录和注销) 和syslog (/var/log/messages 里存储所有核心和系统程序信息. /var/log 里的文件经常不确定地增长，应该定期清除. /var/run 保存到下次引导前有效的关于系统的信息文件.例如， /var/run/utmp 包含当前登录的用户的信息. /var/cache/ 应用程序缓存数据。这些数据是在本地生成的一个耗时的I/O或计算结果。应用程序必须能够再生或恢复数据。缓存的文件可以被删除而不导致数据丢失。 由于FHS仅是定义出最上层(/)及次层(/usr, /var)的目录内容应该要放置的文件或目录数据， 因此，在其他次目录层级内，就可以随开发者自行来配置了。 四. 目录树(directory tree)在Linux底下，所有的文件与目录都是由根目录开始的。那是所有目录与文件的源头, 然后再一个一个的分支下来，因此，我们也称这种目录配置方式为：目录树(directory tree), 这个目录树的主要特性有： 目录树的启始点为根目录 (/, root)； 每一个目录不止能使用本地端的 partition 的文件系统，也可以使用网络上的 filesystem 。举例来说， 可以利用 Network File System (NFS) 服务器挂载某特定目录等。 每一个文件在此目录树中的文件名(包含完整路径)都是独一无二的。 如果我们将整个目录树以图的方法来显示，并且将较为重要的文件数据列出来的话，那么目录树架构就如下图所示： 五. 绝对路径与相对路径除了需要特别注意的FHS目录配置外，在文件名部分我们也要特别注意。因为根据档名写法的不同，也可将所谓的路径(path)定义为绝对路径(absolute)与相对路径(relative)。 这两种文件名/路径的写法依据是这样的： 绝对路径：由根目录(/)开始写起的文件名或目录名称， 例如 /home/dmtsai/.bashrc； 相对路径：相对于目前路径的文件名写法。 例如 ./home/dmtsai 或 http://www.cnblogs.com/home/dmtsai/ 等等。反正开头不是 / 就属于相对路径的写法 而你必须要了解，相对路径是以你当前所在路径的相对位置来表示的。举例来说，你目前在 /home 这个目录下， 如果想要进入 /var/log 这个目录时，可以怎么写呢？ cd /var/log (absolute) cd ../var/log (relative) 因为你在 /home 底下，所以要回到上一层 (../) 之后，才能继续往 /var 来移动的，特别注意这两个特殊的目录： . ：代表当前的目录，也可以使用 ./ 来表示； .. ：代表上一层目录，也可以 ../ 来代表。 这个 . 与 .. 目录概念是很重要的，你常常会看到 cd .. 或 ./command 之类的指令下达方式， 就是代表上一层与目前所在目录的工作状态。 实例1：如何先进入/var/spool/mail/目录，再进入到/var/spool/cron/目录内？命令： cd /var/spool/mail cd ../cron 说明： 由于/var/spool/mail与/var/spool/cron是同样在/var/spool/目录中。如此就不需要在由根目录开始写起了。这个相对路径是非常有帮助的，尤其对于某些软件开发商来说。 一般来说，软件开发商会将数据放置到/usr/local/里面的各相对目录。 但如果用户想要安装到不同目录呢？就得要使用相对路径。 实例2：网络文件常常提到类似./run.sh之类的数据，这个指令是什么意义？说明： 由于指令的执行需要变量的支持，若你的执行文件放置在本目录，并且本目录并非正规的执行文件目录(/bin, /usr/bin等为正规)，此时要执行指令就得要严格指定该执行档。./代表本目录的意思，所以./run.sh代表执行本目录下， 名为run.sh的文件。]]></content>
      <categories>
        <category>linux每日命令</category>
      </categories>
      <tags>
        <tag>linux命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux每日命令(23)：find命令之xargs]]></title>
    <url>%2F2018%2F11%2F20%2Flinux%E6%AF%8F%E6%97%A5%E5%91%BD%E4%BB%A4(23)%EF%BC%9Afind%E5%91%BD%E4%BB%A4%E4%B9%8Bxargs%2F</url>
    <content type="text"><![CDATA[在使用 find命令的-exec选项处理匹配到的文件时， find命令将所有匹配到的文件一起传递给exec执行。但有些系统对能够传递给exec的命令长度有限制，这样在find命令运行几分钟之后，就会出现溢出错误。错误信息通常是“参数列太长”或“参数列溢出”。这就是xargs命令的用处所在，特别是与find命令一起使用。 find命令把匹配到的文件传递给xargs命令，而xargs命令每次只获取一部分文件而不是全部，不像-exec选项那样。这样它可以先处理最先获取的一部分文件，然后是下一批，并如此继续下去。 在有些系统中，使用-exec选项会为处理每一个匹配到的文件而发起一个相应的进程，并非将匹配到的文件全部作为参数一次执行；这样在有些情况下就会出现进程过多，系统性能下降的问题，因而效率不高； 而使用xargs命令则只有一个进程。另外，在使用xargs命令时，究竟是一次获取所有的参数，还是分批取得参数，以及每一次获取参数的数目都会根据该命令的选项及系统内核中相应的可调参数来确定。 1. 从当前目录下开始查找的所有文件，然后使用xargs命令来测试它们分别属于哪类文件命令： find . -type f -print |xargs file 输出： 12345[root@localhost test]# lsdir1 log1 log2[root@localhost test]# find . -type f -print |xargs file./log1: empty./log2: ASCII text 2. 从根目录/开始查找名为core的文件或目录，并将查找结果保存到/tmp/core.log 文件中命令： find / -name &quot;core&quot; -print | xargs &gt; /tmp/core.log 输出：1234567[root@localhost tmp]# lsxmlXPathIniteihlTv.c xmlXPathInitLrmz_p.c xmlXPathInitpywFgf.c xmlXPathInitv76QxM.c yum_save_tx.2018-11-15.18-23.5nqJ3w.yumtx yum_save_tx.2018-11-16.23-54.cMoa46.yumtx[root@localhost tmp]# find / -name 'core' -print |xargs &gt; /tmp/core.log[root@localhost tmp]# lscore.log xmlXPathIniteihlTv.c xmlXPathInitLrmz_p.c xmlXPathInitpywFgf.c xmlXPathInitv76QxM.c yum_save_tx.2018-11-15.18-23.5nqJ3w.yumtx yum_save_tx.2018-11-16.23-54.cMoa46.yumtx[root@localhost tmp]# cat core.log /dev/core /proc/sys/net/core /usr/lib/python2.7/site-packages/firewall/core /usr/lib/modules/3.10.0-693.el7.x86_64/kernel/drivers/infiniband/core /usr/lib/modules/3.10.0-693.el7.x86_64/kernel/drivers/memstick/core /usr/lib/modules/3.10.0-693.el7.x86_64/kernel/drivers/mmc/core /usr/lib/modules/3.10.0-693.el7.x86_64/kernel/drivers/net/ethernet/mellanox/mlx5/core /usr/lib/modules/3.10.0-693.el7.x86_64/kernel/drivers/usb/core /usr/lib/modules/3.10.0-693.el7.x86_64/kernel/net/core /usr/lib/modules/3.10.0-693.el7.x86_64/kernel/sound/core /usr/lib/modules/3.10.0-862.14.4.el7.x86_64/kernel/drivers/infiniband/core /usr/lib/modules/3.10.0-862.14.4.el7.x86_64/kernel/drivers/memstick/core /usr/lib/modules/3.10.0-862.14.4.el7.x86_64/kernel/drivers/mmc/core /usr/lib/modules/3.10.0-862.14.4.el7.x86_64/kernel/drivers/net/ethernet/mellanox/mlx5/core /usr/lib/modules/3.10.0-862.14.4.el7.x86_64/kernel/drivers/usb/core /usr/lib/modules/3.10.0-862.14.4.el7.x86_64/kernel/net/core /usr/lib/modules/3.10.0-862.14.4.el7.x86_64/kernel/sound/core 说明：12345&gt; 是定向输出到文件，如果文件不存在，就创建文件；如果文件存在，就将其清空；一般我们备份清理日志文件的时候，就是这种方法：先备份日志，再用&gt;，将日志文件清空（文件大小变成0字节）；&gt;&gt; 这个是将输出内容追加到目标文件中。如果文件不存在，就创建文件；如果文件存在，则将新的内容追加到那个文件的末尾，该文件中的原有内容不受影响。 3:从当前目录下开始查找其他用户具有读、写和执行权限的文件，并收回相应的写权限命令： find . -perm -7 -print | xargs chmod o-w 输出： 1234567891011[root@localhost test]# lltotal 4drwxr-xr-x. 2 root root 6 Nov 20 18:28 dir1-rwxrwxrwx. 1 root root 0 Nov 20 18:28 log1-rw-r--r--. 1 root root 4 Nov 20 18:29 log2[root@localhost test]# find . -perm -7 -print | xargs chmod o-w[root@localhost test]# lltotal 4drwxr-xr-x. 2 root root 6 Nov 20 18:28 dir1-rwxrwxr-x. 1 root root 0 Nov 20 18:28 log1-rw-r--r--. 1 root root 4 Nov 20 18:29 log2 说明：可以看到，执行命令前 log1文件，所属用户 所属组 其他用户均有读、写、执行权限，执行命令后，其他用户没有了写权限，其他权限都还在 4. 用grep命令在从当前目录下开始查找类型为文件，且文件内容中含有hostname的文件命令： find . -type f -print | xargs grep &quot;hostname&quot; 输出：123456789[root@localhost test]# lsdir1 log1 log2[root@localhost test]# cat log1[root@localhost test]# cat log2我是log2hostnamesina=sina.com 哈哈第三行[root@localhost test]# find . -type f -print | xargs grep "hostname"./log2:hostnamesina=sina.com 哈哈 说明：Linux grep命令用于查找文件里符合条件的字符串。 grep指令用于查找内容包含指定的范本样式的文件，如果发现某文件的内容符合所指定的范本样式，预设grep指令会把含有范本样式的那一行显示出来 5. 从当前目录下开始查找名称中以log开头的文件或目录，并将其移动到dir1目录中命令： find . -name &apos;log*&apos; | xargs -i mv {} dir1 输出：12345678[root@localhost test]# lsdir1 log1 log2[root@localhost test]# find . -name 'log*' | xargs -i mv &#123;&#125; dir1[root@localhost test]# lsdir1[root@localhost test]# cd dir1/[root@localhost dir1]# lslog1 log2 说明：{} 花括号代表前面find查找出来的文件名。 6. 从当前目录下开始查找名称中以log开头的文件或目录，并将其移动到当前目录的父级目录中，移动时，进行询问命令： find . -name &quot;log*&quot; | xargs -p -i mv {} .. 输出：1234567891011121314[root@localhost test]# lsdir1[root@localhost test]# cd dir1/[root@localhost dir1]# lslog1 log2 log3[root@localhost dir1]# find . -name "log*" | xargs -p -i mv &#123;&#125; ..mv ./log1 .. ?...ymv ./log2 .. ?...ymv ./log3 .. ?...n[root@localhost dir1]# lslog3[root@localhost dir1]# cd ..[root@localhost test]# lsdir1 log1 log2 说明： -p参数会提示让你确认是否执行后面的命令,y执行，n不执行。 7.find后执行xargs提示xargs: argument line too long解决方法：命令： find . -type f -atime +0 -print0 | xargs -0 -l1 -t rm -f 输出：123[root@localhost dir1]# find . -type f -atime +0 -print0 | xargs -0 -l1 -t rm -frm -f [root@localhost dir1]# 说明：123-l1 是指一次处理一个-t 是指处理之前打印出的命令-print 在每一个输出后会添加一个回车换行符，而-print0则不会。]]></content>
      <categories>
        <category>linux每日命令</category>
      </categories>
      <tags>
        <tag>linux命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux每日命令(22)：find命令参数详解]]></title>
    <url>%2F2018%2F11%2F16%2Flinux%E6%AF%8F%E6%97%A5%E5%91%BD%E4%BB%A4(22)%EF%BC%9Afind%E5%91%BD%E4%BB%A4%E5%8F%82%E6%95%B0%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[一. name选项文件名选项是find命令最常用的选项，要么单独使用该选项，要么和其他选项一起使用。 可以使用某种文件名模式来匹配文件，记住要用引号将文件名模式引起来。 不管当前路径是什么，如果想要在自己的根目录$HOME中查找文件名符合*.log的文件，使用~作为 ‘pathname’参数，波浪号~代表了你的$HOME目录。 find ~ -name &quot;*.log&quot; 想要在当前目录及子目录中查找所有的‘ *.log‘文件，可以用： find . -name &quot;*.log&quot; 想要的当前目录及子目录中查找文件名以一个大写字母开头的文件，可以用： find . -name &quot;[A-Z]*&quot; 想要在/etc目录中查找文件名以host开头的文件，可以用： find /etc -name &quot;host*&quot; 想要查找$HOME目录中的文件，可以用： find ~ -name &quot;*&quot; 要想让系统高负荷运行，就从根目录开始查找所有的文件。 find / -name &quot;*&quot; 如果想在当前目录查找文件名以一个个小写字母开头，最后是4到9加上.log结束的文件： 命令： find . -name &quot;[a-z]*[4-9].log&quot; -print 二. perm选项按照文件权限模式用-perm选项,按文件权限模式来查找文件的话。最好使用十进制的权限表示法。 如在当前目录下查找文件权限位为755的文件，即文件属主可以读、写、执行，其他用户可以读、执行的文件，可以用： find . -perm 755 find -perm，根据文件的权限来查找文件，有三种形式：find -perm modefind -perm -modefind -perm +mode 那么这三者之间有什么区别呢？解释之前首先得简单说一下linux中文件权限位的概念。在linux中文件或目录有三者权限r,w,x，代表的含义分别是读、写、可执行。而一个文件或目录的属性中又包括所属用户u、所属组g、其他o三个部分的属性，分别表示所属用户、所属组、其他用户对这个文件所拥有的权限。看起来大概是这个样子： 所属用户 所属组 其他 rwx rwx rwx 用户在其拥有权限的位上设置1，没有权限的位设置0。如果将每个部分的这些权限位看成二进制数，每个部分可以用3位二进制数表示，最大值为7(2^3-1)，表示可读、可写、可执行。严格的来说，文件权限除了r、w、x以外还有setuid,setgid权限，等下再解释。好了，有了权限位的基础，那么再来看find -perm mode。mode是三个数字表示的，每个数字最大值是7（原因前面解释过了）。find -perm mode ， 表示严格匹配，也就是你的文件权限位转换成对应的十进制数字与mode一模一样，那么匹配成功，需要注意的是如果mode给的数字不足3位，那么前面自动添0(严格的说是不足4位，原因就是前面所说的setuid,setgid，稍后解释) find -perm -mode ， 表示mode中转换成二进制的1在文件权限位里面必须匹配，比如mode=644那么转换成二进制为110 100 100，而被查找的文件的权限位也可以被转换成一个二进制数，两者在位上为1的部分必须完全匹配，而0则不管。例如被查找的文件的权限为转换成二进制数是111 111 111那么这个比如被匹配，而假如是100 100 100那么则不会匹配。所以这个’-‘的作用归结起来就是匹配比mode权限更充足的文件(找不到什么词语来形容了) find -perm +mode ， 与 -mode的区别是+mode只需其中的任意一个1的部分被匹配，-mode是所有1的部分都必须被匹配，同样+mode也不管0位。 现在来解释setuid,setgid，setuid权限是用来使其他用户可以“越权”执行你的命令，而本质上的实现就是在权限检查的时候，在进程的的有效UID里面保存了这个其他用户的UID,所以权限得意验证通过(在这里的 http://www.2cto.com/os/201205/130111.html 注释1里面很简单的介绍了一下)，这些权限用一个新的3位二进制数表示，有4,2,1三种值，4表示有setuid权限，2表示有setgid权限，1表示有粘着位(t)权限（粘着位权限最典型的例子是/tmp，每个用户可以在里面创建、更新、删除自己创建(文件所属用户是自己)的文件，而不能更改别人的文件）。 1234567$ ls -l total 0-rwxrwxrwx 1 fai root 0 Aug 28 15:15 a-rwxr-xr-x 1 fai root 0 Aug 28 15:15 b----rw---- 1 fai root 0 Aug 28 15:15 c-rw-rw-rw- 1 fai root 0 Aug 28 15:15 d-r-xr--r-- 1 fai root 0 Aug 28 15:15 e 对于权限进行十进制转2进制a(777)：111 111 111b(755)：111 101 101c(060)： 000 110 000d(666)：110 110 110e(544)：101 100 100 123456$ find . -perm +006../b./d./a./e mode中的006转为2进制是：000 000110根据部分匹配的原则，只要在第3组中的第一或者第二位出现1就可以了，所以看到e文件101只是匹配了第一位的1，但是也打印了。而a文件111的情况更是符合这个说法了。注意：c文件虽然出现了110，但是不是对应的组，这个匹配是在相应位的。 123$ find . -perm -006./d./a 对于-perm -006，也同样道理去判断，只是这里需要完全匹配，也就是mode的二进制中出现1的地方，目标中也要出现才行需要在最后一组中的第一和第二位同时出现1才能匹配。a(777)：111 111 111d(666)：110 110 110 三. prune选项（此处引用http://blog.sina.com.cn/s/blog_6ad648f30100tqwy.html）查找时忽略指定目录，是要使用-prune选项，但实际上最重要的还是要和path配合。-prune的意义是，当路径字串匹配了path中指定的目录时 候，find命令不进入这个目录查找，所以这个选项使用的关键，还是在path选项上的使用，也就是path选项和其他选项的配合使用，才能最后确定最终 结果。而path，实际上是对路径字串的一个字符匹配，但也并不仅仅只匹配于目录，文件同样可以被匹配，譬如存在一个目录结构。123456./01.txt./02.txt./03.txt./aaa./aaa/04.txt./aaa/05.txt find . -path “./aaa“ -print 匹配中使用通配符，则会输出 123./aaa./aaa/04.txt./aaa/05.txt 而如果是find . -path “./aaa” -print ，严格等于./aaa目录，则只输出 ./aaa 而且*通配符会将路径中的字符”/“也作为普通字符进行贪婪匹配，所以可以匹配到目录以下的文件，所以在使用这个选项时候不要误以为这个只对目录有效，实际上只是一种路径字符匹配工具。 1.查找文件时，忽略某个目录如果加上-prune，则第一个命令效果是： find . -path &quot;./aaa*&quot; -prune -print ./aaa 因为加入了-prune，在匹配这个目录同时禁止进入到这个目录下搜索，于是也就是我们所需要的不进入某个目录查找。 但如何配合其他选项来使用-path 以及-prune呢？以-name为例，下面对于配合使用方法进行一下演示。 我们先来看看纯粹的-name和-path配合使用是什么效果： find -name &quot;*.txt&quot; -path &quot;./aaa&quot; -print 这个命令也相当于 find -name &quot;*.txt&quot; -a -path &quot;./aaa&quot; -print 但一般的-a都被忽略不写。这个命令对于上面的目录结构这个命令执行为空结果。也就是，既要文件名称匹配”.txt”，同时又要其路径字 串匹配”./aaa”，而文件名匹配”.txt”的结果有：12345./01.txt./02.txt./03.txt./aaa/04.txt./aaa/05.txt 路径字串匹配 “./aaa”的只有./aaa二者取and则为空结果，所以上面的命令输出为空。 如果对-path选项加上-prune find -name &quot;*.txt&quot; -path &quot;./aaa&quot; -prune -print 实际上与上面那条命令输出并无区别，只是禁止进入./aaa下匹配而已，但最终的结果仍然是空。 再来看看很多人会误用的结构： find -name &quot;*.txt&quot; -path &quot;./aaa&quot; -prune -o -print 也就是比上一条语句在-print前增加一个-o。但实际上这条命令是将当前目录以及包含./aaa子目录下的所有文件都打印出来。实际上，这个语句先执行-o左侧的语句，find -name “*.txt” -path “./aaa” -prune，因为匹配为空，则执行-o右侧的语句-print，也就是把不匹配左侧的文件名打印出来，既然左侧没有匹配为真的，所以也就是所有的文件都被打印。 这里要留意的是匹配模式项（比如-name “*.txt”, -path ….），关系符（ -a, -o, “,”），与操作符（-print, -exec,- ok)之间的位置关系，特别是操作符在关系符的不同位置上，对于结果也具有决定的作用。 说明： find [-path ..] [expression] 在路径列表的后面的是表达式 -path “test” -prune -o -print 是 -path “test” -a -prune -o -print 的简写表达式按顺序求值, -a 和 -o 都是短路求值，与 shell 的 &amp;&amp; 和 || 类似如果 -path “test” 为真，则求值 -prune , -prune 返回真，与逻辑表达式为真；否则不求值 -prune，与逻辑表达式为假。如果 -path “test” -a -prune 为假，则求值 -print ，-print返回真，或逻辑表达式为真；否则不求值 -print，或逻辑表达式为真。 这个表达式组合特例可以用伪码写为: if -path “test” then -prune else -print 比如一个语句 find -name &quot;*.txt&quot; -print -o -path &quot;./aaa&quot; -prune -print (1) 其实也可以略写为 find -name &quot;*.txt&quot; -o -path &quot;./aaa&quot; -prune 注意第二个语句-o两侧都没有-print，输出结果为：1234./01.txt./02.txt./03.txt./aaa 这是因为find开始执行，遇到第一个-print命令，则会考虑输出，但是输出的时候，则是将剩余所有的匹配项一起进行匹配操作，也就是执行的是 find -name &quot;*.txt&quot; -print -o -path &quot;./aaa&quot; -prune （注意-print命令的位置） 这个命令执行中相当于 find -path &quot;./aaa&quot; -prune -o -name &quot;*.txt&quot; -print 也 就是在匹配过程中，对于包含了-print部分的匹配项是最后匹配的，因此先匹配到了./aaa路径，由于-prune的存在禁止进入这个路径查找，禁止 进入查找，并不会因为-o选项而被逆转，所以左侧匹配了./aaa后，-o右侧则是不匹配./aaa项目剩余的文件继续去匹配-name模式，匹配的结果 最后被-print打印出来，这也就是我们所期待的忽略某个指定目录进行搜索的结果。 但是我们要分析的是命令（1）中的结果，命令（1）在遇到第一个-print命令后并执行了输出，但是这个find命令中还存在第二个-print命令，所以在输出123./01.txt./02.txt./03.txt 结果后，还是要继续执行，要执行最后一个-print命令，下面的执行则相当于执行一个 find -name &quot;*.txt&quot; -o -path &quot;./aaa&quot; -prune -print -o左侧匹配-name “*.txt”，-o到右侧后则是对不能匹配到-name模式的结果，进行-path匹配，输出结果为./aaa 所以（1）命令最终的输出结果就是1234./01.txt./02.txt./03.txt./aaa 。 2. 忽略多个文件夹-a, -o都常见了，但是实际中还可以存在“，“的使用，例如新建一个aaa1目录，其下有08.txt等文件，若执行 $ find -name &quot;*.txt&quot; 1234567./01.txt./02.txt./03.txt./aaa/04.txt./aaa/05.txt./aaa1/08.txt./aaa1/09.txt 若忽略aaa和aaa1目录查找txt文件，则可以写做 $ find -name &quot;*.txt&quot; -print -o -path &quot;./aaa&quot; -prune , -path &quot;./aaa1&quot; -prune （注意&quot;,&quot;两侧的空格不可忽略） 123./01.txt./02.txt./03.txt 这也就是同时忽略几个目录的写法，注意每忽略一个目录，其后都要跟随一个-prune，而不能几个-path公用一个-prune。 其实若没有-prune的使用，也可以忽略某个目录下文件的匹配，譬如 $find -path &quot;./aaa*&quot; -o -name &quot;*.txt&quot; -print 123./01.txt./02.txt./03.txt 同样可以不匹配到./aaa目录下的文件，但是这里实际上是搜索过./aaa目录下的文件并且进行匹对的，只是因为-print在-o的右侧输出，而./aaa下的文件被匹配是在-o的左侧，所以最终的结果是达不到被打印输出的条件。但效率应当是明显低于使用-prune选项。 四. user和nouser 选项1. 在$HOME目录中查找文件属主为hc的文件find ~ -user hc -print 2. 在/etc目录下查找文件属主为hc的文件:命令： find /etc -user hc -print 3. 为了查找属主帐户已经被删除的文件，可以使用-nouser选项。在/home目录下查找所有的这类文件find /home -nouser -print 说明： 这样就能够找到那些属主在/etc/passwd文件中没有有效帐户的文件。在使用-nouser选项时，不必给出用户名； find命令能够为你完成相应的工作。 五．使用group和nogroup选项：就像user和nouser选项一样，针对文件所属于的用户组， find命令也具有同样的选项，为了在/apps目录下查找属于gem用户组的文件，可以用： find /apps -group gem -print 要查找没有有效所属用户组的所有文件，可以使用nogroup选项。下面的find命令从文件系统的根目录处查找这样的文件: find / -nogroup -print 六．按照更改时间或访问时间等查找文件：如果希望按照更改时间来查找文件，可以使用mtime,atime或ctime选项。如果系统突然没有可用空间了，很有可能某一个文件的长度在此期间增长迅速，这时就可以用mtime选项来查找这样的文件。 用减号-来限定更改时间在距今n日以内的文件，而用加号+来限定更改时间在距今n日以前的文件。 希望在系统根目录下查找更改时间在5日以内的文件，可以用： find / -mtime -5 -print 为了在/var/adm目录下查找更改时间在3日以前的文件，可以用: find /var/adm -mtime +3 -print 七．查找比某个文件新或旧的文件：如果希望查找更改时间比某个文件新但比另一个文件旧的所有文件，可以使用-newer选项。 它的一般形式为： newest_file_name ! oldest_file_name 其中，！是逻辑非符号。 1.查找更改时间比文件log1新但比文件log3旧的文件命令： find -newer log1 ! -newer log3 2.查找当前目录下更改时间在比log2文件新的文件命令： find . -newer log2 -print 八．使用type选项：1：在/etc目录下查找所有的目录命令： find /etc -type d -print 2：在当前目录下查找除目录以外的所有类型的文件命令： find . ! -type d -print 3：在/etc目录下查找所有的符号链接文件命令： find /etc -type l -print 九．使用size选项：可以按照文件长度来查找文件，这里所指的文件长度既可以用块（block）来计量，也可以用字节来计量。以字节计量文件长度的表达形式为N c；以块计量文件长度只用数字表示即可。 在按照文件长度查找文件时，一般使用这种以字节表示的文件长度，在查看文件系统的大小，因为这时使用块来计量更容易转换。 1：在当前目录下查找文件长度大于1 M字节的文件命令： find . -size +1000000c -print 2：在/home/apache目录下查找文件长度恰好为100字节的文件:命令： find /home/apache -size 100c -print 3：在当前目录下查找长度超过10块的文件（一块等于512字节）命令： find . -size +10 -print 十．使用depth选项：在使用find命令时，可能希望先匹配所有的文件，再在子目录中查找。使用depth选项就可以使find命令这样做。这样做的一个原因就是，当在使用find命令向磁带上备份文件系统时，希望首先备份所有的文件，其次再备份子目录中的文件。 1：find命令从文件系统的根目录开始，查找一个名为CON.FILE的文件。命令： find / -name &quot;CON.FILE&quot; -depth -print 说明： 它将首先匹配所有的文件然后再进入子目录中查找 十一．使用mount选项： 在当前的文件系统中查找文件（不进入其他文件系统），可以使用find命令的mount选项。 1：从当前目录开始查找位于本文件系统中文件名以XC结尾的文件命令： find . -name &quot;*.XC&quot; -mount -print]]></content>
      <categories>
        <category>linux每日命令</category>
      </categories>
      <tags>
        <tag>linux命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux每日命令(21)：find命令之exec]]></title>
    <url>%2F2018%2F11%2F15%2Flinux%E6%AF%8F%E6%97%A5%E5%91%BD%E4%BB%A4(21)%EF%BC%9Afind%E5%91%BD%E4%BB%A4%E4%B9%8Bexec%2F</url>
    <content type="text"><![CDATA[find是我们很常用的一个Linux命令，但是我们一般查找出来的并不仅仅是看看而已，还会有进一步的操作，这个时候exec的作用就显现出来了。 一. exec参数说明：-exec 参数后面跟的是command命令，它的终止是以;为结束标志的，所以这句命令后面的分号是不可缺少的，考虑到各个系统中分号会有不同的意义，所以前面加反斜杠。 {} 花括号代表前面find查找出来的文件名。 使用find时，只要把想要的操作写在一个文件里，就可以用exec来配合find查找，很方便的。在有些操作系统中只允许-exec选项执行诸如l s或ls -l这样的命令。大多数用户使用这一选项是为了查找旧文件并删除它们。建议在真正执行rm命令删除文件之前，最好先用ls命令看一下，确认它们是所要删除的文件。 exec选项后面跟随着所要执行的命令或脚本，然后是一对儿{ }，一个空格和一个\，最后是一个分号。为了使用exec选项，必须要同时使用print选项。如果验证一下find命令，会发现该命令只输出从当前路径起的相对路径及文件名。 二. 使用示例1. 查找当前目录下的文件，并对查找结果执行ls -l 命令命令： find . -type f -exec ls -l {} \; 输出：12345678910[root@localhost home]# ls1.log 2.log 3.c 4.log test[root@localhost home]# find -type f./1.log./2.log./3.c[root@localhost home]# find -type f -exec ls -l &#123;&#125; \;-rw-r--r--. 1 root root 0 Nov 14 17:55 ./1.log-rw-r--r--. 1 root root 0 Nov 14 17:55 ./2.log-rwxrwxrwx. 1 root root 0 Nov 14 18:00 ./3.c 2. 查找当前目录下，24小时内更改过的文件，并进行删除操作（慎用！！！，删除没有提示）命令： find -type f -mtime -1 -exec rm {} \; 输出：12345678910111213[root@localhost home]# lltotal 0-rw-r--r--. 1 root root 0 Nov 14 17:55 1.log-rw-r--r--. 1 root root 0 Nov 14 17:55 2.log-rwxrwxrwx. 1 root root 0 Nov 14 18:00 3.cdrwxr-xr-x. 2 root root 6 Nov 14 18:16 4.log-rw-r--r--. 1 root root 0 Nov 15 18:02 5.logdrwxr-xr-x. 2 root root 6 Nov 14 17:55 test[root@localhost home]# find -type f -mtime -1./5.log[root@localhost home]# find -type f -mtime -1 -exec rm &#123;&#125; \;[root@localhost home]# ls1.log 2.log 3.c 4.log test 说明： 在shell中用任何方式删除文件之前，应当先查看相应的文件，一定要小心！当使用诸如mv或rm命令时，可以使用-exec选项的安全模式。它将在对每个匹配到的文件进行操作之前提示你。 3. 查找当前目录下文件名以.log结尾且24小时内更改过的文件，并进行安全删除操作（即删除前会进行询问）命令： find -name &quot;*.log&quot; -type f -mtime -1 -ok rm {} \; 输出： 12345678910111213141516171819202122232425[root@localhost home]# touch 6.c[root@localhost home]# touch 7.c[root@localhost home]# ls1.log 2.log 3.c 4.log 6.log 7.c test[root@localhost home]# lltotal 0-rw-r--r--. 1 root root 0 Nov 14 17:55 1.log-rw-r--r--. 1 root root 0 Nov 14 17:55 2.log-rwxrwxrwx. 1 root root 0 Nov 14 18:00 3.cdrwxr-xr-x. 2 root root 6 Nov 14 18:16 4.log-rw-r--r--. 1 root root 0 Nov 15 18:07 6.log-rw-r--r--. 1 root root 0 Nov 15 18:07 7.cdrwxr-xr-x. 2 root root 6 Nov 14 17:55 test[root@localhost home]# find -name "*.log" -mtime -1 -ok rm &#123;&#125; \;&lt; rm ... ./6.log &gt; ? y[root@localhost home]# lltotal 0-rw-r--r--. 1 root root 0 Nov 14 17:55 1.log-rw-r--r--. 1 root root 0 Nov 14 17:55 2.log-rwxrwxrwx. 1 root root 0 Nov 14 18:00 3.cdrwxr-xr-x. 2 root root 6 Nov 14 18:16 4.log-rw-r--r--. 1 root root 0 Nov 15 18:07 7.cdrwxr-xr-x. 2 root root 6 Nov 14 17:55 test[root@localhost home]# ls1.log 2.log 3.c 4.log 7.c test 说明： -ok： 和-exec的作用相同，只不过以一种更为安全的模式来执行该参数所给出的shell命令，在执行每一个命令之前，都会给出提示，让用户来确定是否执行。 4. 查找当前目录下的以.log结尾的文件或目录，并移动到test目录下命令： find -name &quot;*.log&quot; -exec mv {} test \; 输出：1234567891011121314151617181920212223[root@localhost home]# tree.├── 1.log├── 2.log├── 3.c├── 4.log├── 7.c└── test2 directories, 4 files[root@localhost home]# find -name "*.log" -exec mv &#123;&#125; test \;[root@localhost home]# ls3.c 7.c test[root@localhost home]# tree.├── 3.c├── 7.c└── test ├── 1.log ├── 2.log └── 4.log2 directories, 4 files]]></content>
      <categories>
        <category>linux每日命令</category>
      </categories>
      <tags>
        <tag>linux命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux每日命令(20)：find命令概览]]></title>
    <url>%2F2018%2F11%2F14%2Flinux%E6%AF%8F%E6%97%A5%E5%91%BD%E4%BB%A4(20)%EF%BC%9Afind%E5%91%BD%E4%BB%A4%E6%A6%82%E8%A7%88%2F</url>
    <content type="text"><![CDATA[Linux下find命令在目录结构中搜索文件，并执行指定的操作。Linux下find命令提供了相当多的查找条件，功能很强大。由于find具有强大的功能，所以它的选项也很多，其中大部分选项都值得我们花时间来了解一下。即使系统中含有网络文件系统( NFS)，find命令在该文件系统中同样有效，只你具有相应的权限。 在运行一个非常消耗资源的find命令时，很多人都倾向于把它放在后台执行，因为遍历一个大的文件系统可能会花费很长的时间(这里是指30G字节以上的文件系统)。 一. 命令格式find path -option [ -print ] [ -exec -ok command ] {} \; 二. 命令功能Linux find命令用来在指定目录下查找文件。任何位于参数之前的字符串都将被视为欲查找的目录名。如果使用该命令时，不设置任何参数，则find命令将在当前目录下查找子目录与文件。并且将查找到的子目录和文件全部进行显示。 三. 参数说明find 根据下列规则判断 path 和 expression（运算式），在命令列上第一个 - ( ) , ! 之前的部份为 path，之后的是 expression。如果 path 是空字串则使用目前路径，如果 expression 是空字串则使用 -print 为预设 expression。你可以使用 ( ) 将运算式分隔，并使用下列运算。 exp1 -and exp2 ! expr -not expr exp1 -or exp2 exp1, exp2 参数 描述 path find命令所查找的目录路径。例如用.来表示当前目录，用/来表示系统根目录。 -print find命令将匹配的文件输出到标准输出。 -exec find命令对匹配的文件执行该参数所给出的shell命令。相应命令的形式为’command’ { } \;，注意{ }和\；之间的空格。 -ok 和-exec的作用相同，只不过以一种更为安全的模式来执行该参数所给出的shell命令，在执行每一个命令之前，都会给出提示，让用户来确定是否执行。 四. 参数选项 命令 说明 -name name 按照文件名查找名为name的文件。-iname会忽略大小写 -path p : 路径名称符合 p 的文件，-ipath 会忽略大小写 -perm 按照文件权限来查找文件。 -prune 使用这一选项可以使find命令不在当前指定的目录中查找，如果同时使用-depth选项，那么-prune将被find命令忽略。 -user 按照文件属主来查找文件。 -group name 按照文件所属的组group，查找group为name的文件。 -gid n gid为n的文件 -mtime -n +n 按照文件的更改时间来查找文件， - n表示文件更改时间距现在n天以内，+ n表示文件更改时间距现在n天以前。 -nogroup 查找无有效所属组的文件，即该文件所属的组在/etc/groups中不存在。 -nouser 查找无有效属主的文件，即该文件的属主在/etc/passwd中不存在。 -newer file1 ! file2 查找更改时间比文件file1新但比文件file2旧的文件。 -type 查找某一类型的文件，诸如：b - 块设备文件。d - 目录。c - 字符设备文件。p - 管道文件。l - 符号链接文件。f - 普通文件。 -size n [c] 查找文件长度为n块的文件，带有c时表示文件长度以字节计。 -pid n process id 是 n 的文件 -depth 在查找文件时，首先查找当前目录中的文件，然后再在其子目录中查找。 -fstype 查找位于某一类型文件系统中的文件，这些文件系统类型通常可以在配置文件/etc/fstab中找到，该配置文件中包含了本系统中有关文件系统的信息。 -empty 空的文件 -mount, -xdev 只检查和指定目录在同一个文件系统下的文件，避免列出其它文件系统中的文件 -follow 如果find命令遇到符号链接文件，就跟踪至链接所指向的文件。 -cpio 对匹配的文件使用cpio命令，将这些文件备份到磁带设备中。 -amin n 查找系统中最近 n 分钟内被读取过的文件 -atime n 查找系统中最近n天内被读取过的文件 -cmin n 查找系统中最近 n 分钟内被改变文件状态的文件 -ctime n 查找系统中最近n天内被改变文件状态的文件 -mmin n 查找系统中最近n分钟内被改变文件数据的文件 -mtime n 查找系统中最近n天内被改变文件数据的文件 五. 使用实例1. 查找2天内被读取过的文件命令： find -atime -2 输出：12345[root@localhost home]# find -atime -2../test./1.log./2.log 2. 在当前目录下查找.log结尾的文件命令： find . -name &quot;*.log&quot; 或 find -name &quot;*.log&quot; 输出： 12345678[root@localhost home]# ls1.log 2.log 3.c test[root@localhost home]# find . -name "*.log"./1.log./2.log[root@localhost home]# find -name "*.log"./1.log./2.log 说明： “.” 代表当前目录find 命令 不指定path时，默认是当前目录 3. 查找home目录下 ,权限为777的文件命令： find /home/ -perm 777 输出： 1234567891011121314151617[root@localhost home]# lltotal 0-rw-r--r--. 1 root root 0 Nov 14 17:55 1.log-rw-r--r--. 1 root root 0 Nov 14 17:55 2.log-rw-r--r--. 1 root root 0 Nov 14 18:00 3.cdrwxr-xr-x. 2 root root 6 Nov 14 17:55 test[root@localhost home]# find /home/ -perm 777[root@localhost home]#[root@localhost home]# chmod 777 3.c [root@localhost home]# find /home/ -perm 777/home/3.c[root@localhost home]# lltotal 0-rw-r--r--. 1 root root 0 Nov 14 17:55 1.log-rw-r--r--. 1 root root 0 Nov 14 17:55 2.log-rwxrwxrwx. 1 root root 0 Nov 14 18:00 3.cdrwxr-xr-x. 2 root root 6 Nov 14 17:55 test 说明： chmod 777 3.c 命令是指给3.c文件赋予777权限 4. 查找home目录下以.log结尾的文件或目录命令： 查找以.log结尾的文件 find /home/ -type f -name &apos;*.log&apos; 查找以.log结尾的目录 find /home/ -type d -name &apos;*.log&apos; 输出： 12345678910[root@localhost home]# ls1.log 2.log 3.c test[root@localhost home]# mkdir 4.log[root@localhost home]# ls1.log 2.log 3.c 4.log test[root@localhost home]# find /home/ -type f -name '*.log'/home/1.log/home/2.log[root@localhost home]# find /home/ -type d -name '*.log'/home/4.log 5. 查找当前目录下文件大小大于5个字节的文件命令：大于5个字节 find -size +5c 等于6个字节 find -size 6c 1234567891011121314[root@localhost home]# lltotal 0-rw-r--r--. 1 root root 0 Nov 14 17:55 1.log-rw-r--r--. 1 root root 0 Nov 14 17:55 2.log-rwxrwxrwx. 1 root root 0 Nov 14 18:00 3.cdrwxr-xr-x. 2 root root 6 Nov 14 18:16 4.logdrwxr-xr-x. 2 root root 6 Nov 14 17:55 test[root@localhost home]# find -size +5c../test./4.log[root@localhost home]# find -size 6c./test./4.log]]></content>
      <categories>
        <category>linux每日命令</category>
      </categories>
      <tags>
        <tag>linux命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux每日命令(19)：locate命令]]></title>
    <url>%2F2018%2F11%2F13%2Flinux%E6%AF%8F%E6%97%A5%E5%91%BD%E4%BB%A4(19)%EF%BC%9Alocate%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[locate 让使用者可以很快速的搜寻档案系统内是否有指定的档案。其方法是先建立一个包括系统内所有档案名称及路径的数据库，之后当寻找时就只需查询这个数据库，而不必实际深入档案系统之中了。在一般的 distribution 之中，数据库的建立都被放在 crontab 中自动执行。 一 ．命令格式：locate [-d ][--help][--version][范本样式...] 二．命令功能：locate命令可以在搜寻数据库时快速找到档案，数据库由updatedb程序来更新，updatedb是由cron daemon周期性建立的，locate命令在搜寻数据库时比由整个由硬盘资料来搜寻资料来得快，但较差劲的是locate所找到的档案若是最近才建立或 刚更名的，可能会找不到，在内定值中，updatedb每天会跑一次，可以由修改crontab来更新设定值。(etc/crontab) locate指定用在搜寻符合条件的档案，它会去储存档案与目录名称的数据库内，寻找合乎范本样式条件的档案或目录录，可以使用特殊字元（如”” 或”?”等）来指定范本样式，如指定范本为kcpaner, locate会找出所有起始字串为kcpa且结尾为ner的档案或目录，如名称为kcpartner若目录录名称为kcpa_ner则会列出该目录下包括 子目录在内的所有档案。 locate指令和find找寻档案的功能类似，但locate是通过update程序将硬盘中的所有档案和目录资料先建立一个索引数据库（一般在/var/lib/slocate/slocate.db中），在执行loacte时直接找该索引，查询速度会较快，索引数据库一般是由操作系统管理，但也可以直接下达update强迫系统立即更新索引数据库。命令为： locate -u 三．命令参数： 参数 描述 -e 将排除在寻找的范围之外。 -1 如果 是 1．则启动安全模式。在安全模式下，使用者不会看到权限无法看到 的档案。这会使速度减慢，因为 locate 必须至实际的档案系统中取得档案的权限资料。 -f 将特定的档案系统排除在外，例如我们没有道理要把 proc 档案系统中的档案放在资料库中。 -q 安静模式，不会显示任何错误讯息。 -n 至多显示 n个输出。 -r 使用正规运算式 做寻找的条件。 -o 指定资料库存的名称。 -d -d或–database= 配置locate指令使用的数据库。locate指令预设的数据库位于/var/lib/slocate目录里，文档名为slocate.db，您可使用 这个参数另行指定。 -h 显示辅助讯息 -V 显示程式的版本讯息 四．使用实例查询文件路径中含有/etc/sh的文件或目录命令： locate /etc/sh 输出：12345678910hc@hc-virtual-machine:~$ locate /etc/sh/etc/shadow/etc/shadow-/etc/shells/snap/core/5548/etc/shadow/snap/core/5548/etc/shells/snap/core/5662/etc/shadow/snap/core/5662/etc/shells/snap/core/5742/etc/shadow/snap/core/5742/etc/shells]]></content>
      <categories>
        <category>linux每日命令</category>
      </categories>
      <tags>
        <tag>linux命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux每日命令(18)：whereis命令]]></title>
    <url>%2F2018%2F11%2F12%2Flinux%E6%AF%8F%E6%97%A5%E5%91%BD%E4%BB%A4(18)%EF%BC%9Awhereis%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[whereis命令用于查找文件。 该指令会在特定目录中查找符合条件的文件。这些文件应属于原始代码、二进制文件，或是帮助文件。 该指令只能用于查找二进制文件、源代码文件和man手册页，一般文件的定位需使用locate命令。 一．命令格式：whereis [-bfmsu][-B &lt;目录&gt;...][-M &lt;目录&gt;...][-S &lt;目录&gt;...][文件...] 二．命令功能：whereis命令是定位可执行文件、源代码文件、帮助文件在文件系统中的位置。这些文件的属性应属于原始代码，二进制文件，或是帮助文件。whereis 程序还具有搜索源代码、指定备用搜索路径和搜索不寻常项的能力。如果省略参数，则返回所有信息。 三．命令参数： 参数 描述 -b 定位可执行文件。 -m 定位帮助文件。 -s 定位源代码文件。 -u 搜索默认路径下除可执行文件、源代码文件、帮助文件以外的其它文件。 -B 指定搜索可执行文件的路径。 -M 指定搜索帮助文件的路径。 -S 指定搜索源代码文件的路径。 四．使用实例：1：查看指令”bash”的位置命令： whereis bash 输出：12hc@hc-virtual-machine:~$ whereis bashbash: /bin/bash /etc/bash.bashrc /usr/share/man/man1/bash.1.gz 说明：以上输出信息从左至右分别为查询的程序名、bash路径、bash的man 手册页路径。 2：显示bash 命令的二进制程序的地址命令： whereis -b bash 输出：12hc@hc-virtual-machine:~$ whereis -b bashbash: /bin/bash /etc/bash.bashrc 3.显示bash命令的帮助文件地址命令： whereis -m bash 输出：12hc@hc-virtual-machine:~$ whereis -m bashbash: /usr/share/man/man1/bash.1.gz]]></content>
      <categories>
        <category>linux每日命令</category>
      </categories>
      <tags>
        <tag>linux命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux每日命令(17)：which命令]]></title>
    <url>%2F2018%2F11%2F09%2Flinux%E6%AF%8F%E6%97%A5%E5%91%BD%E4%BB%A4(17)%EF%BC%9Awhich%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[我们经常在linux要查找某个文件，但不知道放在哪里了，可以使用下面的一些命令来搜索： which 查看可执行文件的位置。 whereis 查看文件的位置。 locate 配合数据库查看文件位置。 find 实际搜寻硬盘查询文件名称。 which命令的作用是，在PATH变量指定的路径中，搜索某个系统命令的位置，并且返回第一个搜索结果。也就是说，使用which命令，就可以看到某个系统命令是否存在，以及执行的到底是哪一个位置的命令。 一．命令格式：which 可执行文件名称 二．命令功能：which指令会在PATH变量指定的路径中，搜索某个系统命令的位置，并且返回第一个搜索结果。 三．命令参数： 参数 描述 -n 指定文件名长度，指定的长度必须大于或等于所有文件中最长的文件名。 -p 与-n参数相同，但此处的包括了文件的路径。 -w 指定输出时栏位的宽度。 -V 显示版本信息 四. 命令实例1. 查找可执行文件的位置、显示命令所在路径命令： which pwd 输出：1234hc@hc-virtual-machine:~/test$ which pwd/bin/pwdhc@hc-virtual-machine:~/test$ which head/usr/bin/head 说明： which 是根据使用者所配置的 PATH 变量内的目录去搜寻可运行档的，所以，不同的 PATH 配置内容所找到的命令是不一样的 2. 用 which 去找出 which命令： which which 输出：Ubuntu18.04下：12hc@hc-virtual-machine:~/test$ which which/usr/bin/which Centos7中：1234[root@localhost ~]# which whichalias which='alias | /usr/bin/which --tty-only --read-alias --show-dot --show-tilde' /usr/bin/alias /usr/bin/which 说明： alias 这就是所谓的『命令别名』，意思是输入 which 会等於后面接的那串命令！]]></content>
      <categories>
        <category>linux每日命令</category>
      </categories>
      <tags>
        <tag>linux命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux每日命令(16)：head命令]]></title>
    <url>%2F2018%2F11%2F09%2Flinux%E6%AF%8F%E6%97%A5%E5%91%BD%E4%BB%A4(16)%EF%BC%9Ahead%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[head 与 tail 就像它的名字一样的浅显易懂，它是用来显示开头或结尾某个数量的文字区块，head 用来显示档案的开头至标准输出中，而 tail 想当然尔就是看档案的结尾。 一．命令格式：head [参数]... [文件]... 二．命令功能：head 用来显示档案的开头至标准输出中，默认head命令打印其相应文件的开头10行。 三．命令参数： 参数 描述 -q 隐藏文件名 -v 显示文件名 -c&lt;字节&gt; 显示字节数 -n&lt;行数&gt; 显示的行数 四．使用实例：1.输出log1文件的前4行内容命令： head -n 4 log1 输出： 12345678910111213hc@hc-virtual-machine:~/snap$ nl -b a log1 1 我是log1的第一行 2 3 我是log1的第三行 4 我是log1的第四行 5 我是log1的第五行 6 7 我是log1的第七行hc@hc-virtual-machine:~/snap$ head -n 4 log1我是log1的第一行我是log1的第三行我是log1的第四行 2.输出log1文件除最后4行以外的全部内容命令： head -n -4 log1 输出：12345hc@hc-virtual-machine:~/snap$ head -n -4 log1我是log1的第一行我是log1的第三行hc@hc-virtual-machine:~/snap$ 3.输出log1文件的前24个字节命令： head -c 24 log1 输出： 1234hc@hc-virtual-machine:~/snap$ head -c 24 log1我是log1的第一行hc@hc-virtual-machine:~/snap$ 4.输出log1文件的除最后24个字节以外的内容命令： head -c -24 log1 输出： 1234567hc@hc-virtual-machine:~/snap$ head -c -24 log1我是log1的第一行我是log1的第三行我是log1的第四行我是log1的第五行hc@hc-virtual-machine:~/snap$]]></content>
      <categories>
        <category>linux每日命令</category>
      </categories>
      <tags>
        <tag>linux命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux每日命令(15)：tail命令]]></title>
    <url>%2F2018%2F11%2F08%2Flinux%E6%AF%8F%E6%97%A5%E5%91%BD%E4%BB%A4(15)%EF%BC%9Atail%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[tail 命令从指定点开始将文件写到标准输出.使用tail命令的-f选项可以方便的查阅正在改变的日志文件,tail -f filename会把filename里最尾部的内容显示在屏幕上,并且不断刷新,使你看到最新的文件内容. 一．命令格式;tail [必要参数] [选择参数] [文件] 二．命令功能：用于显示指定文件末尾内容，不指定文件时，作为输入信息进行处理。常用查看日志文件。 三．命令参数： 参数 描述 -f 循环读取 -q 不显示处理信息 -v 显示详细的处理信息 -c&lt;数目&gt; 显示的字节数 -n&lt;行数&gt; 显示行数 –pid=PID 与-f合用,表示在进程ID,PID死掉之后结束. -q –quiet, –silent 从不输出给出文件名的首部 -s –sleep-interval=S 与-f合用,表示在每次反复的间隔休眠S秒 四．使用实例：1.显示log1文件最后3行内容命令： tail -n 3 log1 输出： 123456789101112hc@hc-virtual-machine:~/snap$ nl -b a log1 1 我是log1的第一行 2 3 我是log1的第三行 4 我是log1的第四行 5 我是log1的第五行 6 7 我是log1的第七行hc@hc-virtual-machine:~/snap$ tail -n 3 log1我是log1的第五行我是log1的第七行 2. 从第3行开始显示log1文件内容命令： tail -n +3 log1 输出： 1234567891011121314hc@hc-virtual-machine:~/snap$ nl -b a log1 1 我是log1的第一行 2 3 我是log1的第三行 4 我是log1的第四行 5 我是log1的第五行 6 7 我是log1的第七行hc@hc-virtual-machine:~/snap$ tail -n +3 log1我是log1的第三行我是log1的第四行我是log1的第五行我是log1的第七行 3.循环刷新查看文件内容命令： tail -f test.log 输出: 123456789101112131415161718hc@hc-virtual-machine:~/snap$ ping 127.0.0.1 &gt; test.log &amp; [1] 24615hc@hc-virtual-machine:~/snap$ tail -f test.log64 bytes from 127.0.0.1: icmp_seq=5 ttl=64 time=0.065 ms64 bytes from 127.0.0.1: icmp_seq=6 ttl=64 time=0.068 ms64 bytes from 127.0.0.1: icmp_seq=7 ttl=64 time=0.157 ms64 bytes from 127.0.0.1: icmp_seq=8 ttl=64 time=0.067 ms64 bytes from 127.0.0.1: icmp_seq=9 ttl=64 time=0.034 ms64 bytes from 127.0.0.1: icmp_seq=10 ttl=64 time=0.043 ms64 bytes from 127.0.0.1: icmp_seq=11 ttl=64 time=0.031 ms64 bytes from 127.0.0.1: icmp_seq=12 ttl=64 time=0.076 ms64 bytes from 127.0.0.1: icmp_seq=13 ttl=64 time=0.045 ms64 bytes from 127.0.0.1: icmp_seq=14 ttl=64 time=0.069 ms64 bytes from 127.0.0.1: icmp_seq=15 ttl=64 time=0.067 ms64 bytes from 127.0.0.1: icmp_seq=16 ttl=64 time=0.063 ms^Chc@hc-virtual-machine:~/snap$ ps -ef | less[1]+ 已杀死 ping 127.0.0.1 &gt; test.log 说明： ping 127.0.0.1 &gt; test.log &amp; //在后台ping远程主机。并输出文件到test.log；这种做法也使用于一个以上的档案监视。用Ctrl＋c来终止。 由于加了&amp;,所以输出命令一直在后台运行，想要杀死它就得找到它的pid，然后kill -9 pid，终止输出]]></content>
      <categories>
        <category>linux每日命令</category>
      </categories>
      <tags>
        <tag>linux命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux每日命令(14)：less命令]]></title>
    <url>%2F2018%2F11%2F07%2Flinux%E6%AF%8F%E6%97%A5%E5%91%BD%E4%BB%A4(14)%EF%BC%9Aless%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[less 工具也是对文件或其它输出进行分页显示的工具，应该说是linux正统查看文件内容的工具，功能极其强大。less 的用法比起 more 更加的有弹性。在 more 的时候，我们并没有办法向前面翻， 只能往后面看，但若使用了 less 时，就可以使用 [pageup] [pagedown] 等按键的功能来往前往后翻看文件，更容易用来查看一个文件的内容！除此之外，在 less 里头可以拥有更多的搜索功能，不止可以向下搜，也可以向上搜。 一．命令格式：less [参数] 文件 二．命令功能：less 与 more 类似，但使用 less 可以随意浏览文件，而 more 仅能向前移动，却不能向后移动，而且 less 在查看之前不会加载整个文件。 三．命令参数： 参数 描述 -b &lt;缓冲区大小&gt; 设置缓冲区的大小 -e 当文件显示结束后，自动离开 -f 强迫打开特殊文件，例如外围设备代号、目录和二进制文件 -g 只标志最后搜索的关键词 -i 忽略搜索时的大小写 -m 显示类似more命令的百分比 -N 显示每行的行号 -o &lt;文件名&gt; 将less 输出的内容在指定文件中保存起来 -Q 不使用警告音 -s 显示连续空行为一行 -S 行过长时间将超出部分舍弃 -x &lt;数字&gt; 将“tab”键显示为规定的数字空格 /字符串： 向下搜索“字符串”的功能 ?字符串： 向上搜索“字符串”的功能 n： 重复前一个搜索（与 / 或 ? 有关） N： 反向重复前一个搜索（与 / 或 ? 有关） b CentOs向后翻一页（Ubuntu向前翻一页） d 向后翻半页 h 显示帮助界面 Q 退出less 命令 u 向前滚动半页 y 向前滚动一行 空格键 滚动一页 回车键 滚动一行 [pagedown] 向下翻动一页 [pageup] 向上翻动一页 四．使用实例：1.查看文件命令： less log1 输出：123456789hc@hc-virtual-machine:~/snap$ less log1 我是log1的第一行我是log1的第三行我是log1的第四行我是log1的第五行我是log1的第七行log1 (END) 2. ps查看进程信息并通过less分页显示命令： ps -ef |less 输出：123456789101112131415161718192021222324UID PID PPID C STIME TTY TIME CMDroot 1 0 0 10:10 ? 00:00:03 /sbin/init splashroot 2 0 0 10:10 ? 00:00:00 [kthreadd]root 4 2 0 10:10 ? 00:00:00 [kworker/0:0H]root 6 2 0 10:10 ? 00:00:00 [mm_percpu_wq]root 7 2 0 10:10 ? 00:00:00 [ksoftirqd/0]root 8 2 0 10:10 ? 00:00:03 [rcu_sched]root 9 2 0 10:10 ? 00:00:00 [rcu_bh]root 10 2 0 10:10 ? 00:00:00 [migration/0]root 11 2 0 10:10 ? 00:00:00 [watchdog/0]root 12 2 0 10:10 ? 00:00:00 [cpuhp/0]root 13 2 0 10:10 ? 00:00:00 [cpuhp/1]root 14 2 0 10:10 ? 00:00:00 [watchdog/1]root 15 2 0 10:10 ? 00:00:00 [migration/1]root 16 2 0 10:10 ? 00:00:00 [ksoftirqd/1]root 18 2 0 10:10 ? 00:00:00 [kworker/1:0H]root 19 2 0 10:10 ? 00:00:00 [cpuhp/2]root 20 2 0 10:10 ? 00:00:00 [watchdog/2]root 21 2 0 10:10 ? 00:00:00 [migration/2]root 22 2 0 10:10 ? 00:00:00 [ksoftirqd/2]root 24 2 0 10:10 ? 00:00:00 [kworker/2:0H]root 25 2 0 10:10 ? 00:00:00 [cpuhp/3]root 26 2 0 10:10 ? 00:00:00 [watchdog/3]: 说明： 按空格键或者pagedown键，向后翻一页按b（CentOs向后翻一页,Ubuntu向前翻一页）按y向前翻一行，按回车键向后翻一行d 向后翻半页，u前翻半页 3. 查看命令历史使用记录并通过less分页显示命令： history | less 输出：123456789101112131415161718192021222324 1 sudo apt install vmware-install.pl 2 pwd 3 ls 4 pwd 5 ls 6 vmware-install.pl 7 pwd 8 ls 9 pwd 10 ls 11 cd 桌面 12 ls 13 cp VMwareTools-10.1.6-5214329.tar.gz ../ 14 ls 15 cd .. 16 ls 17 tar zxvf VMwareTools-10.1.6-5214329.tar.gz 18 ls 19 cd vmware-tools-distrib/ 20 sudo ./vmware-install.pl 21 sudo -su 22 sudo su 23 ls: 4. 浏览多个文件命令： less log1 log2 输出：12345678910hc@hc-virtual-machine:~/snap$ less log1 log2我是log1的第一行我是log1的第三行我是log1的第四行我是log1的第五行我是log1的第七行log1 (file 1 of 2) (END) - Next: log2 说明： 输入 :n后，切换到 下一个文件，log2 输入 :p 后，切换到 上一个文件，log1 5．附加备注1.全屏导航CentOs下： ctrl + F - 向前移动一屏 ctrl + B - 向后移动一屏 ctrl + D - 向前移动半屏 ctrl + U - 向后移动半屏 Ubuntu下： ctrl + F - 向后移动一屏 ctrl + B - 向前移动一屏 ctrl + D - 向后移动半屏 ctrl + U - 向前移动半屏 2.单行导航CentOs下：j - 向前移动一行 k - 向后移动一行Ubuntu下：j - 向后移动一行 k - 向前移动一行 3.其它导航G - 移动到最后一行 g - 移动到第一行 q / ZZ - 退出 less 命令 4.其它有用的命令v - 使用配置的编辑器编辑当前文件 h - 显示 less 的帮助文档 &amp;pattern - 仅显示匹配模式的行，而不是整个文件 5.标记导航当使用 less 查看大文件时，可以在任何一个位置作标记，可以通过命令导航到标有特定标记的文本位置： ma - 使用 a 标记文本的当前位置 ‘a - 导航到标记 a 处]]></content>
      <categories>
        <category>linux每日命令</category>
      </categories>
      <tags>
        <tag>linux命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux每日命令(13)：more命令]]></title>
    <url>%2F2018%2F11%2F06%2Flinux%E6%AF%8F%E6%97%A5%E5%91%BD%E4%BB%A4(13)%EF%BC%9Amore%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[more命令，功能类似 cat ，cat命令是整个文件的内容从上到下显示在屏幕上。 more会以一页一页的显示方便使用者逐页阅读，而最基本的指令就是按空白键（space）就往下一页显示，按 b 键就会往回（back）一页显示，而且还有搜寻字串的功能 。more命令从前向后读取文件，因此在启动时就加载整个文件。 一．命令格式：more [-dlfpcsu ] [-num ] [+/ pattern] [+ linenum] [file ... ] 二．命令功能：more命令和cat的功能一样都是查看文件里的内容，但有所不同的是more可以按页来查看文件的内容，还支持直接跳转行等功能。 三．命令参数： 参数 描述 +n 从笫n行开始显示 -n 定义屏幕大小为n行 +/pattern 在每个档案显示前搜寻该字串（pattern），然后从该字串前两行之后开始显示 -c 从顶部清屏，然后显示 -d 提示“Press space to continue，’q’ to quit（按空格键继续，按q键退出）”，禁用响铃功能 -l 忽略Ctrl+l（换页）字符 -p 通过清除窗口而不是滚屏来对文件进行换页，与-c选项相似 -s 把连续的多个空行显示为一行 -u 把文件内容中的下画线去掉 四．常用操作命令： 操作命令 描述 Enter 向下n行，需要定义。默认为1行 Ctrl+F 向下滚动一屏 空格键 向下 滚动一屏 Ctrl+B 返回上一屏 = 输出当前行的行号 ：f 输出文件名和当前行的行号 V 调用vi编辑器 !命令 调 用Shell，并执行命令 q 退出more 五. 使用实例1. 从第3行起显示log1文件中的内容命令： more +3 log1 输出：1234567891011121314hc@hc-virtual-machine:~/snap$ nl -b a log1 1 我是log1的第一行 2 3 4 我是log1的第四行 5 我是log1的第五行 6 7 我是log1的第七行hc@hc-virtual-machine:~/snap$ more +3 log1 我是log1的第四行我是log1的第五行我是log1的第七行 2.从文件中查找第一个出现”五”字符串的行，并从该处前两行开始显示输出命令： more +/五 log1 输出：12345678910111213141516hc@hc-virtual-machine:~/snap$ cat log1 我是log1的第一行我是log1的第三行我是log1的第四行我是log1的第五行我是log1的第七行hc@hc-virtual-machine:~/snap$ more +/五 log1...跳过我是log1的第三行我是log1的第四行我是log1的第五行我是log1的第七行 3.设定每屏显示2行命令： more -2 log1 输出: 显示输出文件的第一二行1234hc@hc-virtual-machine:~/snap$ more -2 log1 我是log1的第一行--更多--(20%) 按下ENTER键后,向下n行，需要定义。默认为1行，输出了第三行1234我是log1的第一行我是log1的第三行--更多--(40%) 按下空格键后,向下滚动一屏(当前设置的是一屏为2行)，输出了第四五行1234567hc@hc-virtual-machine:~/snap$ more -2 log1 我是log1的第一行我是log1的第三行我是log1的第四行我是log1的第五行--更多--(79%) 4. 列一个目录下的文件，由于内容太多，我们应该学会用more来分页显示。这得和管道 | 结合起来命令： ls | more -5 输出：12345678910hc@hc-virtual-machine:~$ lsexamples.desktop PycharmProjects vmware-tools-distrib 模板 图片 下载 桌面git_demo snap 公共的 视频 文档 音乐hc@hc-virtual-machine:~$ ls | more -5examples.desktopgit_demoPycharmProjectssnapvmware-tools-distrib--更多-- 说明： 每页显示5个文件信息，按 Ctrl+F 或者 空格键 将会显示下5条文件信息。]]></content>
      <categories>
        <category>linux每日命令</category>
      </categories>
      <tags>
        <tag>linux命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux每日命令(12)：nl命令]]></title>
    <url>%2F2018%2F11%2F05%2Flinux%E6%AF%8F%E6%97%A5%E5%91%BD%E4%BB%A4(12)%EF%BC%9Anl%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[nl命令在linux系统中用来计算文件中行号。nl 可以将输出的文件内容自动的加上行号！其默认的结果与 cat -n 有点不太一样， nl 可以将行号做比较多的显示设计，包括位数与是否自动补齐 0 等等的功能。 一．命令格式：nl [参数]... [文件]... 二．命令参数： 参数 描述 -b 指定行号指定的方式，主要有两种 -b a 表示不论是否为空行，也同样列出行号(类似 cat -n)； -b t 如果有空行，空的那一行不要列出行号(默认值) -n 列出行号表示的方法，主要有三种 -n ln 行号在屏幕的最左方显示 -n rn 行号在自己栏位的最右方显示，且不加 0 -n rz 行号在自己栏位的最右方显示，且加行号不足6位时左边加0补位 -w 指定行号栏位的占用的位数 -p 在逻辑定界符处不重新开始计算。 三．命令功能：nl 命令读取 File 参数（缺省情况下标准输入），计算输入中的行号，将计算过的行号写入标准输出。 在输出中，nl 命令根据您在命令行中指定的标志来计算左边的行。 输入文本必须写在逻辑页中。每个逻辑页有头、主体和页脚节（可以有空节）。 除非使用 -p 标志，nl 命令在每个逻辑页开始的地方重新设置行号。 可以单独为头、主体和页脚节设置行计算标志（例如，头和页脚行可以被计算然而文本行不能）。 四．使用实例：1.用 nl 列出 log1 的内容命令： nl log1 输出：12345678hc@hc-virtual-machine:~/snap$ nl log1 1 我是log1的第一行 2 我是log1的第四行 3 我是log1的第五行 4 我是log1的第七行 说明： 文件中的空白行，nl 不会加上行号 2.用 nl 列出 log1 的内容，空行也加上行号命令： nl -b a log1 输出：12345678hc@hc-virtual-machine:~/snap$ nl -b a log1 1 我是log1的第一行 2 3 4 我是log1的第四行 5 我是log1的第五行 6 7 我是log1的第七行 3.让行号前面自动补上0,统一输出格式12345678910111213141516hc@hc-virtual-machine:~/snap$ nl -b a -n rz log1 000001 我是log1的第一行000002 000003 000004 我是log1的第四行000005 我是log1的第五行000006 000007 我是log1的第七行hc@hc-virtual-machine:~/snap$ nl -b a -n rz -w 3 log1 001 我是log1的第一行002 003 004 我是log1的第四行005 我是log1的第五行006 007 我是log1的第七行 说明： nl -b a -n rz 命令行号默认为六位，要调整位数可以加上参数 -w 3 调整为3位。]]></content>
      <categories>
        <category>linux每日命令</category>
      </categories>
      <tags>
        <tag>linux命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux每日命令(11)：cat命令]]></title>
    <url>%2F2018%2F11%2F03%2Flinux%E6%AF%8F%E6%97%A5%E5%91%BD%E4%BB%A4(11)%EF%BC%9Acat%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[cat命令的用途是连接文件或标准输入并打印。这个命令常用来显示文件内容，或者将几个文件连接起来显示，或者从标准输入读取内容并显示，它常与重定向符号配合使用。 一．命令格式：cat [参数] [文件]... 二．命令功能：cat主要有三大功能： 1.一次显示整个文件:cat filename 2.从键盘创建一个文件:cat &gt; filename 只能创建新文件,不能编辑已有文件. 3.将几个文件合并为一个文件:cat file1 file2 &gt; file 三. 命令参数 参数 描述 -n –number ， 由1开始对所有输出的行数编号 -b –number-nonblank， 和 -n 相似，只不过对于空白行不编号。 -s –squeeze-blank,当遇到有连续两行以上的空白行,就代换为一行的空白行。 -v –show-nonprinting ， 使用 ^ 和 M- 引用，除了 LFD 和 TAB 之外 -E –show-ends ， 在每行结束处显示 $ -T –show-tabs，将 TAB 字符显示为 ^I。 -A –show-all ， 等价于 -vET -e 等价于 -vE -t 与 -vT 等价 四. 使用实例1. 将file1的文档内容覆盖到file2中命令： 不带行号覆盖内容 cat file1 &gt; file2 带行号覆盖内容 cat -n file1 &gt; file2 输出： 123456789101112hc@hc-virtual-machine:~/test$ cat file1我是file1的第一行我是file1的第二行hc@hc-virtual-machine:~/test$ cat file2hc@hc-virtual-machine:~/test$ cat file1 &gt; file2hc@hc-virtual-machine:~/test$ cat file2我是file1的第一行我是file1的第二行hc@hc-virtual-machine:~/test$ cat -n file1 &gt; file2hc@hc-virtual-machine:~/test$ cat file2 1 我是file1的第一行 2 我是file1的第二行 2. 将file1的内容追加到file2的内容中命令： 不带行号追加 cat file1 &gt;&gt; file2 带行号追加（空白行不加行号） 输出：123456789101112131415161718192021222324252627282930313233343536hc@hc-virtual-machine:~/test$ cat file1我是file1的第一行我是file1的第二行hc@hc-virtual-machine:~/test$ cat file2我是file2的第一行我是file2的第6行hc@hc-virtual-machine:~/test$ cat file1 &gt;&gt; file2hc@hc-virtual-machine:~/test$ cat file1我是file1的第一行我是file1的第二行hc@hc-virtual-machine:~/test$ cat file2我是file2的第一行我是file2的第6行我是file1的第一行我是file1的第二行hc@hc-virtual-machine:~/test$ cat -b file2 &gt;&gt; file1hc@hc-virtual-machine:~/test$ cat file1我是file1的第一行我是file1的第二行 1 我是file2的第一行 2 我是file2的第6行 3 我是file1的第一行 4 我是file1的第二行hc@hc-virtual-machine:~/test$ 说明： &gt;是重新编辑内容，&gt;&gt; 是追加内容 3. 清空file1文档内容命令： cat /dev/null &gt; file1 输出：1234567891011121314hc@hc-virtual-machine:~/test$ cat file1我是file1的第一行我是file1的第二行 1 我是file2的第一行 2 我是file2的第6行 3 我是file1的第一行 4 我是file1的第二行hc@hc-virtual-machine:~/test$ cat /dev/null &gt; file1hc@hc-virtual-machine:~/test$ cat file1hc@hc-virtual-machine:~/test$ 4. 倒序输出file2中的内容命令： tac file2 输出： 12345678910111213141516171819hc@hc-virtual-machine:~/test$ cat file2我是file2的第一行我是file2的第6行我是file1的第一行我是file1的第二行hc@hc-virtual-machine:~/test$ tac file2我是file1的第二行我是file1的第一行我是file2的第6行我是file2的第一行hc@hc-virtual-machine:~/test$ 说明： tac 是将 cat 反写过来，所以他的功能就跟 cat 相反， cat 是由第一行到最后一行连续显示在屏幕上，而 tac 则是由最后一行到第一行反向在屏幕上显示出来！]]></content>
      <categories>
        <category>linux每日命令</category>
      </categories>
      <tags>
        <tag>linux命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux每日命令(10)：touch命令]]></title>
    <url>%2F2018%2F11%2F01%2Flinux%E6%AF%8F%E6%97%A5%E5%91%BD%E4%BB%A4(10)%EF%BC%9Atouch%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[linux的touch命令一般用来修改文件时间戳，或者新建一个不存在的文件。 一．命令格式：touch [参数]... 文件... 二．命令参数： 参数 描述 -a 或–time=atime或–time=access或–time=use 只更改存取时间。 -c 或–no-create 不建立任何文档。 -d 使用指定的日期时间，而非现在的时间。 -f 此参数将忽略不予处理，仅负责解决BSD版本touch指令的兼容性问题。 -m 或–time=mtime或–time=modify 只更改变动时间。 -r 把指定文档或目录的日期时间，统统设成和参考文档或目录的日期时间相同。 -t 使用指定的日期时间，而非现在的时间。 三．命令功能：touch命令参数可更改文档或目录的日期时间，包括存取时间和更改时间。 四．使用实例：1. 创建file1和file2两个空文件命令： touch file1 file2 输出： 1234567891011hc@hc-virtual-machine:~/test$ ll总用量 8drwxr-xr-x 2 hc hc 4096 11月 1 09:48 ./drwxr-xr-x 25 hc hc 4096 10月 31 19:52 ../hc@hc-virtual-machine:~/test$ touch file1 file2hc@hc-virtual-machine:~/test$ ll总用量 8drwxr-xr-x 2 hc hc 4096 11月 1 09:48 ./drwxr-xr-x 25 hc hc 4096 10月 31 19:52 ../-rw-r--r-- 1 hc hc 0 11月 1 09:48 file1-rw-r--r-- 1 hc hc 0 11月 1 09:48 file2 说明： 如果加入 -c 参数，当目标文件不存在时，不会创建新文件，如果目标文件存在，则会修改文件时间属性为当前系统时间 1234567891011121314hc@hc-virtual-machine:~/test$ ll总用量 8drwxr-xr-x 2 hc hc 4096 11月 1 09:48 ./drwxr-xr-x 25 hc hc 4096 10月 31 19:52 ../-rw-r--r-- 1 hc hc 0 11月 1 09:48 file1-rw-r--r-- 1 hc hc 0 11月 1 09:48 file2hc@hc-virtual-machine:~/test$ touch -c file2hc@hc-virtual-machine:~/test$ touch -c file3hc@hc-virtual-machine:~/test$ ll总用量 8drwxr-xr-x 2 hc hc 4096 11月 1 09:48 ./drwxr-xr-x 25 hc hc 4096 10月 31 19:52 ../-rw-r--r-- 1 hc hc 0 11月 1 09:48 file1-rw-r--r-- 1 hc hc 0 11月 1 09:50 file2 2. 将file1的时间改为file2的时间命令： touch -r file2 file1 输出： 12345678910111213hc@hc-virtual-machine:~/test$ ll总用量 8drwxr-xr-x 2 hc hc 4096 11月 1 09:48 ./drwxr-xr-x 25 hc hc 4096 10月 31 19:52 ../-rw-r--r-- 1 hc hc 0 11月 1 09:48 file1-rw-r--r-- 1 hc hc 0 11月 1 09:50 file2hc@hc-virtual-machine:~/test$ touch -r file2 file1hc@hc-virtual-machine:~/test$ ll总用量 8drwxr-xr-x 2 hc hc 4096 11月 1 09:48 ./drwxr-xr-x 25 hc hc 4096 10月 31 19:52 ../-rw-r--r-- 1 hc hc 0 11月 1 09:50 file1-rw-r--r-- 1 hc hc 0 11月 1 09:50 file2 3.指定文件的日期时间命令： touch -t 201810011003.17 file2 输出： 123456789101112hc@hc-virtual-machine:~/test$ ll总用量 8drwxr-xr-x 2 hc hc 4096 11月 1 09:48 ./drwxr-xr-x 25 hc hc 4096 10月 31 19:52 ../-rw-r--r-- 1 hc hc 0 11月 1 09:50 file1-rw-r--r-- 1 hc hc 0 11月 1 09:50 file2hc@hc-virtual-machine:~/test$ touch -t 201810011003.17 file2hc@hc-virtual-machine:~/test$ ll总用量 8drwxr-xr-x 2 hc hc 4096 11月 1 09:48 ./drwxr-xr-x 25 hc hc 4096 10月 31 19:52 ../-rw-r--r-- 1 hc hc 0 11月 1 09:50 file1 说明： -t time 使用指定的时间值 time 作为指定文件相应时间戳记的新值。此处的 time规定为如下形式的十进制数: [[CC]YY]MMDDhhmm[.SS] 这里，CC为年数中的前两位，即”世纪数”；YY为年数的后两位，即某世纪中的年数。如果不给出CC的值，则touch 将把年数CCYY限定在1969–2068之内。MM为月数，DD为天将把年数CCYY限定在1969–2068之内。MM为月数，DD为天数，hh 为小时数(几点)，mm为分钟数，SS为秒数。此处秒的设定范围是0–61，这样可以处理闰秒。这些数字组成的时间是环境变量TZ指定的时区中的一个时 间。由于系统的限制，早于1970年1月1日的时间是错误的。]]></content>
      <categories>
        <category>linux每日命令</category>
      </categories>
      <tags>
        <tag>linux命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux每日命令(9)：cp命令]]></title>
    <url>%2F2018%2F10%2F31%2Flinux%E6%AF%8F%E6%97%A5%E5%91%BD%E4%BB%A4(9)%EF%BC%9Acp%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[一．命令格式：cp [参数] source dest 或 cp [参数] source... directory 二．命令功能：将源文件复制至目标文件，或将多个源文件复制至目标目录。 三. 命令参数： 参数 描述 -a 此选项通常在复制目录时使用，它保留链接、文件属性，并复制目录下的所有内容。其作用等于dpR参数组合。 -b –backup,删除、覆盖目的文件先备份，备份的文件或目录亦建立为符号链接，并指向源文件或目录链接的源文件或目录。假如没有加上这个参数，在复制过程中若遇到符号链接，则会直接复制源文件或目录 -d 复制时保留链接。这里所说的链接相当于Windows系统中的快捷方式。 -f 覆盖已经存在的目标文件而不给出提示。 -i 与-f选项相反，在覆盖目标文件之前给出提示，要求用户确认是否覆盖，回答”y”时目标文件将被覆盖。 -n –no-clobber,不要覆盖已存在的文件(使前面的 -i 选项失效) -p –preserve ,除复制文件的内容外，还保留源文件或目录的属性，包括所有者、所属组、权限与修改时间也复制到新文件中。 -P –parents ,保留源文件或目录的路径，此路径可以是绝对路径或相对路径，且目的目录必须已经存在 -r 若给出的源文件是一个目录文件，此时将复制该目录下所有的子目录和文件。 -R –recursive , 递归处理，将指定目录下的文件及子目录一并处理 -s –symbolic-link， 对源文件建立符号链接，而非复制文件 -l 对源文件生成硬链接文件。 四. 命令实例：1. 复制单个文件到目标目录，文件在目标目录中不存在命令： cp log1 dir2 输出： 12345678910111213141516171819202122232425hc@hc-virtual-machine:~/test$ tree ../test/../test/├── dir2├── dir3│ ├── dir1│ ├── file2.txt│ ├── log2│ └── log2~└── log1hc@hc-virtual-machine:~/test$ ll log1 -rw-r--r-- 1 hc hc 0 10月 31 19:18 log1hc@hc-virtual-machine:~/test$ cp log1 dir2hc@hc-virtual-machine:~/test$ tree ../test/../test/├── dir2│ └── log1├── dir3│ ├── dir1│ ├── file2.txt│ ├── log2│ └── log2~└── log1hc@hc-virtual-machine:~/test$ cd dir2hc@hc-virtual-machine:~/test/dir2$ ll log1 -rw-r--r-- 1 hc hc 0 10月 31 19:19 log1 目标文件存在时，会覆盖1234567891011121314hc@hc-virtual-machine:~/test$ ll总用量 16drwxr-xr-x 4 hc hc 4096 10月 31 19:18 ./drwxr-xr-x 25 hc hc 4096 10月 31 19:13 ../drwxr-xr-x 2 hc hc 4096 10月 31 19:19 dir2/drwxr-xr-x 3 hc hc 4096 10月 30 10:08 dir3/-rw-r--r-- 1 hc hc 0 10月 31 19:18 log1hc@hc-virtual-machine:~/test$ cp -a log1 dir2hc@hc-virtual-machine:~/test$ cd dir2hc@hc-virtual-machine:~/test/dir2$ ll总用量 8drwxr-xr-x 2 hc hc 4096 10月 31 19:19 ./drwxr-xr-x 4 hc hc 4096 10月 31 19:18 ../-rw-r--r-- 1 hc hc 0 10月 31 19:18 log1 加上参数 -i会询问是否覆盖，-f强制覆盖说明： 在没有带-a参数时，两个文件的时间是不一样的。在带了-a参数时，两个文件的时间是一致的。 2. 复制整个目录命令： 复制dir3目录到dir2目录下 cp -a dir3 dir2 复制dir2目录到dir3目录下 cp -t dir2 dir3 输出： 目标目录存在时： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455hc@hc-virtual-machine:~/test$ tree ../test/../test/├── dir2│ └── log1├── dir3│ ├── dir1│ ├── file2.txt│ ├── log2│ └── log2~└── log13 directories, 5 fileshc@hc-virtual-machine:~/test$ cp -a dir3 dir2hc@hc-virtual-machine:~/test$ tree ../test/../test/├── dir2│ ├── dir3│ │ ├── dir1│ │ ├── file2.txt│ │ ├── log2│ │ └── log2~│ └── log1├── dir3│ ├── dir1│ ├── file2.txt│ ├── log2│ └── log2~└── log15 directories, 8 fileshc@hc-virtual-machine:~/test$ cp -r dir2 dir3hc@hc-virtual-machine:~/test$ tree ../test/../test/├── dir2│ ├── dir3│ │ ├── dir1│ │ ├── file2.txt│ │ ├── log2│ │ └── log2~│ └── log1├── dir3│ ├── dir1│ ├── dir2│ │ ├── dir3│ │ │ ├── dir1│ │ │ ├── file2.txt│ │ │ ├── log2│ │ │ └── log2~│ │ └── log1│ ├── file2.txt│ ├── log2│ └── log2~└── log18 directories, 12 files 目标目录不存在时：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556hc@hc-virtual-machine:~/test$ lsdir2 dir3 log1hc@hc-virtual-machine:~/test$ cp -r dir2 dir4hc@hc-virtual-machine:~/test$ cp -a dir3 dir5hc@hc-virtual-machine:~/test$ ll总用量 24drwxr-xr-x 6 hc hc 4096 10月 31 19:36 ./drwxr-xr-x 25 hc hc 4096 10月 31 19:13 ../drwxr-xr-x 3 hc hc 4096 10月 31 19:30 dir2/drwxr-xr-x 4 hc hc 4096 10月 31 19:32 dir3/drwxr-xr-x 3 hc hc 4096 10月 31 19:36 dir4/drwxr-xr-x 4 hc hc 4096 10月 31 19:32 dir5/-rw-r--r-- 1 hc hc 0 10月 31 19:18 log1hc@hc-virtual-machine:~/test$ tree ../test/../test/├── dir2│ ├── dir3│ │ ├── dir1│ │ ├── file2.txt│ │ ├── log2│ │ └── log2~│ └── log1├── dir3│ ├── dir1│ ├── dir2│ │ ├── dir3│ │ │ ├── dir1│ │ │ ├── file2.txt│ │ │ ├── log2│ │ │ └── log2~│ │ └── log1│ ├── file2.txt│ ├── log2│ └── log2~├── dir4│ ├── dir3│ │ ├── dir1│ │ ├── file2.txt│ │ ├── log2│ │ └── log2~│ └── log1├── dir5│ ├── dir1│ ├── dir2│ │ ├── dir3│ │ │ ├── dir1│ │ │ ├── file2.txt│ │ │ ├── log2│ │ │ └── log2~│ │ └── log1│ ├── file2.txt│ ├── log2│ └── log2~└── log116 directories, 23 files 说明： 注意目标目录存在与否结果是不一样的。目标目录存在时，整个源目录被复制到目标目录里面。 3.复制的 log.log 建立一个连结档 log_link.log命令： cp -s log1 log1_link 输出： 123456789101112131415hc@hc-virtual-machine:~/test$ lsdir2 dir3 dir4 dir5 log1hc@hc-virtual-machine:~/test$ cp -s log1 log1_linkhc@hc-virtual-machine:~/test$ lsdir2 dir3 dir4 dir5 log1 log1_linkhc@hc-virtual-machine:~/test$ ll总用量 24drwxr-xr-x 6 hc hc 4096 10月 31 19:47 ./drwxr-xr-x 25 hc hc 4096 10月 31 19:13 ../drwxr-xr-x 3 hc hc 4096 10月 31 19:30 dir2/drwxr-xr-x 4 hc hc 4096 10月 31 19:32 dir3/drwxr-xr-x 3 hc hc 4096 10月 31 19:36 dir4/drwxr-xr-x 4 hc hc 4096 10月 31 19:32 dir5/-rw-r--r-- 1 hc hc 0 10月 31 19:18 log1lrwxrwxrwx 1 hc hc 4 10月 31 19:47 log1_link -&gt; log1 说明： 那个 log1_link 是由 -s 的参数造成的，建立的是一个『快捷方式』，所以会看到在文件的最右边，会显示这个文件是『连结』到哪里去的！]]></content>
      <categories>
        <category>linux每日命令</category>
      </categories>
      <tags>
        <tag>linux命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux每日命令(8)：mv命令]]></title>
    <url>%2F2018%2F10%2F30%2Flinux%E6%AF%8F%E6%97%A5%E5%91%BD%E4%BB%A4(8)%EF%BC%9Amv%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[mv命令是move的缩写，可以用来移动文件或者将文件改名（move (rename) files），是Linux系统下常用的命令，经常用来备份文件或者目录。 一．命令格式：mv [选项] 源文件或目录 目标文件或目录 二．命令功能：视mv命令中第二个参数类型的不同（是目标文件还是目标目录），mv命令将文件重命名或将其移至一个新的目录中。当第二个参数类型是文件时，mv命令完成文件重命名，此时，源文件只能有一个（也可以是源目录名），它将所给的源文件或目录重命名为给定的目标文件名。当第二个参数是已存在的目录名称时，源文件或目录参数可以有多个，mv命令将各参数指定的源文件均移至目标目录中。在跨文件系统移动文件时，mv先拷贝，再将原有文件删除，而链至该文件的链接也将丢失。 三．命令参数： 选项 描述 -b 若需覆盖文件，则覆盖前先行备份。 -f force 强制的意思，如果目标文件已经存在，不会询问而直接覆盖 -i 若目标文件 (destination) 已经存在时，就会询问是否覆盖！ -u 若目标文件已经存在，且 source 比较新，才会更新(update) -t 即指定mv的目标目录，该选项适用于移动多个源文件到一个目录的情况，此时目标目录在前，源文件在后。 四．命令实例：1.将文件file1.txt重命名为file2.txt命令： mv file1.txt file2.txt 输出： 12345hc@hc-virtual-machine:~/test$ lsfile1.txthc@hc-virtual-machine:~/test$ mv file1.txt file2.txt hc@hc-virtual-machine:~/test$ lsfile2.txt 2.将文件file2.txt移动到目录dir1中命令： mv file2.txt dir1 输出：123456789101112131415hc@hc-virtual-machine:~/test$ tree ../test/../test/├── dir1│ └── log1└── file2.txt1 directory, 2 fileshc@hc-virtual-machine:~/test$ mv file2.txt dir1hc@hc-virtual-machine:~/test$ tree ../test/../test/└── dir1 ├── file2.txt └── log11 directory, 2 files 3.将文件log1重命名为log2，如果log2已经存在，则询问是否覆盖命令 mv -i log1 log2 输出：12345678910111213hc@hc-virtual-machine:~/test/dir1$ lsfile2.txt log1 log2hc@hc-virtual-machine:~/test/dir1$ cat log1I'm log1hc@hc-virtual-machine:~/test/dir1$ cat log2I'm log2hc@hc-virtual-machine:~/test/dir1$ mv -i log1 log2 mv：是否覆盖'log2'？ yhc@hc-virtual-machine:~/test/dir1$ lsfile2.txt log2hc@hc-virtual-machine:~/test/dir1$ cat log2 I'm log1hc@hc-virtual-machine:~/test/dir1$ 4.将文件log2重命名为log3，无论log3是否存在，不进行询问，直接覆盖命令： mv -f log2 log3 输出：12345678910111213hc@hc-virtual-machine:~/test/dir1$ touch log3hc@hc-virtual-machine:~/test/dir1$ vim log3hc@hc-virtual-machine:~/test/dir1$ lsfile2.txt log2 log3hc@hc-virtual-machine:~/test/dir1$ cat log2I'm log1hc@hc-virtual-machine:~/test/dir1$ cat log3I'm log3hc@hc-virtual-machine:~/test/dir1$ mv -f log2 log3hc@hc-virtual-machine:~/test/dir1$ lsfile2.txt log3hc@hc-virtual-machine:~/test/dir1$ cat log3 I'm log1 说明： -f 这是个危险的选项，使用的时候一定要保持头脑清晰，一般情况下最好不用加上它。 5. 将目录dir1移动到目录dir2中命令： mv dir1 dir2 输出：123456789101112131415161718192021hc@hc-virtual-machine:~/test$ lsdir1hc@hc-virtual-machine:~/test$ mkdir dir2hc@hc-virtual-machine:~/test$ tree ../test/../test/├── dir1│ ├── file2.txt│ └── log3└── dir22 directories, 2 fileshc@hc-virtual-machine:~/test$ mv dir1 dir2hc@hc-virtual-machine:~/test$ tree ../test/../test/└── dir2 └── dir1 ├── file2.txt └── log32 directories, 2 fileshc@hc-virtual-machine:~/test$ 6.将目录dir2重命名为dir3命令： mv dir2 dir3 输出： 123456789101112hc@hc-virtual-machine:~/test$ lsdir2hc@hc-virtual-machine:~/test$ mv dir2 dir3hc@hc-virtual-machine:~/test$ tree ../test/../test/└── dir3 └── dir1 ├── file2.txt └── log32 directories, 2 fileshc@hc-virtual-machine:~/test$ 说明： 当进行目录移动时，如果目标目录名存在，则将源目录移动到目标目录下，成为目标目录的子目录；如果目标目录不存在，则进行重命名操作 7. 移动当前文件夹下的所有文件到上一级目录命令： mv * ../ 输出： 1234567891011121314151617181920212223242526hc@hc-virtual-machine:~/test$ tree dir3/dir3/└── dir1 ├── file2.txt └── log31 directory, 2 fileshc@hc-virtual-machine:~/test$ cd dir3/hc@hc-virtual-machine:~/test/dir3$ lsdir1hc@hc-virtual-machine:~/test/dir3$ cd dir1/hc@hc-virtual-machine:~/test/dir3/dir1$ lsfile2.txt log3hc@hc-virtual-machine:~/test/dir3/dir1$ mv * ../hc@hc-virtual-machine:~/test/dir3/dir1$ lshc@hc-virtual-machine:~/test/dir3/dir1$ cd ..hc@hc-virtual-machine:~/test/dir3$ lsdir1 file2.txt log3hc@hc-virtual-machine:~/test/dir3$ tree ../dir3../dir3├── dir1├── file2.txt└── log31 directory, 2 fileshc@hc-virtual-machine:~/test/dir3$ 8.将目录dir3下的所有内容移到dir2目录下命令： mv dir3/* dir2 输出： 123456789101112131415161718192021222324hc@hc-virtual-machine:~/test$ tree ../test/../test/├── dir2└── dir3 ├── dir1 ├── file2.txt └── log33 directories, 2 fileshc@hc-virtual-machine:~/test$ lsdir2 dir3hc@hc-virtual-machine:~/test$ mv dir3/* dir2hc@hc-virtual-machine:~/test$ lsdir2 dir3hc@hc-virtual-machine:~/test$ tree ../test/../test/├── dir2│ ├── dir1│ ├── file2.txt│ └── log3└── dir33 directories, 2 fileshc@hc-virtual-machine:~/test$ 9.将当前目录（dir2）下的dir1,file2.txt,log3移动到dir3目录下命令： mv -t ../dir3 dir1 file2.txt log3 输出： 123456789101112131415161718192021hc@hc-virtual-machine:~/test$ tree ../test/../test/├── dir2│ ├── dir1│ ├── file2.txt│ └── log3└── dir3hc@hc-virtual-machine:~/test$ cd dir2hc@hc-virtual-machine:~/test/dir2$ lsdir1 file2.txt log3hc@hc-virtual-machine:~/test/dir2$ mv -t ../dir3 dir1 file2.txt log3 hc@hc-virtual-machine:~/test/dir2$ tree ../../test/../../test/├── dir2└── dir3 ├── dir1 ├── file2.txt └── log33 directories, 2 fileshc@hc-virtual-machine:~/test/dir2$ 说明： -t ： –target-directory=DIRECTORY move all SOURCE arguments into DIRECTORY，即指定mv的目标目录，该选项适用于移动多个源文件到一个目录的情况，此时目标目录在前，源文件在后。 10.将log3重命名为log2对log2进行的内容进行覆盖，并给log2源内容进行备份命令： mv log3 -b log2 输出： 1234567891011121314hc@hc-virtual-machine:~/test/dir3$ lsdir1 file2.txt log2 log3hc@hc-virtual-machine:~/test/dir3$ cat log22hc@hc-virtual-machine:~/test/dir3$ cat log3I'm log1hc@hc-virtual-machine:~/test/dir3$ mv log3 -b log2hc@hc-virtual-machine:~/test/dir3$ lsdir1 file2.txt log2 log2~hc@hc-virtual-machine:~/test/dir3$ cat log2I'm log1hc@hc-virtual-machine:~/test/dir3$ cat log2~2hc@hc-virtual-machine:~/test/dir3$ 说明： -b 不接受参数，mv会去读取环境变量VERSION_CONTROL来作为备份策略。 –backup该选项指定如果目标文件存在时的动作，共有四种备份策略： 1.CONTROL=none或off : 不备份。 2.CONTROL=numbered或t：数字编号的备份 3.CONTROL=existing或nil：如果存在以数字编号的备份，则继续编号备份m+1…n： 执行mv操作前已存在以数字编号的文件log2.txt.~1~，那么再次执行将产生log2.txt~2~，以次类推。如果之前没有以数字编号的文件，则使用下面讲到的简单备份。 4.CONTROL=simple或never：使用简单备份：在被覆盖前进行了简单备份，简单备份只能有一份，再次被覆盖时，简单备份也会被覆盖。]]></content>
      <categories>
        <category>linux每日命令</category>
      </categories>
      <tags>
        <tag>linux命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux每日命令(7)：rmdir命令]]></title>
    <url>%2F2018%2F10%2F29%2Flinux%E6%AF%8F%E6%97%A5%E5%91%BD%E4%BB%A4(7)%EF%BC%9Armdir%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[rmdir是常用的命令，该命令的功能是删除空目录，一个目录被删除之前必须是空的。（注意，rm - r dir命令可代替rmdir，但是有很大危险性。）删除某目录时也必须具有对父目录的写权限。 一.命令格式rmdir [参数] 目录 二．命令功能：该命令从一个目录中删除一个或多个子目录项，删除某目录时也必须具有对父目录的写权限。 三．命令参数： 参数 描述 -p 递归删除目录dirname，当子目录删除后其父目录为空时，也一同被删除。如果整个路径被删除或者由于某种原因保留部分路径，则系统在标准输出上显示相应的信息。 -v –verbose,显示指令执行过程 四. 命令示例1.删除空目录dir31命令： rmdir dir31 输出： 123456789101112131415161718192021222324hc@hc-virtual-machine:~$ tree test1/test1/├── dir1│ ├── dir11│ └── file1└── dir2│ └── dir21└── dir3 └── dir314 directories, 1 filehc@hc-virtual-machine:~$ rmdir test1/dir1/file1rmdir: 删除 'test1/dir1/file1' 失败: 不是目录hc@hc-virtual-machine:~$ rmdir test1/dir3rmdir: 删除 'test1/dir3' 失败: 目录非空hc@hc-virtual-machine:~$ rmdir test1/dir3/dir31hc@hc-virtual-machine:~$ tree test1/test1/├── dir1│ ├── dir11│ └── file1└── dir2│ └── dir21└── dir3 说明： rmdir 目录名 ，不能用来删除文件，也不能删除非空目录，只能用来删除单个空目录 2. “递归”删除空目录（此“递归”指“反向递归”，删除父级空目录）命令： rmdir -p test1/dir2/dir21/ 输出： 123456789101112131415161718hc@hc-virtual-machine:~$ tree test1/test1/├── dir1│ ├── dir11│ └── file1└── dir2 └── dir214 directories, 1 filehc@hc-virtual-machine:~$ rmdir -p test1/dir2/dir21/rmdir: 删除目录 'test1' 失败: 目录非空hc@hc-virtual-machine:~$ tree test1/test1/└── dir1 ├── dir11 └── file12 directories, 1 file 说明：删除dir2目录下的dir21目录，如果删除后，dir21目录的父级目录为空目录，则删除其父级目录dir2，如果dir2的目录被删除后，test1目录为空目录，则接着删除，直到遇到父级目录不为空目录，则停止删除 rmdir -p 当该目录的子目录被删除后使其也成为空目录的话，则顺便一并删除该目录 3. 显示删除过程命令： rmdir -pv test1/dir1/dir11/ 输出：123456789101112hc@hc-virtual-machine:~$ lsPycharmProjects snap test1 公共的 模板 视频 图片 文档 下载 音乐 桌面hc@hc-virtual-machine:~$ tree test1/test1/└── dir1 └── dir11hc@hc-virtual-machine:~$ rmdir -pv test1/dir1/dir11/rmdir: 正在删除目录 'test1/dir1/dir11/'rmdir: 正在删除目录 'test1/dir1'rmdir: 正在删除目录 'test1'hc@hc-virtual-machine:~$ lsPycharmProjects snap 公共的 模板 视频 图片 文档 下载 音乐 桌面]]></content>
      <categories>
        <category>linux每日命令</category>
      </categories>
      <tags>
        <tag>linux命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux每日命令(6)：rm命令]]></title>
    <url>%2F2018%2F10%2F26%2Flinux%E6%AF%8F%E6%97%A5%E5%91%BD%E4%BB%A4(6)%EF%BC%9Arm%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[rm是常用的命令，该命令的功能为删除一个目录中的一个或多个文件或目录，它也可以将某个目录及其下的所有文件及子目录均删除。对于链接文件，只是删除了链接，原有文件均保持不变。 rm是一个危险的命令，使用的时候要特别当心，尤其对于新手，否则整个系统就会毁在这个命令（比如在/（根目录）下执行rm * -rf）。所以，我们在执行rm之前最好先确认一下在哪个目录，到底要删除什么东西，操作时保持高度清醒的头脑。 一. 命令格式：rm [选项] 文件 二. 命令功能：删除一个目录中的一个或多个文件或目录，如果没有使用- r参数，则rm不会删除目录。如果使用 rm 来删除文件，通常仍可以将该文件恢复原状。 三. 命令参数选项 参数 描述 -f –force,忽略不存在的文件，从不给出提示。 -i –interactive,进行交互式删除 -r (-R) –recursive , 指示rm将参数中列出的全部目录和子目录均递归地删除。 -v –verbose, 详细显示进行的步骤 –help 显示此帮助信息并退出 –version 输出版本信息并退出 四. 命令实例1. 删除文件命令： rm 文件名 输出： 123456hc@hc-virtual-machine:~/test2/test5$ lsfile1 scf test5-1hc@hc-virtual-machine:~/test2/test5$ rm file1 rm：是否删除普通空文件 'file1'？ yhc@hc-virtual-machine:~/test2/test5$ lsscf test5-1 说明： 输入rm file1命令后，系统会询问是否删除，输入y后就会删除文件，不想删除则数据n。如果没有进行询问，建议加上，毕竟删除操作需谨慎！ 方法： vi ~/.bashrc 然后再里面加入 alias rm=&apos;rm -i&apos; 意思是 rm命令 实际使用的是 rm -i 交互模式，需要进行确认注意，此处 rm 和 = 之间不能有空格，否则会有找不到rm命令的提示， 然后在终端执行这条命令，使得刚才的修改即刻生效： source ~/.bashrc 2. 强行删除file，系统不进行确认提示。命令： rm -f 文件名 输出： 12345hc@hc-virtual-machine:~/test2/test5$ lsfile2 scf test5-1hc@hc-virtual-machine:~/test2/test5$ rm -f file2 hc@hc-virtual-machine:~/test2/test5$ lsscf test5-1 3. 删除当前目录下的所有.log结尾的文件，删除前逐一询问确认命令： rm -i *.log 输出：12345678hc@hc-virtual-machine:~/test2/test5/test5-1$ lslog1.log log2.log log3.loghc@hc-virtual-machine:~/test2/test5/test5-1$ rm -i *.logrm：是否删除普通空文件 'log1.log'？ yrm：是否删除普通空文件 'log2.log'？ yrm：是否删除普通空文件 'log3.log'？ yhc@hc-virtual-machine:~/test2/test5/test5-1$ lshc@hc-virtual-machine:~/test2/test5/test5-1$ 说明： touch 是创建文件的命令 mkdir 是创建目录的命令 touch 1.log 2.log 3.log 如果一次性创建多个连续的文件/目录可以使用{1..3} 例如：一次创建3个.log文件 touch {1..3}.log 4. 删除test5目录及其子目录里的所有的内容命令： rm -r test5 输出：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152hc@hc-virtual-machine:~/test2$ lstest22 test3 test4 test5hc@hc-virtual-machine:~/test2$ tree test5test5├── log.log├── scf│ ├── bin│ ├── doc│ │ ├── info│ │ └── product│ ├── lib│ ├── logs│ │ ├── info│ │ └── product│ └── service│ └── deploy│ ├── info│ └── product└── test5-1 └── log4.log14 directories, 2 fileshc@hc-virtual-machine:~/test2$ lstest22 test3 test4 test5hc@hc-virtual-machine:~/test2$ rm -r test5rm：是否进入目录'test5'? yrm：是否进入目录'test5/scf'? yrm：是否进入目录'test5/scf/logs'? yrm：是否删除目录 'test5/scf/logs/info'？ yrm：是否删除目录 'test5/scf/logs/product'？ yrm：是否删除目录 'test5/scf/logs'？ yrm：是否进入目录'test5/scf/service'? yrm：是否进入目录'test5/scf/service/deploy'? yrm：是否删除目录 'test5/scf/service/deploy/info'？ yrm：是否删除目录 'test5/scf/service/deploy/product'？ yrm：是否删除目录 'test5/scf/service/deploy'？ yrm：是否删除目录 'test5/scf/service'？ yrm：是否删除目录 'test5/scf/bin'？ yrm：是否进入目录'test5/scf/doc'? yrm：是否删除目录 'test5/scf/doc/info'？ yrm：是否删除目录 'test5/scf/doc/product'？ yrm：是否删除目录 'test5/scf/doc'？ yrm：是否删除目录 'test5/scf/lib'？ yrm：是否删除目录 'test5/scf'？ yrm：是否进入目录'test5/test5-1'? yrm：是否删除普通空文件 'test5/test5-1/log4.log'？ yrm：是否删除目录 'test5/test5-1'？ yrm：是否删除普通空文件 'test5/log.log'？ yrm：是否删除目录 'test5'？ yhc@hc-virtual-machine:~/test2$ lstest22 test3 test4hc@hc-virtual-machine:~/test2$ 5. 删除test5目录及其子目录里的所有的内容，且不用进行询问确认命令： rm -rf test5 6. 创建、删除以-开头的文件命令： 在当前目录下创建文件名为-a和-b的文件 方法一： touch ./-a 方法二： touch -- -b 删除当前目录下文件名为-a和-b 的文件 方法一： rm -- -a 方法二： rm ./-b 输出： 12345678910111213141516171819202122hc@hc-virtual-machine:~/test2/test4$ lshc@hc-virtual-machine:~/test2/test4$ touch -atouch: 缺少了文件操作数Try 'touch --help' for more information.hc@hc-virtual-machine:~/test2/test4$ touch ./-ahc@hc-virtual-machine:~/test2/test4$ ls-ahc@hc-virtual-machine:~/test2/test4$ touch -- -bhc@hc-virtual-machine:~/test2/test4$ ls-a -bhc@hc-virtual-machine:~/test2/test4$ rm -arm: 不适用的选项 -- aTry 'rm ./-a' to remove the file '-a'.Try 'rm --help' for more information.hc@hc-virtual-machine:~/test2/test4$ rm -- -arm：是否删除普通空文件 '-a'？ yhc@hc-virtual-machine:~/test2/test4$ ls-bhc@hc-virtual-machine:~/test2/test4$ rm ./-brm：是否删除普通空文件 './-b'？ yhc@hc-virtual-machine:~/test2/test4$ lshc@hc-virtual-machine:~/test2/test4$ 说明： 档名最好不要使用 “-“ 号开头， 因为 “-“ 后面接的是选项，因此，单纯的使用『 rm -a 』系统的命令就会误判。所以，只能用避过首位字节是 “-“ 的方法啦！ 就是加上本目录『 ./ 』即可！如果 man rm 查看使用方法的话，其实还有一种方法，那就是『 rm – -f 』（另外一种方法而已）。 7. 自定义回收站功能命令： myrm(){ D=/tmp/$(date +%Y%m%d%H%M%S); mkdir -p $D; mv &quot;$@&quot; $D &amp;&amp; echo &quot;moved to $D ok&quot;; } 说明：1234567891011121314myrm()&#123; D=/tmp/$(date +%Y%m%d%H%M%S); #在/tmp文件夹中创建名为“当前日期”的文件；#其中“date+%Y%m%d%H%M%S”是规定了日期的输出格式；mkdir -p $D; #以变量D中的路径创建文件夹。mv "$@" $D &amp;&amp; echo "moved to $D ok"; #将所要删除的文件移入变量D中的文件夹内，移入成功后，输出移动成功。&#125;alias rm='myrm'#命令别名定义方式，此定义成功后，无论输入rm或myrm系统都会做出相同操作。 输出：123456789101112131415hc@hc-virtual-machine:/tmp$ myrm()&#123; D=/tmp/$(date +%Y%m%d%H%M%S); mkdir -p $D; mv "$@" $D &amp;&amp; echo "moved to $D ok"; &#125;hc@hc-virtual-machine:/tmp$ alias rm='myrm'hc@hc-virtual-machine:/tmp$ touch &#123;1..4&#125;.loghc@hc-virtual-machine:/tmp$ ls1.log 2.log 3.log 4.loghc@hc-virtual-machine:/tmp$ rm [1234].logmoved to /tmp/20181026111028 okhc@hc-virtual-machine:/tmp$ ls20181026111028hc@hc-virtual-machine:/tmp$ cd 20181026111028/hc@hc-virtual-machine:/tmp/20181026111028$ ls1.log 2.log 3.log 4.log 说明： 上面的操作过程模拟了回收站的效果，即删除文件的时候只是把文件放到一个临时目录中，这样在需要的时候还可以恢复过来。 由于我们当前已将rm绑定为myrm，所以我们无法执行删除操作 临时设置rm命令别名为myrm alias rm=&apos;myrm&apos; 此时若想删除回收站里的文件，由于是临时的，所以换一个命令行窗口后，绑定就会失效即换一个命令行窗口执行rm -r 命令删除即可 如果不想换命令行窗口，可以用 sudo rm -rf 目录名 删除回收站的文件 或者解除临时绑定 unalias rm 输出： 1234567891011121314151617181920hc@hc-virtual-machine:/tmp/20181026111444$ alias alias alert='notify-send --urgency=low -i "$([ $? = 0 ] &amp;&amp; echo terminal || echo error)" "$(history|tail -n1|sed -e '\''s/^\s*[0-9]\+\s*//;s/[;&amp;|]\s*alert$//'\'')"'alias egrep='egrep --color=auto'alias fgrep='fgrep --color=auto'alias grep='grep --color=auto'alias l='ls -CF'alias la='ls -A'alias ll='ls -alF'alias ls='ls --color=auto'alias rm='myrm'hc@hc-virtual-machine:/tmp/20181026111444$ unalias rmhc@hc-virtual-machine:/tmp/20181026111444$ alias alias alert='notify-send --urgency=low -i "$([ $? = 0 ] &amp;&amp; echo terminal || echo error)" "$(history|tail -n1|sed -e '\''s/^\s*[0-9]\+\s*//;s/[;&amp;|]\s*alert$//'\'')"'alias egrep='egrep --color=auto'alias fgrep='fgrep --color=auto'alias grep='grep --color=auto'alias l='ls -CF'alias la='ls -A'alias ll='ls -alF'alias ls='ls --color=auto']]></content>
      <categories>
        <category>linux每日命令</category>
      </categories>
      <tags>
        <tag>linux命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux每日命令(5)：mkdir命令]]></title>
    <url>%2F2018%2F10%2F25%2Flinux%E6%AF%8F%E6%97%A5%E5%91%BD%E4%BB%A4(5)%EF%BC%9Amkdir%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[linux mkdir 命令用来创建指定的名称的目录，要求创建目录的用户在当前目录中具有写权限，并且指定的目录名不能是当前目录中已有的目录。 1．命令格式：mkdir [选项] 目录名或路径名 2．命令功能：通过 mkdir 命令可以实现在指定位置创建以 DirName(指定的文件名)命名的文件夹或目录。要创建文件夹或目录的用户必须对所创建的文件夹的父文件夹具有写权限。并且，所创建的文件夹(目录)不能与其父目录(即父文件夹)中的文件名重名，即同一个目录下不能有同名的(区分大小写)。 3．命令参数： 参数 描述 -m –mode=模式，设定权限&lt;模式&gt; (类似 chmod) -p –parents 可以是一个路径名称。此时若路径中的某些目录尚不存在,加上此选项后,系统将自动建立好那些尚不存在的目录,即一次可以建立多个目录; -v –verbose , 每次创建新目录都显示信息 –help 显示此帮助信息并退出 –version 输出版本信息并退出 4．命令实例：1：创建一个空目录命令： mkdir test1 输出： 12345hc@hc-virtual-machine:~$ lsPycharmProjects snap 公共的 模板 视频 图片 文档 下载 音乐 桌面hc@hc-virtual-machine:~$ mkdir test1hc@hc-virtual-machine:~$ lsPycharmProjects snap test1 公共的 模板 视频 图片 文档 下载 音乐 桌面 2：递归创建多个目录命令： mkdir -p test2/test22 输出： 1234567hc@hc-virtual-machine:~$ mkdir -p test2/test22hc@hc-virtual-machine:~$ lsPycharmProjects test1 公共的 视频 文档 音乐snap test2 模板 图片 下载 桌面hc@hc-virtual-machine:~$ cd test2/hc@hc-virtual-machine:~/test2$ lstest22 3：创建权限为777的目录命令： mkdir -m 777 test3 输出： 1234567hc@hc-virtual-machine:~/test2$ mkdir -m 777 test3hc@hc-virtual-machine:~/test2$ ll总用量 16drwxrwxr-x 4 hc hc 4096 10月 25 09:13 ./drwxr-xr-x 25 hc hc 4096 10月 25 09:11 ../drwxrwxr-x 2 hc hc 4096 10月 25 09:11 test22/drwxrwxrwx 2 hc hc 4096 10月 25 09:13 test3/ 说明： ll 与 ls -l 命令效果相同 test3 的权限为rwxrwxrwx 4：创建新目录并显示创建信息命令： mkdir -v test4 输出： 1234hc@hc-virtual-machine:~/test2$ mkdir -v test4mkdir: 已创建目录 'test4'hc@hc-virtual-machine:~/test2$ lstest22 test3 test4 5：创建目录及其子目录并显示创建信息命令： mkdir -vp test5/test5-1 输出： 12345678hc@hc-virtual-machine:~/test2$ mkdir -vp test5/test5-1mkdir: 已创建目录 'test5'mkdir: 已创建目录 'test5/test5-1'hc@hc-virtual-machine:~/test2$ lstest22 test3 test4 test5hc@hc-virtual-machine:~/test2$ cd test5/hc@hc-virtual-machine:~/test2/test5$ lstest5-1 6. 通过一个命令创建出项目的目录结构命令： mkdir -vp scf/{lib/,bin/,doc/{info,product},logs/{info,product},service/deploy/{info,product}} 输出： 12345678910111213141516171819202122232425262728293031323334353637hc@hc-virtual-machine:~/test2/test5$ lstest5-1hc@hc-virtual-machine:~/test2/test5$ pwd/home/hc/test2/test5hc@hc-virtual-machine:~/test2/test5$ mkdir -vp scf/&#123;lib/,bin/,doc/&#123;info,product&#125;,logs/&#123;info,product&#125;,service/deploy/&#123;info,product&#125;&#125;mkdir: 已创建目录 'scf'mkdir: 已创建目录 'scf/lib/'mkdir: 已创建目录 'scf/bin/'mkdir: 已创建目录 'scf/doc'mkdir: 已创建目录 'scf/doc/info'mkdir: 已创建目录 'scf/doc/product'mkdir: 已创建目录 'scf/logs'mkdir: 已创建目录 'scf/logs/info'mkdir: 已创建目录 'scf/logs/product'mkdir: 已创建目录 'scf/service'mkdir: 已创建目录 'scf/service/deploy'mkdir: 已创建目录 'scf/service/deploy/info'mkdir: 已创建目录 'scf/service/deploy/product'hc@hc-virtual-machine:~/test2/test5$ lsscf test5-1hc@hc-virtual-machine:~/test2/test5$ tree scf/scf/├── bin├── doc│ ├── info│ └── product├── lib├── logs│ ├── info│ └── product└── service └── deploy ├── info └── product12 directories, 0 fileshc@hc-virtual-machine:~/test2/test5$ 说明： tree命令可以用来查看目录树，需要自行安装后才能使用，Ubuntu安装命令： apt install tree]]></content>
      <categories>
        <category>linux每日命令</category>
      </categories>
      <tags>
        <tag>linux命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux每日命令(4)：pwd命令]]></title>
    <url>%2F2018%2F10%2F24%2Flinux%E6%AF%8F%E6%97%A5%E5%91%BD%E4%BB%A4(4)%EF%BC%9Apwd%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[Linux中用 pwd 命令来查看”当前工作目录“的完整路径。 简单得说，每当你在终端进行操作时，你都会有一个当前工作目录。 在不太确定当前位置时，就会使用pwd来判定当前目录在文件系统内的确切位置。 1．命令格式：pwd [参数] 2. 命令功能： pwd 代表的是‘Print Working Directory’（打印当前目录）。如它的名字那样，‘pwd’会打印出当前工作目录，或简单的来说就是当前用户所位于的目录。它会打印出以根目录 (/)为起点的完整目录名（绝对目录） 3. 常用参数：一般情况下不带任何参数 参数 描述 -L 即逻辑路径logical，当目录为连接路径时，显示连接路径 -P 即物理路径physical，显示实际物理路径，而非使用连接（link）路径 如果同时使用了‘-L‘和‘-P‘，‘-L‘会有更高的优先级。如果没有指定参数，pwd会避开所有的软链接，也就是说会使用‘-P‘参数。 4. 常用示例1. 查看pwd命令命令： man pwd 输出:123456789101112131415161718192021222324PWD(1) User Commands PWD(1)NAME pwd - print name of current/working directorySYNOPSIS pwd [OPTION]...DESCRIPTION Print the full filename of the current working directory. -L, --logical use PWD from environment, even if it contains symlinks -P, --physical avoid all symlinks --help display this help and exit --version output version information and exit If no option is specified, -P is assumed. Manual page pwd(1) line 1 (press h for help or q to quit) 2. 显示当前目录所在路径.命令： pwd 输出：12hc@hc-virtual-machine:~/PycharmProjects/py3_test$ pwd/home/hc/PycharmProjects/py3_test 目录结构如下：1234567891011121314151617181920212223242526272829hc@hc-virtual-machine:~/PycharmProjects$ tree -L 2.├── FreshOnline│ ├── apps│ ├── db_tools│ ├── extra_apps│ ├── FreshMartOnline│ ├── manage.py│ ├── media│ ├── README.md│ └── requirements.txt├── FreshOnline_env│ ├── bin│ ├── include│ ├── lib│ ├── lib64 -&gt; lib│ ├── pip-selfcheck.json│ ├── pyvenv.cfg│ └── share├── my_test│ ├── 2018.log│ ├── link2018 -&gt; 2018.log│ ├── ln2018│ └── test├── py3_test│ ├── t1.py│ └── venv└── test └── my_test -&gt; /home/hc/PycharmProjects/my_test 说明：目录为连接路径时，pwd -P 显示出实际路径，而非使用连接（link）路径；pwd显示的是连接路径 示例如下： PycharmProjects/test目录下有一个my_test连接文件,指向PycharmProjects/my_test目录,进入test目录下的my_test目录，使用pwd，显示结果与pwd -L 一致，是逻辑（连接）路径，要查看实际物理路径则使用pwd -P 1234567891011121314hc@hc-virtual-machine:~/PycharmProjects/test$ pwd/home/hc/PycharmProjects/testhc@hc-virtual-machine:~/PycharmProjects/test$ ll总用量 8drwxr-xr-x 2 hc hc 4096 10月 23 13:38 ./drwxrwxr-x 7 hc hc 4096 10月 23 13:30 ../lrwxrwxrwx 1 hc hc 32 10月 23 13:38 my_test -&gt; /home/hc/PycharmProjects/my_test/hc@hc-virtual-machine:~/PycharmProjects/test$ cd my_testhc@hc-virtual-machine:~/PycharmProjects/test/my_test$ pwd/home/hc/PycharmProjects/test/my_testhc@hc-virtual-machine:~/PycharmProjects/test/my_test$ pwd -P/home/hc/PycharmProjects/my_testhc@hc-virtual-machine:~/PycharmProjects/test/my_test$ pwd -L/home/hc/PycharmProjects/test/my_test 3. 多层连接文件时，显示所有连接文件最终指向的文件全路径 /root目录下面有个dir1目录，test连接文件指向dir1目录 /opt目录下面有一个test连接文件，指向/root/test连接文件 通过cd命令进入/opt/test pwd默认，只显示连接文件的全路径 123456789101112131415root@hc-virtual-machine:~# pwd/rootroot@hc-virtual-machine:~# ll total 12drwxr-xr-x 2 root root 4096 Apr 24 05:51 dir1lrwxrwxrwx 1 root root 5 Apr 24 05:54 test -&gt; dir1/root@hc-virtual-machine:~# ll /opt/ total 20drwx------ 16 sgl sgl 4096 Oct 17 2015 sgllrwxrwxrwx 1 root root 10 Apr 24 05:55 test -&gt; /root/testroot@hc-virtual-machine:~# cd /opt/test/ root@hc-virtual-machine:~# pwd /opt/testroot@hc-virtual-machine:~# pwd -P /root/dir1 pwd -P 显示连接文件最终指向的文件的全路径。注意这里不是/root/test。]]></content>
      <categories>
        <category>linux每日命令</category>
      </categories>
      <tags>
        <tag>linux命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[如何优雅的退出关闭重启gunicorn进程]]></title>
    <url>%2F2018%2F10%2F24%2F%E5%A6%82%E4%BD%95%E4%BC%98%E9%9B%85%E7%9A%84%E9%80%80%E5%87%BA%E5%85%B3%E9%97%AD%E9%87%8D%E5%90%AFgunicorn%E8%BF%9B%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[在工作中，会发现gunicorn启动的web服务，无论怎么使用kill -9 进程号都是无法杀死gunicorn，经过我一番百度和谷歌，发现想要删除gunicorn进程其实很简单。 1. 寻找masterpid通过执行如下命令，可以获取Gunicorn进程树： 1pstree -ap|grep gunicorn 得到如下的结果。 1234567891011121314151617181920212223242526|-grep,6194 --col gunicorn | `-gunicorn,30080 /usr/local/bin/gunicorn collect:app -c collect_gunicorn.py | |-gunicorn,4413 /usr/local/bin/gunicorn collect:app -c collect_gunicorn.py | |-gunicorn,8030 /usr/local/bin/gunicorn collect:app -c collect_gunicorn.py | |-gunicorn,8135 /usr/local/bin/gunicorn collect:app -c collect_gunicorn.py | |-gunicorn,8137 /usr/local/bin/gunicorn collect:app -c collect_gunicorn.py | |-gunicorn,11532 /usr/local/bin/gunicorn collect:app -c collect_gunicorn.py | |-gunicorn,13460 /usr/local/bin/gunicorn collect:app -c collect_gunicorn.py | |-gunicorn,19728 /usr/local/bin/gunicorn collect:app -c collect_gunicorn.py | |-gunicorn,23585 /usr/local/bin/gunicorn collect:app -c collect_gunicorn.py | |-gunicorn,23825 /usr/local/bin/gunicorn collect:app -c collect_gunicorn.py | |-gunicorn,27921 /usr/local/bin/gunicorn collect:app -c collect_gunicorn.py | |-gunicorn,28899 /usr/local/bin/gunicorn collect:app -c collect_gunicorn.py | |-gunicorn,28900 /usr/local/bin/gunicorn collect:app -c collect_gunicorn.py | |-gunicorn,28901 /usr/local/bin/gunicorn collect:app -c collect_gunicorn.py | |-gunicorn,35637 /usr/local/bin/gunicorn collect:app -c collect_gunicorn.py | |-gunicorn,36963 /usr/local/bin/gunicorn collect:app -c collect_gunicorn.py | |-gunicorn,43074 /usr/local/bin/gunicorn collect:app -c collect_gunicorn.py | |-gunicorn,43118 /usr/local/bin/gunicorn collect:app -c collect_gunicorn.py | |-gunicorn,43232 /usr/local/bin/gunicorn collect:app -c collect_gunicorn.py | |-gunicorn,43307 /usr/local/bin/gunicorn collect:app -c collect_gunicorn.py | |-gunicorn,43308 /usr/local/bin/gunicorn collect:app -c collect_gunicorn.py | |-gunicorn,44018 /usr/local/bin/gunicorn collect:app -c collect_gunicorn.py | |-gunicorn,46996 /usr/local/bin/gunicorn collect:app -c collect_gunicorn.py | |-gunicorn,47000 /usr/local/bin/gunicorn collect:app -c collect_gunicorn.py | `-gunicorn,47650 /usr/local/bin/gunicorn collect:app -c collect_gunicorn.py 很显然，30080就是Gunicorn的主进程。 2. 重启Gunicorn任务按照官方的推荐方法，很容易执行命令： 1kill -HUP 30080 执行上述命令后，再次执行“pstree -ap|grep gunicorn”，我们很容易发现，除了主进程，其他的Gunicorn进程都已经销毁，并新建了进程（进程ID发生了变化）。 3. 退出Gunicorn任务1kill -9 30080 转自:http://www.chenxm.cc/post/541.html?csdn]]></content>
      <categories>
        <category>工具</category>
      </categories>
      <tags>
        <tag>gunicorn</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux每日命令(3)：ln命令]]></title>
    <url>%2F2018%2F10%2F23%2Flinux%E6%AF%8F%E6%97%A5%E5%91%BD%E4%BB%A4(3)%EF%BC%9Aln%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[ln是linux中又一个非常重要命令，它的功能是为某一个文件在另外一个位置建立一个同步的链接.当我们需要在不同的目录，用到相同的文件时，我们不需要在每一个需要的目录下都放一个必须相同的文件，我们只要在某个固定的目录，放上该文件，然后在 其它的目录下用ln命令链接（link）它就可以，不必重复的占用磁盘空间。 1．命令格式：ln [参数][源文件或目录][目标文件或目录] 2．命令功能： Linux文件系统中，有所谓的链接(link)，我们可以将其视为档案的别名，而链接又可分为两种 : 硬链接(hard link)与软链接(symbolic link)，硬链接的意思是一个档案可以有多个名称，而软链接的方式则是产生一个特殊的档案，该档案的内容是指向另一个档案的位置。硬链接是存在同一个文件系统中，而软链接却可以跨越不同的文件系统。 软链接： 软链接，以路径的形式存在。类似于Windows操作系统中的快捷方式 软链接可以 跨文件系统 ，硬链接不可以 软链接可以对一个不存在的文件名进行链接 软链接可以对目录进行链接 软链接就相当于windows的的快捷方式，使用场景：1.在文件系统中多处共享同一个较大文件时，使用软链接就可以避免创建多个副本。2.维护动态库文件的版本时，使用软链接，在升级库文件后，只需修改软链接的源文件，而使用该库的程序则不需要修改。 使用原文件的绝对路径创建的软链接，不会随着软链接路径改动而失效！所以建议使用原文件绝对路径创建软链接。这时候的软链接才算得上是真正意义上相当于Windows的快捷方式，一旦生成处处可用 硬链接: 硬链接，以文件副本的形式存在。但不占用实际空间。 不允许给目录创建硬链接 硬链接只有在同一个文件系统中才能创建 硬链接说白了是一个指针，指向文件索引节点，系统并不为它重新分配inode。源文件和硬链接文件都是指向同一块磁盘空间的！通过使用硬链接可达到备份数据(实际是备份节点)的效果！ 注意：第一，ln命令会保持每一处链接文件的同步性，也就是说，不论你改动了哪一处，其它的文件都会发生相同的变化； 第二，ln的链接又分软链接和硬链接两种，软链接就是ln –s 源文件 目标文件，它只会在你选定的位置上生成一个文件的镜像，不会占用磁盘空间，硬链接 ln 源文件 目标文件，没有参数-s， 它会在你选定的位置上生成一个和源文件大小相同的文件，无论是软链接还是硬链接，文件都保持同步变化。 ln指令用在链接文件或目录，如同时指定两个以上的文件或目录，且最后的目的地是一个已经存在的目录，则会把前面指定的所有文件或目录复制到该目录。若同时指定多个文件或目录，且最后的目的地并非是一个已存在的目录，则会出现错误信息。 3. 命令参数： 必要参数 描述 -b 删除，覆盖以前建立的链接 -d 允许超级用户制作目录的硬链接 -f 强制执行 -i 交互模式，文件存在则提示用户是否覆盖 -n 把符号链接视为一般目录 -s 软链接(符号链接) -v 显示详细的处理过程 选择参数 描述 -S “-S&lt;字尾备份字符串&gt; ”或 “–suffix=&lt;字尾备份字符串&gt;” -V “-V&lt;备份方式&gt;”或“–version-control=&lt;备份方式&gt;” –help 显示帮助信息 –version 显示版本信息 4. 常用示例1. 给2018.log创建一个名为link2018的软链接命令： ln -s 2018.log link2018 输出：123456789101112hc@hc-virtual-machine:~/PycharmProjects/my_test$ ls2018.loghc@hc-virtual-machine:~/PycharmProjects/my_test$ ln -s 2018.log link2018hc@hc-virtual-machine:~/PycharmProjects/my_test$ ls2018.log link2018hc@hc-virtual-machine:~/PycharmProjects/my_test$ ll总用量 12drwxrwxr-x 3 hc hc 4096 10月 23 11:53 ./drwxrwxr-x 6 hc hc 4096 10月 19 18:22 ../-rw-r--r-- 1 hc hc 0 10月 23 11:53 2018.logdrwxrwxr-x 2 hc hc 4096 10月 18 17:42 .idea/lrwxrwxrwx 1 hc hc 8 10月 23 11:53 link2018 -&gt; 2018.log 修改源文件2018.log内容，其软链接内容会同步修改123456789hc@hc-virtual-machine:~/PycharmProjects/my_test$ cat 2018.log 我是log日志hc@hc-virtual-machine:~/PycharmProjects/my_test$ cat link2018我是log日志hc@hc-virtual-machine:~/PycharmProjects/my_test$ vim 2018.log hc@hc-virtual-machine:~/PycharmProjects/my_test$ cat 2018.log 我是loghc@hc-virtual-machine:~/PycharmProjects/my_test$ cat link2018.log 我是log 说明： cat 命令是查看文件内容为2018.log文件创建软链接link2018，如果2018.log丢失，link2018将失效 2. 为2018.log 创建一个硬链接ln2018命令： ln 2018.log ln2018 输出：12345678910111213hc@hc-virtual-machine:~/PycharmProjects/my_test$ ls2018.log link2018hc@hc-virtual-machine:~/PycharmProjects/my_test$ ln 2018.log ln2018hc@hc-virtual-machine:~/PycharmProjects/my_test$ ls2018.log link2018 ln2018hc@hc-virtual-machine:~/PycharmProjects/my_test$ ll总用量 20drwxrwxr-x 3 hc hc 4096 10月 23 12:02 ./drwxrwxr-x 6 hc hc 4096 10月 19 18:22 ../-rw-r--r-- 2 hc hc 10 10月 23 11:57 2018.logdrwxrwxr-x 2 hc hc 4096 10月 18 17:42 .idea/lrwxrwxrwx 1 hc hc 8 10月 23 12:00 link2018 -&gt; 2018.log-rw-r--r-- 2 hc hc 10 10月 23 11:57 ln2018 说明： 为2018.log创建硬链接ln2018，2018.log与ln2018的各项属性相同 修改源文件2018.log内容，其软硬链接内容均会同步修改1234567891011hc@hc-virtual-machine:~/PycharmProjects/my_test$ cat ln2018 我是loghc@hc-virtual-machine:~/PycharmProjects/my_test$ cat 2018.log 我是loghc@hc-virtual-machine:~/PycharmProjects/my_test$ vim 2018.log hc@hc-virtual-machine:~/PycharmProjects/my_test$ cat 2018.log 我是log1hc@hc-virtual-machine:~/PycharmProjects/my_test$ cat ln2018 我是log1hc@hc-virtual-machine:~/PycharmProjects/my_test$ cat link2018 我是log1 3. 接上面两实例，链接完毕后，删除和重建链接原文件演示如下：1234567891011121314151617181920212223242526272829303132333435hc@hc-virtual-machine:~/PycharmProjects/my_test$ ls2018.log link2018 ln2018hc@hc-virtual-machine:~/PycharmProjects/my_test$ ll总用量 20drwxrwxr-x 3 hc hc 4096 10月 23 12:04 ./drwxrwxr-x 6 hc hc 4096 10月 19 18:22 ../-rw-r--r-- 2 hc hc 11 10月 23 12:04 2018.logdrwxrwxr-x 2 hc hc 4096 10月 18 17:42 .idea/lrwxrwxrwx 1 hc hc 8 10月 23 12:00 link2018 -&gt; 2018.log-rw-r--r-- 2 hc hc 11 10月 23 12:04 ln2018hc@hc-virtual-machine:~/PycharmProjects/my_test$ rm -rf 2018.log hc@hc-virtual-machine:~/PycharmProjects/my_test$ ll总用量 16drwxrwxr-x 3 hc hc 4096 10月 23 12:57 ./drwxrwxr-x 6 hc hc 4096 10月 19 18:22 ../drwxrwxr-x 2 hc hc 4096 10月 18 17:42 .idea/lrwxrwxrwx 1 hc hc 8 10月 23 12:00 link2018 -&gt; 2018.log-rw-r--r-- 1 hc hc 11 10月 23 12:04 ln2018hc@hc-virtual-machine:~/PycharmProjects/my_test$ touch 2018.loghc@hc-virtual-machine:~/PycharmProjects/my_test$ ll总用量 16drwxrwxr-x 3 hc hc 4096 10月 23 12:57 ./drwxrwxr-x 6 hc hc 4096 10月 19 18:22 ../-rw-r--r-- 1 hc hc 0 10月 23 12:57 2018.logdrwxrwxr-x 2 hc hc 4096 10月 18 17:42 .idea/lrwxrwxrwx 1 hc hc 8 10月 23 12:00 link2018 -&gt; 2018.log-rw-r--r-- 1 hc hc 11 10月 23 12:04 ln2018hc@hc-virtual-machine:~/PycharmProjects/my_test$ vim 2018.log hc@hc-virtual-machine:~/PycharmProjects/my_test$ cat 2018.log 2018log日志hc@hc-virtual-machine:~/PycharmProjects/my_test$ cat link2018 2018log日志hc@hc-virtual-machine:~/PycharmProjects/my_test$ cat ln2018 我是log1hc@hc-virtual-machine:~/PycharmProjects/my_test$ 说明： 源文件被删除后，并没有影响硬链接文件；软链接文件在centos系统下不断的闪烁，提示源文件已经不存在 重建源文件后，软链接不在闪烁提示，说明已经链接成功，找到了链接文件系统；重建后，硬链接文件并没有受到源文件影响，硬链接文件的内容还是保留了删除前源文件的内容，说明硬链接已经失效 4. 将文件链接到目录中演示如下：1234567891011121314151617181920212223242526272829hc@hc-virtual-machine:~/PycharmProjects/my_test$ ls2018.log link2018 ln2018hc@hc-virtual-machine:~/PycharmProjects/my_test$ mkdir testhc@hc-virtual-machine:~/PycharmProjects/my_test$ ls2018.log link2018 ln2018 testhc@hc-virtual-machine:~/PycharmProjects/my_test$ ln 2018.log testhc@hc-virtual-machine:~/PycharmProjects/my_test$ ls2018.log link2018 ln2018 testhc@hc-virtual-machine:~/PycharmProjects/my_test$ cd test/hc@hc-virtual-machine:~/PycharmProjects/my_test/test$ ls2018.loghc@hc-virtual-machine:~/PycharmProjects/my_test/test$ vi 2018.log hc@hc-virtual-machine:~/PycharmProjects/my_test/test$ cat 2018.log 2018log日志,加1hc@hc-virtual-machine:~/PycharmProjects/my_test/test$ cd ..hc@hc-virtual-machine:~/PycharmProjects/my_test$ ls2018.log link2018 ln2018 testhc@hc-virtual-machine:~/PycharmProjects/my_test$ cat 2018.log 2018log日志,加1hc@hc-virtual-machine:~/PycharmProjects/my_test$ ll总用量 24drwxrwxr-x 4 hc hc 4096 10月 23 13:31 ./drwxrwxr-x 7 hc hc 4096 10月 23 13:30 ../-rw-r--r-- 2 hc hc 19 10月 23 13:32 2018.logdrwxrwxr-x 2 hc hc 4096 10月 18 17:42 .idea/lrwxrwxrwx 1 hc hc 8 10月 23 12:00 link2018 -&gt; 2018.log-rw-r--r-- 1 hc hc 11 10月 23 12:04 ln2018drwxr-xr-x 2 hc hc 4096 10月 23 13:32 test/hc@hc-virtual-machine:~/PycharmProjects/my_test$ 说明： 在test目录中创建了2018.log的硬链接，修改test目录中的2018.log文件，同时也会同步到源文件 5：给目录创建软链接命令： ln -sv 源目录 目标目录 演示如下：12345678910111213141516171819202122232425262728293031323334353637383940hc@hc-virtual-machine:~/PycharmProjects$ ll总用量 28drwxrwxr-x 7 hc hc 4096 10月 23 13:30 ./drwxr-xr-x 23 hc hc 4096 10月 23 13:32 ../drwxr-xr-x 9 hc hc 4096 10月 22 15:25 FreshOnline/drwxrwxr-x 6 hc hc 4096 10月 19 19:07 FreshOnline_env/drwxrwxr-x 4 hc hc 4096 10月 23 13:31 my_test/drwxrwxr-x 4 hc hc 4096 10月 23 11:52 py3_test/drwxr-xr-x 2 hc hc 4096 10月 23 13:30 test/hc@hc-virtual-machine:~/PycharmProjects$ ln -sv /home/hc/PycharmProjects/my_test /home/hc/PycharmProjects/test'/home/hc/PycharmProjects/test/my_test' -&gt; '/home/hc/PycharmProjects/my_test'hc@hc-virtual-machine:~/PycharmProjects$ ll总用量 28drwxrwxr-x 7 hc hc 4096 10月 23 13:30 ./drwxr-xr-x 23 hc hc 4096 10月 23 13:32 ../drwxr-xr-x 9 hc hc 4096 10月 22 15:25 FreshOnline/drwxrwxr-x 6 hc hc 4096 10月 19 19:07 FreshOnline_env/drwxrwxr-x 4 hc hc 4096 10月 23 13:31 my_test/drwxrwxr-x 4 hc hc 4096 10月 23 11:52 py3_test/drwxr-xr-x 2 hc hc 4096 10月 23 13:38 test/hc@hc-virtual-machine:~/PycharmProjects$ cd my_test/hc@hc-virtual-machine:~/PycharmProjects/my_test$ ls2018.log link2018 ln2018 testhc@hc-virtual-machine:~/PycharmProjects/my_test$ cd ..hc@hc-virtual-machine:~/PycharmProjects$ lsFreshOnline FreshOnline_env my_test py3_test testhc@hc-virtual-machine:~/PycharmProjects$ cd test/hc@hc-virtual-machine:~/PycharmProjects/test$ lsmy_testhc@hc-virtual-machine:~/PycharmProjects/test$ cd my_testhc@hc-virtual-machine:~/PycharmProjects/test/my_test$ ls2018.log link2018 ln2018 testhc@hc-virtual-machine:~/PycharmProjects/test/my_test$ cd ..hc@hc-virtual-machine:~/PycharmProjects/test$ lsmy_testhc@hc-virtual-machine:~/PycharmProjects/test$ ll总用量 8drwxr-xr-x 2 hc hc 4096 10月 23 13:38 ./drwxrwxr-x 7 hc hc 4096 10月 23 13:30 ../lrwxrwxrwx 1 hc hc 32 10月 23 13:38 my_test -&gt; /home/hc/PycharmProjects/my_test/ 说明： 目录只能创建软链接 目录创建链接必须用绝对路径，相对路径创建会不成功，会提示：符号连接的层数过多 这样的错误 使用原文件的绝对路径创建的软链接，不会随着软链接路径改动而失效！所以建议使用原文件绝对路径创建软链接。这时候的软链接才算得上是真正意义上相当于Windows的快捷方式，一旦生成处处可用 在链接目标目录中修改文件都会在源文件目录中同步变化]]></content>
      <categories>
        <category>linux每日命令</category>
      </categories>
      <tags>
        <tag>linux命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux每日命令(2)：cd命令]]></title>
    <url>%2F2018%2F10%2F22%2Flinux%E6%AF%8F%E6%97%A5%E5%91%BD%E4%BB%A4(2)%EF%BC%9Acd%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[1.命令格式：cd [目录名] 2.命令功能切换当前目录至 [目录名] 3. 常用范例1.进入系统根目录命令： cd / 说明：进入系统根目录,上面命令执行完后拿ls命令看一下，当前目录已经到系统根目录了 输出：1234567hc@hc-virtual-machine:~$ pwd/home/hchc@hc-virtual-machine:~$ cd /hc@hc-virtual-machine:/$ lsbin dev initrd.img lib64 mnt root snap sys varboot etc initrd.img.old lost+found opt run srv tmp vmlinuzcdrom home lib media proc sbin swapfile usr pwd的作用是查询当前所在目录 2. 返回父级目录命令： cd .. 输出： 12345hc@hc-virtual-machine:~/PycharmProjects$ pwd/home/hc/PycharmProjectshc@hc-virtual-machine:~/PycharmProjects$ cd ..hc@hc-virtual-machine:~$ pwd/home/hc 3.进入当前目录的父目录的父目录命令： cd ../.. 输出： 12345hc@hc-virtual-machine:~/PycharmProjects$ pwd/home/hc/PycharmProjectshc@hc-virtual-machine:~/PycharmProjects$ cd ../..hc@hc-virtual-machine:/home$ pwd/home 4. 进入当前用户主目录 “当前用户主目录”和“系统根目录”是两个不同的概念。进入当前用户主目录有两个方法。 命令1： cd 直接输入cd，然后回车 输出：12345hc@hc-virtual-machine:~/PycharmProjects/my_test$ pwd/home/hc/PycharmProjects/my_testhc@hc-virtual-machine:~/PycharmProjects/my_test$ cd hc@hc-virtual-machine:~$ pwd/home/hc 上面的命令是我在非root用户下操作的，现在我切换到root用户下再操作一遍 123456hc@hc-virtual-machine:~/PycharmProjects/my_test$ sudo suroot@hc-virtual-machine:/home/hc/PycharmProjects/my_test# pwd/home/hc/PycharmProjects/my_testroot@hc-virtual-machine:/home/hc/PycharmProjects/my_test# cd root@hc-virtual-machine:~# pwd/root 命令2： cd ~ 输出12345hc@hc-virtual-machine:~/PycharmProjects/my_test$ pwd/home/hc/PycharmProjects/my_testhc@hc-virtual-machine:~/PycharmProjects/my_test$ cd ~hc@hc-virtual-machine:~$ pwd/home/hc 5. 跳转到指定目录命令 cd /home/hc/PycharmProjects/my_test/ 输出12345hc@hc-virtual-machine:/$ pwd/hc@hc-virtual-machine:/$ cd /home/hc/PycharmProjects/my_test/hc@hc-virtual-machine:~/PycharmProjects/my_test$ pwd/home/hc/PycharmProjects/my_test 6.返回进入此目录之前所在的目录命令： cd - 说明：自动跳转到进入此目录之前所在的目录，并输出所在目录名称 输出：123456789hc@hc-virtual-machine:/$ pwd/hc@hc-virtual-machine:/$ cd /home/hc/PycharmProjects/my_test/hc@hc-virtual-machine:~/PycharmProjects/my_test$ pwd/home/hc/PycharmProjects/my_testhc@hc-virtual-machine:~/PycharmProjects/my_test$ cd -/hc@hc-virtual-machine:/$ pwd/ 7. 把上个命令的参数作为cd参数使用命令： cd !$ 输出:12345678hc@hc-virtual-machine:~/PycharmProjects/my_test$ pwd/home/hc/PycharmProjects/my_testhc@hc-virtual-machine:~/PycharmProjects/my_test$ ls /opt/googlehc@hc-virtual-machine:~/PycharmProjects/my_test$ cd !$cd /opt/hc@hc-virtual-machine:/opt$ pwd/opt]]></content>
      <categories>
        <category>linux每日命令</category>
      </categories>
      <tags>
        <tag>linux命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux每日命令(1)：ls命令]]></title>
    <url>%2F2018%2F10%2F20%2Flinux%E6%AF%8F%E6%97%A5%E5%91%BD%E4%BB%A4(1)%EF%BC%9Als%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[ls命令是linux下最常用的命令。ls命令就是list的缩写缺省下ls用来打印出当前目录的清单如果ls指定其他目录那么就会显示指定目录里的文件及文件夹清单。 通过ls 命令不仅可以查看linux文件夹包含的文件而且可以查看文件权限(包括目录、文件夹、文件权限)查看目录信息等等。ls 命令在日常的linux操作中用的很多! 1.命令格式：ls [选项] [目录名] 2.命令功能列出目标目录中所有的子目录和文件。（不包含.开头的文件） 3.常用选项参数 选项参数 作用 -l 除了文件名之外，还将文件的权限、所有者、文件大小等信息详细列出来。 -g 类似 -l,但不列出所有者 -o 类似 -l,显示文件的除组信息外的详细信息。 -a 列出目录下的所有文件，包括以 . 开头的文件 -A 同-a，但不列出“.”(表示当前目录)和“..”(表示当前目录的父目录)。 -F 使得ls命令可以在显示子目录的时候在它的文件名之后加上一个斜线(“/”)字符。而文件后面的星号(“*”)字符表示这是一个可执行程序 -r –reverse 依相反次序排列 -i 显示文件或者目录的inode信息，即索引信息 -R –recursive 同时列出所有子目录层 -t 以文件修改时间排序 -S 根据文件大小排序 -c 根据 ctime(文件状态最后更改的时间) 排序；配合 -l：显示 ctime 但根据名称排序否则：根据 ctime 排序；配合-lt:根据 ctime 排序及显示 ctime -u 配合 -lt:显示访问时间而且依访问时间排序；配合 -l:显示访问时间但根据名称排序；否则：根据访问时间排序 -U 不进行排序;依文件系统原有的次序列出项目 -v 根据版本进行排序 -h 以容易理解的格式列出文件大小 (例如 1K 234M 2G) –si 类似 -h,但文件大小取 1000 的次方而不是 1024 -k 以 k 字节的形式表示文件的大小。 -s 以块大小为单位列出所有文件的大小 -m 所有项目以逗号分隔，并填满整行行宽 -w 自行指定屏幕宽度而不使用目前的数值 -x 逐行列出项目而不是逐栏列出 -X 根据扩展名排序 -1 每行只列出一个文件 –help 显示此帮助信息并离开 –version 显示版本信息并离开 4.常见范例1：列出/home/hc文件夹下的所有文件和目录的详细资料命令1 ls -l -R /home/hc 在使用 ls 命令时要注意命令的格式：在命令提示符后，首先是命令的关键字，接下来是命令参数，在命令参数之前要有一短横线“-”，所有的命令参数都有特定的作用，自己可以根据需要选用一个或者多个参数，在命令参数的后面是命令的操作对象。在以上这条命令“ ls -l -R /home/hc”中，“ls” 是命令关键字，“-l -R”是参数，“ /home/hc”是命令的操作对象。在这条命令中，使用到了两个参数，分别为“l”和“R”，当然，你也可以把他们放在一起使用，如下所示： 命令2 ls -lR /home/hc 这种形式和上面的命令形式执行的结果是完全一样的。另外，如果命令的操作对象位于当前目录中，可以直接对操作对象进行操作;如果不在当前目录则需要给出操作对象的完整路径，例如上面的例子中，我的当前文件夹是hc文件夹，我想对home文件夹下的hc文件进行操作，我可以直接输入 ls -lR hc，也可以用 ls -lR /home/hc。 2：列出当前目录中所有以“t”开头的目录的详细内容，可以使用如下命令：命令： ls -l t* 可以查看当前目录下文件名以“t”开头的所有文件的信息。其实，在命令格式中，方括号内的内容都是可以省略的，对于命令ls而言，如果省略命令参数和操作对象，直接输入“ ls ”，则将会列出当前工作目录的内容清单。 3：只列出文件下的子目录列出 /home/hc/PycharmProjects 文件下面的子目录命令： ls -F /home/hc/PycharmProjects |grep /$ 输出： 12345hc@hc-virtual-machine:~$ ls -F /home/hc/PycharmProjects |grep /$FreshOnline/FreshOnline_env/my_test/py3_test/ 列出 /home/hc/PycharmProjects 文件下面的子目录详细情况 命令： ls -l /home/hc/PycharmProjects | grep &quot;^d&quot; 输出： 12345hc@hc-virtual-machine:~$ ls -l /home/hc/PycharmProjects | grep "^d"drwxr-xr-x 9 hc hc 4096 10月 20 08:56 FreshOnlinedrwxrwxr-x 6 hc hc 4096 10月 19 19:07 FreshOnline_envdrwxrwxr-x 3 hc hc 4096 10月 18 15:24 my_testdrwxrwxr-x 4 hc hc 4096 10月 18 17:58 py3_test 4：列出目前工作目录下所有名称是s 开头的档案，愈新的排愈后面，可以使用如下命令：命令： ls -ltr s* 输出：1234hc@hc-virtual-machine:~$ ls -ltr s*总用量 8drwxr-xr-x 5 hc hc 4096 9月 28 21:28 gnome-system-monitordrwxr-xr-x 4 hc hc 4096 9月 29 08:39 pycharm-professional 5：列出目前工作目录下所有档案及目录;目录于名称后加”/“, 可执行档于名称后加”*”命令： ls -AF 输出： 12hc@hc-virtual-machine:~/PycharmProjects$ ls -AFFreshOnline/ FreshOnline_env/ my_test/ py3_test/ 6：计算当前目录下的文件数和目录数命令： ls -l * |grep &quot;^-&quot;|wc -l ---文件个数 ls -l * |grep &quot;^d&quot;|wc -l ---目录个数 7: 在ls中列出文件的绝对路径命令： ls | sed &quot;s:^:`pwd`/:&quot; 输出： 12345hc@hc-virtual-machine:~/PycharmProjects$ ls | sed "s:^:`pwd`/:"/home/hc/PycharmProjects/FreshOnline/home/hc/PycharmProjects/FreshOnline_env/home/hc/PycharmProjects/my_test/home/hc/PycharmProjects/py3_test 8：列出当前目录下的所有文件（包括隐藏文件）的绝对路径， 对目录不做递归命令： find $PWD -maxdepth 1 | xargs ls -ld 输出： 123456hc@hc-virtual-machine:~/PycharmProjects$ find $PWD -maxdepth 1 | xargs ls -lddrwxrwxr-x 6 hc hc 4096 10月 19 18:22 /home/hc/PycharmProjectsdrwxr-xr-x 9 hc hc 4096 10月 20 08:56 /home/hc/PycharmProjects/FreshOnlinedrwxrwxr-x 6 hc hc 4096 10月 19 19:07 /home/hc/PycharmProjects/FreshOnline_envdrwxrwxr-x 3 hc hc 4096 10月 18 15:24 /home/hc/PycharmProjects/my_testdrwxrwxr-x 4 hc hc 4096 10月 18 17:58 /home/hc/PycharmProjects/py3_test 9：递归列出当前目录下的所有文件（包括隐藏文件）的绝对路径命令： find $PWD | xargs ls -ld 10：指定文件时间输出格式命令： ls -tl --time-style=full-iso 输出：123456hc@hc-virtual-machine:~/PycharmProjects$ ls -tl --time-style=full-iso总用量 16drwxr-xr-x 9 hc hc 4096 2018-10-20 08:56:55.833765666 +0800 FreshOnlinedrwxrwxr-x 6 hc hc 4096 2018-10-19 19:07:08.330876787 +0800 FreshOnline_envdrwxrwxr-x 4 hc hc 4096 2018-10-18 17:58:39.489690632 +0800 py3_testdrwxrwxr-x 3 hc hc 4096 2018-10-18 15:24:06.613354334 +0800 my_test ls -ctl --time-style=long-iso 输出： 123456hc@hc-virtual-machine:~/PycharmProjects$ ls -ctl --time-style=long-iso总用量 16drwxr-xr-x 9 hc hc 4096 2018-10-20 08:56 FreshOnlinedrwxrwxr-x 6 hc hc 4096 2018-10-19 19:07 FreshOnline_envdrwxrwxr-x 4 hc hc 4096 2018-10-18 17:58 py3_testdrwxrwxr-x 3 hc hc 4096 2018-10-18 15:24 my_test 扩展：显示彩色目录列表打开/etc/bashrc, 加入如下一行: alias ls=&quot;ls --color&quot; 下次启动bash时就可以像在Slackware里那样显示彩色的目录列表了, 其中颜色的含义如下: 1. 蓝色--&gt;目录 2. 绿色--&gt;可执行文件 3. 红色--&gt;压缩文件 4. 浅蓝色--&gt;链接文件 5. 灰色--&gt;其他文件]]></content>
      <categories>
        <category>linux每日命令</category>
      </categories>
      <tags>
        <tag>linux命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[git常用命令大全]]></title>
    <url>%2F2018%2F08%2F31%2Fgit%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E6%93%8D%E4%BD%9C%E5%A4%A7%E5%85%A8%2F</url>
    <content type="text"><![CDATA[记录日常工作中常用git命令，以便备忘查询 初始化git仓库 git initgit init 添加文件到Git仓库 git add 、 git commit分两步： 第一步，使用命令git add 文件名 ，将指定文件添加到版本库的暂存状态。注意，可反复多次使用，添加多个文件；也可以直接 git add . 代表添加所有改变的文件 第二步，使用命令 git commit -m &#39;自定义的提交说明&#39; 将暂存区的文件提交到版本库的分支 我们需要知道Git把管理的文件分为了两个区域四个状态 工作区：当前开发程序所在目录称为工作区，即：工作开发都是在该目录，该区域的文件会有状态的变化且状态由git自动检测，如果程序中文件做任何操作（增、删、改），文件状态均会被检测到，可以使用 【git status】命令查看。 版本库 工作区检测到有文件发生变化，那么意味着较上一个版本之后对程序进行了修改，修改完成之后，可以当做下一版本进行提交，那么就是执行 【git add .】 将所有文件提交到暂存区，然后再执行【git commit -m ‘又一个版本’】提交到版本库的分支即可，之后可以使用【git log】命令查看版本记录。 查看当前仓库状态 git status我们可以用 git status 来查看当前Git仓库状态,如：那些文件被修改过、那些文件还未提交到版本库等。 查看提交的版本记录 git log、 git refloggit log， 命令显示从最近到最远的提交日志，即：历史版本记录 git reflog，用来查看执行回退命令后，在 git log中未显示的记录 查看修改内容 git diff假设我们已经成功地添加并提交了一个readme.txt文件，现在，继续工作了，我们继续修改readme.txt文件 此时，我们使用git status 命令， 可以发现readme.txt文件已经被修改了，但还未提交，但是具体修改了什么，我们无法得知，加入我们此时将其放置，一两周后再回来看，可能会不记得之前改动了什么，此时我们可以使用 git diff readme.txt 来查看readme.txt 文件里修改的内容确定了我们修改了什么内容以后，我们就可以放心大胆的git add . 然后git commit -m&#39;修改readme.txt&#39; 提交此次修改了 要随时掌握工作区的状态，使用 git status 命令。•如果 git status 告诉你有文件被修改过，用 git diff 可以查看修改内容。 版本回退在Git中，用HEAD表示当前版本，也就是最新的提交版），上一个版本就是HEAD^ ，上上一个版本就是HEAD^^，当然往上100 个版本写100个^比较容易数不过来，所以写成HEAD~100。 比如当前版本id为4,我们想跳到上一个版本3去，可以使用下面的命令 回退到上一个版本 git reset --hard HEAD^git reset --hard HEAD^ 或直接指定具体版本 git reset --hard 3 回退到具体版本 git reset --hard commit_id一旦我们执行了回退操作，则 git log中将看不到当前回退到的版本之后的所有版本信息 要想在回退后，看到当前版本之后的信息需要用到git reflog 如果现在又想跳回去，可以使用git reset --hard 4 小结 HEAD指向的版本就是当前版本，因此，Git允许我们在版本的历史之间穿梭，使用命令 git reset --hard commit_id 。 穿梭前，用 git log 可以查看提交历史，以便确定要回退到哪个版本。 要重返未来，用 git reflog 查看命令历史，以便确定要回到未来的哪个版本。 撤销工作区的修改git checkout --文件名有时我们不小心写了很多无用的东西，想丢弃工作区的修改，可以使用git checkout --文件名 命令 git checkout -- readme.txt 意思就是，把readme.txt文件在工作区的修改全部撤销，这里有两种情况： 一种是readme.txt自修改后还没有被放到暂存区，现在，撤销修改就回到和版本库一模一样的状态； 一种是readme.txt已经添加到暂存区后，又作了修改，现在，撤销修改就回到添加到暂存区后的状态。总之，就是让这个文件回到最近一次 git commit 或 git add 时的状态 当我们工作区中的内容不小心 git add 了（但是没有git commit），进入了暂存区时，此时要想撤销修改，则需要用到下面的命令 撤销暂存区的修改 git reset HEAD 文件名用命令 git reset HEAD file 可以把暂存区的修改撤销掉（unstage），重新放回工作区：git reset 命令既可以回退版本，也可以把暂存区的修改回退到工作区。当我们用HEAD时，表示最新的版本。再用 git status 查看一下，现在暂存区是干净的，工作区有修改还记得如何丢弃工作区的修改吗？git checkout -- 文件名 此时再用 git status，则是干净的 重新编辑最近一次git commit -m 里写的注释备注内容命令： git commit --amend 如果git commit 后发现commit的信息写错了或者是有的文件忘记提交，并且commit后没有进行过push，可以通过git commit --amend 来对本次commit进行修改 123git commit -m 'initial commit'git add ./README.mdgit commit --amend 上面的三条命令最终只是产生一个提交，第二个提交命令修正了第一个的提交内容。 小结 场景1：当你改乱了工作区某个文件的内容，想直接丢弃工作区的修改时，用命令 git checkout -- file。 场景2：当你不但改乱了工作区某⽂文件的内容，还添加到了暂存区时，想丢弃修改，分两步，第一步用命令 git reset HEAD file ，就回到了场景1，第二步按场景1操作。 场景3：已经提交了不合适的修改到版本库时，想要撤销本次提交，则使用git reset --hard commit_id，不过前提是没有推送到远程库。 删除文件 git rm 在Git中，删除也是一个修改操作,当我们直接在文件管理器中删除git仓库所在目录下的文件，或者直接通过rm 文件名来删除某个文件时，git会将其认定为一个修改操作，这样会造成工作区和版本库中不一致，此时有两种情况，根据我们的需求来进行选择 情况1：如果我们确实是想从版本库中删除该文件，那么就用git rm 文件名 命令来进行删除，然后 git commit -m&#39;删除某文件&#39; ，提交此次删除，这样，该文件就从版本库中被删除了 情况2: 不小心误删了，由于版本库中还存在，我们可以直接将误删的文件恢复到版本库中该文件的最新版本，使用命令git checkout -- 文件名,git checkout 其实是用版本库里的版本替换工作区的版本，无论工作区是修改还是删除，都可以“一键还原”。但是需要注意的是：这种方法只能恢复文件到最新版本，但会丢失最近一次提交后你修改的内容。 分支管理创建分支 git branch 分支名切换分支 git checkout 分支名也可以直接使用一条命令，来完成上面两个命令的操作 创建并切换分支 git checkout -b 分支名查看当前所属分支 git branchgit branch 命令会列出所有分支，当前分支前面会标一个*号。 合并分支 git merge 分支名比如：我们当前所在分支为master，我们要想将dev分支中的内容合并到master中来，就在master分支下，使用命令 git merge dev 即可 git merge 命令用于合并指定分支到当前分支。合并后，就可以看到，当前master分支和dev分支的最新提交是完全一样的。 注意到,默认情况下,git会采用Fast-forward方式进行合并，即“快进模式”，也就是直接把master指向dev的当前提交，所以合并速度非常快。当然，也不是每次合并都能Fast-forward（比如当我们合并时产生了冲突，需要解决冲突时，就无法使用”快进模式”了） 解决合并冲突之所以合并产生冲突，是因为我们进行合并时，我们的合并分支在我们准备合并前已发生变化（大多数情况下，是由于协同开发时，由于别人在我们进行合并之前，先进行了合并操作，导致我们再去合并时，已经发生了变化），因此我们需要根据冲突提升，找出冲突所在地，去解决冲突，在冲突文件中，Git用 &lt;&lt;&lt;&lt;&lt;&lt;&lt;，=======，&gt;&gt;&gt;&gt;&gt;&gt;&gt;标记出不同分支的内容，我们需要对比找出需要删除和保留的代码，最后再将&lt;&lt;&lt;&lt;&lt;&lt;&lt;，=======，&gt;&gt;&gt;&gt;&gt;&gt;&gt;这些符号删除，然后git add . ,git commit -m&#39;解决冲突&#39; ，即合并完成。 合并分支时，可禁用”Fast forward”模式 git merge --no-ff -m &quot;提交信息&quot; 分支名通常，合并分支时，如果可能，Git会用“Fast forward”模式，但这种模式下，删除分支后，会丢掉分支信息。如果要强制禁用“Fast forward”模式，Git就会在merge时生成一个新的commit，这样，从分支历史上就可以看出分支信息。--no-ff 参数，表示禁用“Fast forward”,因为禁用了“快速模式”，合并时要创建一个新的commit，所以加上-m参数，把commit描述写进去。 删除分支 git branch -d 分支名如果要丢弃一个没有被合并过的分支，可以通过 git branch -D 分支名 强行删除。 查看分支合并图 git log --graphBug 分支 在我们日常开发中，经常会遇到开发途中，遇到需要修复之前BUG的需求，很自然地，我们会到想创建一个分支来修复它，但是，当前正在dev上进行的工作还没有提交，并不是你不想提交，而是工作只进行到一半，还没法提交，预计完成还需1天时间。但是，必须在两个小时内修复该bug，怎么办？无法创建新的分支，怎么办？幸好，Git还提供了一个stash功能，可以把当前工作现场“储藏”起来，等以后恢复现场后继续工作： “暂存”工作区中的代码 git stash使用命令git stash 后，我们当前工作区的代码将被暂存起来（并不是git add 命令存入的那个暂存区）， 这时用 git status 查看工作区，就是干净的（除非有没有被Git管理的文件），因此可以放心地创建分支来修复bug。首先确定要在哪个支上修复bug，假定需要在master分支上修复，就从master创建临时分支： 切换分支git checkout master 创建并切换bug分支git checkout -b bug01 git add . 、git commit -m&#39;修复bug01&#39;修复完成后 切换到master分支，并完成合并，最后删除bug01分支： git checkout master git merge --no-ff -m &quot;合并bug1分支&quot; bug01 git branch -d bug01 OK! bug修复完成，是时候切换回dev分支接着干活了 git checkout dev git status通过查看状态发现，我们当前工作区是干净的，我们在修复bug之前写的代码去哪了？我们之前用 git stash把工作区的内容存在某个地方了，现在可以通过命令查看stash记录 查看stash记录 git stash list现在我们要把之前暂存的内容恢复回来，有两种方式 恢复stash内容 一是用 git stash apply 恢复，但是恢复后，stash内容并不删除，你需要用git stash drop 来删除； 另一种方式是用 git stash pop ，恢复的同时把stash内容也删了： 再用 git stash list查看，就看不到任何stash内容了 我们可以多次stash，恢复的时候，先用 git stash list 查看，然后恢复指定的stash，用命令： git stash apply stash@{id} 小结修复bug时，我们会通过创建新的bug分支进行修复，然后合并，最后删除；当手头工作没有完成时，先把⼯工作现场 git stash一下，然后去修复bug，修复后，再 gitstash pop ，回到工作现场。 远程仓库git多账号登陆问题设置git全局设置：git config --global user.name &quot;your_name&quot; git config --global user.email &quot;your_email&quot; 需要取消git的全局设置:git config --global --unset user.name git config --global --unset user.email 针对每个项目，单独设置用户名和邮箱，设置方法如下：git config user.name &quot;your_name&quot; git config user.email &quot;your_email&quot; 绑定远程仓库地址 要关联一个远程库，使用命令 git remote add origin 远程仓库地址（如：git@server-name:path/repo-name.git） ；关联后，使用命令 git push -u origin master 第一次推送master分⽀的所有内容；此后，每次本地提交后，只要有必要，就可以使用命令git push origin master 推送最新修改。 从远程库克隆要克隆一个仓库，首先必须知道仓库的地址，然后使用 git clone 远程库地址进行克隆。Git支持多种协议，包括https，但通过ssh支持的原生git协议速度最快。 Git支持多种协议，默认的git://使用ssh，但也可以使用https等其他协议。使用https除了速度慢以外，还有个最大的麻烦是每次推送都必须输入口令，但是在某些只开放http端口的公司内部就无法使用ssh协议而只能用https。 git删除远程文件夹或文件的方法具体操作步骤如下： 1. 预览将要删除的文件123git rm -r -n --cached 文件/文件夹名称 加上 -n 这个参数，执行命令时，是不会删除任何文件，而是展示此命令要删除的文件列表预览。 2. 确定无误后删除文件git rm -r --cached 文件/文件夹名称 3. 提交到本地并推送到远程服务器12git commit -m "提交说明"git push origin master 4. 修改本地 .gitignore 文件 并提交12git commit -m "提交说明"git push origin master 其他常用操作 查看远程库信息，使用 git remote -v； 本地新建的分支如果不推送到远程，对其他人就是不可见的； 从本地推送分支，使用 git push origin 分支名 ，如果推送失败，先用git pull orign 分支名抓取远程的新提交； 在本地创建和远程分支对应的分支，使用 git checkout -b 分支名 origin/分支名，本地和远程分支的名称最好一致； 建立本地分支和远程分支的关联，使用 git branch --set-upstream 分支名 origin/分支名 ； 从远程抓取分支，使用git pull ，如果有冲突，要先处理冲突。 参考：Git教程]]></content>
      <categories>
        <category>工具</category>
      </categories>
      <tags>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[windows10环境下安装RabbitMQ(图文步骤)]]></title>
    <url>%2F2018%2F07%2F31%2Fwindows10%E7%8E%AF%E5%A2%83%E4%B8%8B%E5%AE%89%E8%A3%85RabbitMQ(%E5%9B%BE%E6%96%87%E6%AD%A5%E9%AA%A4)%2F</url>
    <content type="text"><![CDATA[记录下本人在win10环境下安装RabbitMQ的步骤，以作备忘。 第一步：下载并安装erlang 原因：RabbitMQ服务端代码是使用并发式语言Erlang编写的，安装Rabbit MQ的前提是安装Erlang。 下载地址：http://www.erlang.org/downloads 根据本机位数选择erlang下载版本。 下载完是这么个东西： 双击，点next就可以。 选择一个自己想保存的地方，然后next、finish就可以。 安装完事儿后要记得配置一下系统的环境变量。此电脑–&gt;鼠标右键“属性”–&gt;高级系统设置–&gt;环境变量–&gt;“新建”系统环境变量 变量名：ERLANG_HOME 变量值就是刚才erlang的安装地址，点击确定。 然后双击系统变量path 点击“新建”，将%ERLANG_HOME%\bin加入到path中。 最后windows键+R键，输入cmd，再输入erl，看到版本号就说明erlang安装成功了。 第二步：下载并安装RabbitMQ 下载地址：http://www.rabbitmq.com/download.html 双击下载后的.exe文件，安装过程与erlang的安装过程相同。 RabbitMQ安装好后接下来安装RabbitMQ-Plugins。打开命令行cd，输入RabbitMQ的sbin目录 我的目录是：D:\Program Files\RabbitMQ Server\rabbitmq_server-3.7.3\sbin 然后在后面输入enable rabbitmq_management```命令进行安装1234567如果```rabbitmq-plugins enable rabbitmq_management```使用报错如下 ![](http://pcqah8keq.bkt.clouddn.com/13.png) 请请使用```rabbitmq-plugins.bat enable rabbitmq_management 安装成功如下： 打开sbin目录，双击rabbitmq-server.bat 等几秒钟看到这个界面后，访问http://localhost:15672 然后可以看到如下界面 默认用户名和密码都是guest 登陆即可。 转自：https://blog.csdn.net/weixin_39735923/article/details/79288578]]></content>
      <categories>
        <category>工具</category>
      </categories>
      <tags>
        <tag>RabbitMQ</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python unicode和str拼接报错原因]]></title>
    <url>%2F2018%2F07%2F25%2FPython%20unicode%E5%92%8Cstr%E6%8B%BC%E6%8E%A5%E6%8A%A5%E9%94%99%E5%8E%9F%E5%9B%A0%2F</url>
    <content type="text"><![CDATA[首先来看一段代码 一、例子 123456789101112131415161718192021222324# -*- coding: utf-8 -*-a1 = u'你好'b1 = '中文' print(a1+b1) # 报错a2 = u'你好'b2 = '中文' + a.encode('utf-8')print(b2) # 正常输出type(b2) # stra3 = u'http'b3 = 'abc' + aprint(b3) # 正常输出type(b3) # unicode a1,a2,a3都是unicode对象，unicode是一种编码标准，具体的实现可能是utf-8，utf-16，gbk等等，这就是中文字符串和unicode有密切关系的原因。python内部使用两个字节存储一个unicode对象（unicode对象并不只能是字符串，这两个字节还可以存其他内容），为什么要用unicode而不用str呢，因为中文转码的缘故，因为unicode的优点是便于跨平台。 b1 是str对象，中文字符串。存储方式是字节码。字节码是怎么存的：如果这行代码在python解释器中输入&amp;运行，那么s的格式就是解释器的编码格式；如果这行代码是在源码文件中写入、保存然后执行，那么解释器载入代码时就将s初始化为文件指定编码(比如py文件开头那行的utf-8)； 下面这两种方式都是表示unicode对象 12s1 = u'中文' # s1: &lt;type 'unicode'&gt;s2 = unicode('中文', 'utf-8') # utf8是在指定解码方式, s2: &lt;type 'unicode'&gt; python解释器中 如果 将一个 普通字符串 和 unicode对象字符串 拼接，会默认将普通字符串 用decode(‘ascii’)解码成unicode对象。为什么是用 ascii的方式解码呢，因为这里用的是python的默认编码,也就是defaultencoding = ascii。 所以，如果这个普通字符串 包含中文的话，就会报错，因为用ascii码去解码中文是不够用的。(中文得用unicode解码)。 二、正确的str对象和unicode对象拼接方式只要注意正确的decode、encode方式，统一编码后就能顺利地拼接了。123456789101112# -*- coding: utf-8 -*- s1 = '中文's2 = u'你好'print s1 + unicode(s2, 'utf-8') # 中文你好print s1 + s2.decode('utf-8') # 中文你好print s1.encode('utf-8') + s2 # 中文你好 print type(s1) # &lt;type 'str'&gt;print type(s2) # &lt;type 'unicode'&gt;print type(s1.decode('utf-8')) # &lt;type 'unicode'&gt;print type(s2.encode('utf-8')) # &lt;type 'str'&gt; 对于str要注意当前环境编码方式，也许是控制台那种设定好了的，也许是你自己在代码中指定的。对于unicode对象，一般都是decode得到的，像直接【u’你好’】这种其实不是很常见，所以要注意字符串来源是什么编码，比如从gbk文件或utf8文件中读入的。 参考自： https://blog.csdn.net/index20001/article/details/78974814 https://blog.csdn.net/qq_31739317/article/details/75257726]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>编码</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python时间格式转换(时间戳、日期、时间、字符串)]]></title>
    <url>%2F2018%2F07%2F24%2FPython%E6%97%B6%E9%97%B4%E6%A0%BC%E5%BC%8F%E8%BD%AC%E6%8D%A2(%E6%97%B6%E9%97%B4%E6%88%B3%E3%80%81%E6%97%A5%E6%9C%9F%E3%80%81%E6%97%B6%E9%97%B4%E3%80%81%E5%AD%97%E7%AC%A6%E4%B8%B2)%2F</url>
    <content type="text"><![CDATA[在工作中我们常会对时间戳以及日期时间等格式进行转换，下面介绍了一些常用的Python时间的转换方法，方便以后查询 一、str类型的日期转换为时间戳1234567891011121314# -*- coding: utf-8 -*-import timefrom datetime import datetimetss1 = '2013-10-10 23:40:00'# 转为时间数组timeArray = time.strptime(tss1, "%Y-%m-%d %H:%M:%S")# timeArray可以调用tm_year等print timeArray # time.struct_time# 转为时间戳timeStamp = int(time.mktime(timeArray))print timeStamp # 1381419600 二、时间戳转换:10位（秒级）和13位（毫秒级）时间戳123456789101112131415161718# -*- coding: utf-8 -*-import timefrom datetime import datetimenow_timestamp = time.time()print 'now_timestamp', now_timestamp, type(now_timestamp)# now_timestamp 1532447792.62 &lt;type 'float'&gt;seconds = int(now_timestamp)print '10位秒级', seconds# 10位秒级 1532447792millis1 = int(round(now_timestamp * 1000))print '13位毫秒级1', millis1, type(millis1)# 13位毫秒级1 1532447792615 &lt;type 'long'&gt;millis2 = '%.f' % (now_timestamp * 1000)print '13位毫秒级2', millis2, type(millis2)# 13位毫秒级2 1532447792615 &lt;type 'str'&gt; 三、更改str类型日期的显示格式1234567891011121314# -*- coding: utf-8 -*-import timefrom datetime import datetimetss2 = "2013-10-10 23:40:00"# 转为数组timeArray = time.strptime(tss2, "%Y-%m-%d %H:%M:%S")# 转为其它格式otherStyleTime = time.strftime("%Y/%m/%d %H:%M:%S", timeArray)print otherStyleTime # 2013/10/10 23:40:00tss3 = "2013/10/10 23:40:00"timeArray = time.strptime(tss3, "%Y/%m/%d %H:%M:%S")otherStyleTime = time.strftime("%Y-%m-%d %H:%M:%S", timeArray)print otherStyleTime # 2013-10-10 23:40:00 四、时间戳转换为指定格式的日期12345678910111213141516171819# -*- coding: utf-8 -*-import timefrom datetime import datetime# 使用timetimeStamp = 1381419600timeArray = time.localtime(timeStamp)print timeArray # time.struct_timeotherStyleTime = time.strftime("%Y--%m--%d %H:%M:%S", timeArray)print otherStyleTime # 2013--10--10 23:40:00# 使用datetimeutc_data = datetime.utcfromtimestamp(now_timestamp)print 'utc时间', utc_data, type(utc_data)# utc时间 2018-07-24 15:59:49.501000 &lt;type 'datetime.datetime'&gt;local_data = datetime.fromtimestamp(now_timestamp)print 'local时间', local_data, type(local_data)# local时间 2018-07-24 23:59:49.501000 &lt;type 'datetime.datetime'&gt; 五、时间戳转换为指定格式的日期123456789101112131415# -*- coding: utf-8 -*-import timefrom datetime import datetime# 获取当前时间戳now = int(time.time())timeArray = time.localtime(now)otherStyleTime = time.strftime("%Y--%m--%d %H:%M:%S", timeArray)print otherStyleTime # 2018--07--24 23:59:49# 获取当前时间，数组格式now = datetime.now()otherStyleTime = now.strftime("%Y--%m--%d %H:%M:%S")print otherStyleTime # 2018--07--24 23:59:49 六、获取本地时区当天0点时间戳和时间的一种方法123456789# -*- coding: utf-8 -*-import timefrom datetime import datetime# 方法1print time.mktime(datetime.now().date().timetuple()) # 1532534400.0today = datetime.today()# 方法2print datetime(today.year, today.month, today.day, 0, 0, 0) # 2018-07-26 00:00:00]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>时间</tag>
      </tags>
  </entry>
</search>
